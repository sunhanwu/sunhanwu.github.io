<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2Fsunpages%2F2020%2F07%2F13%2Fguide%2F</url>
    <content type="text"><![CDATA[李宏毅机器学习2020课程导学 机器学习2020与以往不同的地方在于增加了很多作业，具体的作业如下如所示。下图中的每一个符号都代表一个作业。 机器学习就是自动找一个函数 语音辨识：$f(语音)=$”How are you” 图像识别：$f(图像)=$”cat“ 围棋：$f(棋谱)=$”5-5”（下一步棋的位置） 对话系统：f(“How are you”)=”I am fine” 如果机器可以能给我们找到函数。随着我们想要找到的函数的不同，我们有不同的机器学习的任务。例如： 第一个作业是叫regression， 意思就是我们现在要找到一个函数，函数的输出是一个数值。 在作业一中，我们要做的事情就是要让机器]]></content>
  </entry>
  <entry>
    <title><![CDATA[纯手工实现线性回归（作业一）]]></title>
    <url>%2Fsunpages%2F2020%2F07%2F06%2Fhw1%2F</url>
    <content type="text"><![CDATA[纯手工实现线性回归（作业一）​ 近年来机器学习和深度学习十分火热，应用十分广泛。在完成本科毕设过程中和在信工所实习的时候深感自己对于深度学习方面的知识掌握的远远不够，因此打算在暑假期间恶补一下深度学习。寻找学习资料的时候，在B站发现了一个宝藏教程, 台大李宏毅教授对于深度学习中的各种技术和算法讲解的十分透彻，并且公开了作业，甚至有些作业是以kaggle比赛的形式，我们也可以提交自己写的作业。因此打算跟随教程完成这些作业，并且将每次的作业报告发布到自己的博客，主要是方便以后自己查阅。 ​ 这篇博客是作业一，kaggle比赛的传送门在此,kaggle平台上有作业提供的数据集合介绍。助教也给做了相关的说明 ​ 我个人在github仓库，完整的数据和代码里面都有 准备数据数据集介绍数据集的详细介绍在kaggle平台上都有，助教提供的ppt和视频说明中也都有。这里简单介绍一下我认为值得关注的几个点。 题目要求根据前9个小时的数据预测第10个小时的PM2.5的数值。因此对于每个样本来说前9个小时内所有观测数据都属于特征值，特征值共包括18种观测指标，每种观测指标9个数据，所以一个样本的特征值个数为$18 * 9 = 162$, 而PM2.5在第十个小时的数值作为label 一天24个小时，按照1的方式进行提取样本的话可以提取15个样本数据 数据中存在NR值的话需要给替换为数值0 数据预处理基本了解了数据集合题目要求之后，就需要对数据进行预处理工作了，首先处理训练数据。 处理训练数据1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859def loadTrainData(trainDataFile): """ 加载训练数据集，并且处理成需要的格式 """ trainData = pd.read_csv(trainDataFile, encoding='big5') # 去除日期等误用数据 trainData = trainData.iloc[:, 2:] # 将NR替换为0,并将其转回为numpy trainData[trainData == 'NR'] = 0 # 原始的数据大小为4320*25 trainDataArray = trainData.to_numpy().astype('float64') # 重组数据 rows, columns = trainDataArray.shape Data = [] for day in range(rows // 18): rowLow = day * 18 rowHigh = rowLow + 18 rowPM25 = rowLow + 9 for columnLeft in range(15): columnRight = columnLeft + 9 OneTrainData = trainDataArray[rowLow:rowHigh, columnLeft:columnRight].reshape(-1) label = trainDataArray[rowPM25, columnRight] oneSampleData = np.append(OneTrainData, label) Data.append(oneSampleData) if rowHigh + 18 &lt;= rows: for columnLeft_ in range(15, 24, 1): leftData = trainDataArray[rowLow:rowHigh, columnLeft_:] rightData = trainDataArray[rowLow+18:rowHigh+18, :9 - (24 - columnLeft_)] OneTrainData = np.hstack((leftData, rightData)).reshape(-1) label = trainDataArray[rowPM25 + 18, 9 - (24 - columnLeft_)] oneSampleData = np.append(OneTrainData, label) Data.append(oneSampleData) Data = np.array(Data) return Data[:, :162], Data[:, 162]def loadTrainData(trainDataFile): """ 加载训练数据集，并且处理成需要的格式 """ trainData = pd.read_csv(trainDataFile, encoding='big5') # 去除日期等误用数据 trainData = trainData.iloc[:, 2:] # 将NR替换为0,并将其转回为numpy trainData[trainData == 'NR'] = 0 # 原始的数据大小为4320*25 trainDataArray = trainData.to_numpy().astype('float64') # 重组数据 rows, columns = trainDataArray.shape Data = [] for day in range(rows // 18): rowLow = day * 18 rowHigh = rowLow + 18 rowPM25 = rowLow + 9 for columnLeft in range(15): columnRight = columnLeft + 9 OneTrainData = trainDataArray[rowLow:rowHigh, columnLeft:columnRight].reshape(-1) label = trainDataArray[rowPM25, columnRight] oneSampleData = np.append(OneTrainData, label) Data.append(oneSampleData) Data = np.array(Data) return Data[:, :162], Data[:, 162] 原始数据文件中，每天的数据有18个观测指标，每个观测指标记录24个数值，共有240天的数据。因此原始数据集（去除日期和指标名称等误用信息）对应的大小为4320*24 一个样本对应同一天中18中观测指标中连续9个小时的观测数据，特征值个数为18*9=162，df的shape为(18,9) label为同一天连续9个小时观测数据后一小时的pm2.5数值 使用pandas按照上述方法截取到对应位置的数值后将其reshape为一维数据，得到(162,1)的数据，加上label值后维度为(163,1) 处理测试数据测试数据和训练数据的处理方式类似，只是过程简单一些。测试数据是给出每天前9个小时各个观测指标的数值，要求我们预测每天第10个小时的PM2.5值 1234567891011121314151617def loadTestData(testDataFile): """ 加载测试数据 """ testData = pd.read_csv(testDataFile, encoding='big5', header=None) testData = testData.iloc[:, 2:] testData[testData == 'NR'] = 0 testDataArray = testData.to_numpy() rows, column = testDataArray.shape Data = [] for day in range(rows // 18): rowLow = day * 18 rowHigh = rowLow + 18 OneTestData = testDataArray[rowLow:rowHigh, :].reshape(-1) Data.append(OneTestData) Data = np.array(Data) return Data 数据归一化由于不同特征表示的是空气质量的不同指标，其值域范围有很大的不同，这样的训练数据会很严重的影响模型的性能，至于是如何影响可以看下面模型调优里面关于数据归一化的相关介绍 12345678def normalization(data): mu = np.mean(data, axis=0) sigma = np.std(data, axis=0) for i in range(len(data)): for j in range(len(data[0])): if sigma[j] != 0: data[i][j] = (data[i][j] - mu[j]) / sigma[j] return data 我简单的将各个特征的极差(最大值和最小值的从差)绘制成如下的图像： 可以看到不同特征之间的极差相差特别大，这种变化会导致后来梯度下降过程中出现一些问题，某些特征对应的wight的梯度变化的比其他的块的多，有可能导致出现梯度爆炸等情况。 使用归一化函数后这种数据之间的极差不平衡就会消失 定义模型定义dataLoader首先定义一个数据装载器，并于对数据进行shuffle操作，每次返回batch_size数据便于后续进行随机梯度下降。 1234567891011def dataIter(batchSize, feature, label, shuffle=True): """ 将训练数据进行shuffle，按照一个batch_size的数据量返回 """ numExample = len(feature) indexs = list(range(numExample)) if shuffle: random.shuffle(indexs) for i in range(0, numExample, batchSize): index = indexs[i:i + batchSize] yield feature[index], label[index] 定义线性回归模型和损失函数 定义线性回归模型 线性回归是最简单的机器学习模型，对于每个特征值都有一个对应的参数w，模型中对应的参数$w_i$乘以$x_i$求和后加上bias，具体的公示如下： \hat y_i = \sum {w_i* x_i} + b_i123def regression(feature, param): predict = np.dot(feature, param[0]) + param[1] return predict ​ 需要注意的是在具体计算的时候feature不是简单的一个向量，而是由多个向量组成的一个矩阵，对应变量维度信息如下： w = param[0]\\ b = param[1]\\ dim(feature) = (batch\_size, num\_feature)\\ dim(param[0]) = (num\_feature, 1)\\ dim(b) = 1\\ dim(\hat y) = (batch\_size, 1) 定义损失函数 损失函数就是最普通的平方损失函数，就是直接计算模型预测的值$\hat y$和真实的$y$的差的值的平方的平均值。为了在求导过程中方便计算，一般有人多除以个2，也有人不除。下面是损失函数的公示： Loss = \frac {1}{N} (y_i - (w_i x_i + b))^212def Loss(predict, label): return np.sum((label - predict) ** 2) / (2 *len(label)) 这里的predict和label都是长度为batch_size的向量 定义随机梯度下降函数MBGD梯度下降算法是整个机器学习里面最为核心的算法。可以说整个无论是复杂的LSTM，CNN等深度学习网络，还是简单的线性回归/逻辑回归都是靠着各种各样的梯度下降算法来实现对参数的更新，从而实现让模型更加智能的目的。下面首先介绍SGD的实现过程，如果在后续实验过程中发现效果不好的话则换用其他梯度下降算法。 算法名 说明 优缺点 BGD 采用整个训练集的数据来计算 cost function 对参数的梯度 由于这种方法是在一次更新中，就对整个数据集计算梯度，所以计算起来非常慢，遇到很大量的数据集也会非常棘手，而且不能投入新数据实时更新模型 SGD 每次更新时对每个样本进行梯度更新 对于很大的数据集来说，可能会有相似的样本，这样 BGD 在计算梯度时会出现冗余，而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。SGD 因为更新比较频繁，会造成 cost function 有严重的震荡。BGD 可以收敛到局部极小值，当然 SGD 的震荡可能会跳到更好的局部极小值处。 MBGD MBGD 每一次利用一小批样本，即 n 个样本进行计算 这样它可以降低参数更新时的方差，收敛更稳定，另一方面可以充分地利用深度学习库中高度优化的矩阵操作来进行更有效的梯度计算不过 Mini-batch gradient descent 不能保证很好的收敛性，learning rate 如果选择的太小，收敛速度会很慢，如果太大，loss function 就会在极小值处不停地震荡甚至偏离。 在梯度下降算法中最为重要的是对损失函数进行求导，下面给出线性回归模型中对于w和b的求导公示（因为线性回归模型比较简单，手工求导不复杂，但是之后复杂的神经网络中一般使用深度学习框架进行自动求导） \frac{\partial L o s s}{\partial m}=\frac{\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\left(m x_{i}+b\right)\right)^{2}}{\partial m}=-\frac{2}{N} \sum_{i=1}^{N} x_{i}\left(y_{i}-\left(m x_{i}+b\right)\right)\\ \frac{\partial L o s s}{\partial b}=\frac{\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-\left(m x_{i}+b\right)\right)^{2}}{\partial b}=-\frac{2}{N} \sum_{i=1}^{N}\left(y_{i}-\left(m x_{i}+b\right)\right)下面是对应的python代码实现 123456789101112131415def MBGD(param, lr, features, labels): """ 使用SGD优化器 """ w = param[0] b = param[1] N = len(labels) h = np.dot(features, w) + b labels = labels.reshape(h.shape) dw = features.T.dot((h - labels)) / N db = np.sum((h - labels)) / N new_w = w - lr * dw new_b = b - lr * db new_param = (new_w, new_b) return new_param 注意这里对参数w和b的求导方式和上面所述公示结果是一致的，只是将$\hat y$放在了前面而已 模型调优​ 经过上述一系列的准备工作，已经能够跑起来一个简单的线性回归模型，下面是经过上面模型跑出来的loss曲线图, 模型在训练集和验证集上都能够有效的训练，并且没有出现过拟合现象。 将预测得到的实验结果应用到测试数据集上得到结果, 并提交到kaggle上进行测试，发现自己写了个:shit:，baseline的score是8.7377, 注意这里的score是越底越好 所以必须对上述的模型进行调优 欠拟合从上面的loss曲线图可以看出来，loss曲线还在下降中，并没有收敛。因此可以尝试增大epoch，增大训练的轮数，直到最后完全收敛。 最后当epoch设置为1000的时候看到loss曲线有明显得到收敛。 再次在kaggle上提交答案，发现结果如下:cry: 虽然对比baseline来说，我的模型依然和:shit:一样，但是至少score降低了不少, 接着慢慢调试吧 使用adagrad算法来更新学习率之前所有的训练使用的学习率都是固定不变的，在前期的时候可能loss的最低值可能距离起点位置比较远，使用较大的学习率没有什么问题，但是到后面如果学校率还是很大的话就有可能导致错过loss的最低值点，因此要使用adagrad算法来更新学习率。 下面是adagrad算法的推导过程: 普通的梯度下降过程为： w ^ { t + 1 } \leftarrow w ^ { t } - p ^ { t } g ^ { t } \\ \eta ^ { t } = \frac { \eta ^ { t } } { \sqrt { t + 1 } }普通学习率是固定的，要想让学习率逐步变小的话，一个最直接的办法就是让学习率除以迭代次数的1/2次方，这样当迭代次数特别大之后，学习率也会不断减小。基于这种想法，我们调整我们代码中的学习率。 1learningRate = learningRate / np.sqrt(e + 1) 发现结果好像炸了呀:cry:, 看来事情并没有现象的那么简单。不能所有的参数都简单粗暴的直接减小，要根据不同参数给出不同的应对方案。所以才去的办法是每个参数的学习率除以之前微分的均方根。 w ^ { t + 1 } \leftarrow w ^ { t } - \frac { n ^ { t } } { \sigma ^ { t } } g ^ { t } \\ g ^ { t } = \frac { \partial L ( \theta ^ { t } ) } { \partial w } $\sigma ^ t$： 表示之前参数的所有微分的均方根，对于每个参数都是不一样的。 \sigma ^ t = \sqrt {\frac {1}{t+1}\sum_{i=0}^{t}(g^i)^2}随意最终版本的adagrad算法中参数的更新公示如下： w^{t+1} \leftarrow w^t - \frac{\eta}{\sqrt {\sum_{i=0}^t(g^i)^2}} g ^t123gradient = 2 * np.dot(TrainData_.transpose(), np.dot(TrainData_, W) - TrainLabel)adagrad += gradient ** 2W = W - learningRate * gradient / np.sqrt(adagrad + 1e-10) 上面的代码就是实现adagrad的核心代码。 使用adagrad之后，loss收敛的就特别快]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>深度学习作业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas玩转数据透视表]]></title>
    <url>%2Fsunpages%2F2020%2F07%2F04%2F2020-07-04-Pandas%E7%8E%A9%E8%BD%AC%E6%95%B0%E6%8D%AE%E9%80%8F%E8%A7%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[Pandas 玩转数据透视表 本文以kaggle比赛Predict Future Sales为中的数据为例介绍pandas中数据透视表的使用。 透视表本来是一种对数据进行动态排布和分类汇总的表。大多数人可能在使用Excel的过程中听说过这个概念。相对于Excel中可视化的操作，Pandas提供的是一个与Excel功能类似的制作透视表的API，只不过将可视化的操作换成了Python程序操作。 数据介绍本次使用到的数据集是kaggle比赛Predict Future Sales中提供的数据集。主要要处理的是其中名为sales_trains.csv的训练数据，该数据记录了一些俄罗斯一些商铺在2013年到2015年间的销售数据，原始的训练数据如下图所示： 123import pandas as pdsale_data = pd.read_csv('../data/sales_train.csv')sales_data.head() 其中有6个字段，分别是： date: 货物销售日期 date_block_num: 连续的月份编号，第一个月为0，最后一个月为33 shop_id: 商店编号 item_id: 货物编号 item_price: 货物价格 item_cnt_day: 货物销售量 可以看到原始的数据集中销售数据是凌乱的。对题目分析后需要将同一个商店的同一种货物在每个月份（0到33之间）的销售总量给统计出来。这个时候使用Pandas提供的透视表API就显得极为简单。 pivot_table函数介绍Pandas给出的文档如下所示： pivot_table函数中最关键的四个函数分别是：index, values, columns, aggfunc这里主要介绍其中最重要的四个参数的用法，其他参数可以使用python内置函数help直接查看该函数的说明文档。 index参数index参数必须指定，用于设定将原始的DataFrame中某一列或者某些列作为透视表的index，类似数据库sql语句中的group by后面接的字段。index需要传入一个列表，列表中的每个元素必须是原始的DataFrame中的列名。 12sale_data_index = sale_data.pivot_table(index=['shop_id'])sale_data_index.head() 可以看到，当使用shop_id作为索引group by之后，原始零散的销售数据现在按照商铺编号聚集在一起，和group by不同的是，同一个shop_id的数据不是简单的聚集在一起显示，而是所有shop_id相同的数据给合并。和并的规则就是同一个index，也就是shop_id所确定的所有数据的同一字段(例如date_block_num, item_cnt_day, item_id, item_price)都按照aggfunc给定的函数计算。在aggfunc没有指定函数的时候，默认计算其平均值。所以上图中第一行看到的item_price为563.4就是所有shop_id的销售数据的item_price的平均值。 index参数也可以给定多个值，使用多个字段作为透视表的index，透视表按照index中字段出现的先手顺序分级进行group by 12sale_data_indexs = sale_data.pivot_table(index=['shop_id', 'item_id'])sale_data_indexs.head() 如上图所示，当index有多个值的时候，透视表会进行分级聚集。首先第一季是shop_id为0的销售数据，第二级是item_id为30的销售数据，由于item_id为最后一级，最细的粒度为item_id，每一行表示同一个shop_id下同一个item_id的所有数据的各个字段的平均值。 values参数在介绍index参数的时候可以看到，当对item_cnt_day（销量）和item_price（售价）求平均值是有意义的，但是对日期求均值就没有意义了，所以可以通过values参数指定透视表中保留那些字段的值。 12sale_data_value = sale_data.pivot_table(index = ['shop_id', 'item_id'],values = ['item_price','item_cnt_day'])sale_data_value.head() 不同于index参数的是，index参数必须指定，而values参数可以缺省，缺省时values默认会保留所有字段。 aggfunc参数上述所有例子中，当数据按照某个index聚集之后，同一个index的数据会按照aggfunc指定的函数进行计算，aggfunc同样也是一个非必须参数，当没有指定参数的时候默认计算平均值。而本题目中明显需要计算同一个shop_id和同一个item_id的销售量的综合，所以需要使用求和函数。 123sale_data_agg = sale_data.pivot_table(index = ['shop_id', 'item_id'],\ values = ['item_price','item_cnt_day'],aggfunc=[np.sum,np.mean])sale_data_agg.head() 需要注意的是aggfunc使用字符串传入python内置函数名，也可以直接传入函数对象，并且可以使用列表传入多个函数，如下所示： 123sale_data_agg = sale_data.pivot_table(index = ['shop_id', 'item_id'],\ values = ['item_price','item_cnt_day'],aggfunc=[np.sum,np.mean])sale_data_agg.head() columns参数columns参数可以说是最不好理解的一个参数。如果我现在的需求是统计每个shop_id和item_id确定的销售数据中，每个月份的销售量。可能很多人会在index参数中再加一个date_block_num,如下所示： 123sale_data_columns = sale_data.pivot_table(index = ['shop_id', 'item_id','date_block_num'],\ values = ['item_cnt_day'],aggfunc=[np.sum])sale_data_columns.head() 虽然也能达到相同的效果，但是对于有些商品在有些月份没有销售数据的时候，透视表中就不会出现对应的数据，并且竖向排列显得十分不直观。这时候就可以使用columns参数。指定某个字段，按照类似index的方式进行聚集，只是聚集的结果不是作为行标index，而是作为列标。 123sale_data_columns = sale_data.pivot_table(index = ['shop_id', 'item_id'],values = ['item_cnt_day'],\ aggfunc=[np.sum],columns=['date_block_num'])sale_data_columns.head() 这样同一个ship_id和item_id的所有数据就按照月份聚集好了。只是由于很多月份没有销售数据，导致透视表中出现了很多NaN,所以需要用最后一个参数去除这些NaN。 最后使用fill_value参数指定使用某个值填充NaN 123sale_data_columns = sale_data.pivot_table(index = ['shop_id', 'item_id'],values = ['item_cnt_day'],\ aggfunc=[np.sum],columns=['date_block_num'],fill_value=0)sale_data_columns.head() 至此，你已经可以愉快的使用pivot_table函数制作各种各样的数据透视表了。原来可能要写几十行的代码才能达到这种效果，现在只要一行代码就可以完成。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 新手入门教程之增删改查]]></title>
    <url>%2Fsunpages%2F2020%2F02%2F13%2Fvim-learn1%2F</url>
    <content type="text"><![CDATA[vim 新手入门教程一: 增删改查​ 对于任何一个编辑器来说，对文本所做的操作无非就是增删改查这四种操作，但是由于vim里面的命令众多，学习成本较高，这样就劝退了很多新手，本篇博客将从增删改查四个操作来介绍一下如何入门vim。 一、添加操作​ vim有两种模式，一种是normal模式（命令模式），一种是insert模式（插入模式）。只有在命令模式下，所有的下面介绍的所有命令才会起作用，而插入模式下，键盘敲入的每个字符都会写入文本中。辨别vim是命令模式还是插入模式的方法很简单，插入模式的时候vim的底部有insert的字样，而什么都没有的时候表示处于命令模式。 ​ 当我们插入字符的时候，就需要从命令模式转为插入模式，在vim中从命令模式转为插入模式有三个命令，他们分别的作用如下表所示，区分大小写的话共有六种方式。 命令 作用 联想记忆 i 向当前字符前面一个字符插入 insert I 在当前行的行首插入 —- a 向当前字符后面一个字符插入 append A 在当前行的行尾插入 —- o 想当前字符下面一行插入 open a new line O 向当前行的上一行插入 —- 二、删除操作​ vim里面关于删除的操作命令十分的简单，只有两个，一个是x，他们的区别如下： x : 相当于不及物动词，后面不需要跟文本对象，按一下x直接删除贯标对应的字符，前面可以加上数字表示删除的字符的个数，比如说4x表示删除4个字符。 d: 相当于及物动词，一个单独的d事没有办法删除东西的，d的后面必须跟着一下文本对象，下面介绍一下vim中的各个文本对象的概念 命令 文本对象 示例 w 下一个单词开始 dw从当前删除到下一个单词 e 本单词的结尾 de表示删除到这个单词的结尾 b 上一个单词的开始 db删除到上一个单词 $ 行尾 d$表示从光标删除到行尾 0 行首 d0表示从光标删除到行首 gg 文件首 dgg表示从光标删除到文件首 G 文件结尾 dG表示从光标删除到文件结尾 另外还有以下特殊的操作： 命令 含义 dd 删除当前行 dt + [任意字符] 删除到[任意字符]处 三、修改操作在vim涉及到修改文本的目录有三个，一个是c（change），一个是r（replace）,他们分别的含义和作用如下： 命令 含义 注 c 修改 不及物 r 替换 替换完成之后依然处于命令模式 s 删除当前字符 删除之后进入插入模式 S 删除当前行 删除之后进入插入模式 对于修改操作，使用做多的还是c命令，c命令后面可以加上不同的文本对象实现不同的修改，具体用法如下： 命令 含义 cw 修改一个单词 c$ 修改到行尾 c0 修改到行首 cgg 修改到文件首 cG 修改到文件尾 Ct [任意字符] 修改到任意字符 ci [成对出现的字符] 修改成对出的字符内部的内容 c i [成对出现的字符]：这个命令里面相当于不及物动词后面加上一个介词i，然后在跟上字符（宾语），例如： ci + “(“: 修改小括号内部的内容 ci + “[“: 修改中括号内部的内容 ci + “: 表示修改引号内部的内容 四、查找操作vim中的查找操作的命令是/，在命令模式中输入反斜杠之后可以查找，查找完成之后n表示下一个匹配对象，N跳转到上一个匹配对象。 ​ 当然编辑文本的过程中还有一个操作就是所有替换，vim也支持搜索替换。 1: %查找范围s/查找文本/替换文本/替换标志]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何配置一个顺手vim系列（一）：安装插件]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F27%2Fvim%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[如何配置一个顺手vim系列（一）：安装插件 个人由于在服务器上进行科研和开发工作，所以使用vim比较多，这里简单记录一下自己配置vim的过程 对于任何一个Linux玩家来说，vim都不可避免，其许多看似反人类的设计，其实背后都有原因。虽然前期的学习曲线比较高，但是一旦使用熟练之后，其开发和编辑的效率完全能和各种现代的编辑器媲美甚至更胜一筹，并且由于其打开速度快，线上开发方便等优点而深受程序员喜爱，下面就结合我自己的vim配置介绍一下。 一、安装插件管理器:vim-plugvim-plug是一款优秀的插件管理器，其安装十分简单,命令如下: 12curl -fLo ~/.vim/autoload/plug.vim --create-dirs \ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 二、安装插件在home目录下的.vimrc文件中添加如下配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192set nocompatible " be iMproved, requiredfiletype off " requiredset backspace=2" 插件管理set rtp+=~/.vim/bundle/Vundle.vimcall plug#begin()" Plug 'VundleVim/Vundle.vim'Plug 'python-mode/python-mode', &#123; 'branch': 'develop' &#125;" Plug 'davidhalter/jedi-vim'Plug 'tpope/vim-surround'Plug 'majutsushi/tagbar'" Plug 'w0rp/ale'Plug 'mhinz/vim-startify'Plug 'ervandew/supertab'Plug 'python-mode/python-mode'Plug 'scrooloose/nerdcommenter'Plug 'kien/ctrlp.vim'Plug 'scrooloose/nerdtree'Plug 'vim-scripts/taglist.vim'Plug 'vim-scripts/The-NERD-Commenter'" Plug 'junegunn/vim-easy-align'Plug 'easymotion/vim-easymotion'Plug 'vim-scripts/winmanager'Plug 'tomasr/molokai'Plug 'vim-airline/vim-airline'Plug 'vim-airline/vim-airline-themes'Plug 'Yggdroot/indentLine'Plug 'Xuyuanp/nerdtree-git-plugin'Plug 'sbdchd/neoformat'" Plug 'Chiel92/vim-autoformat'" Plug 'lyokha/vim-xkbswitch'call plug#end() " requiredfiletype plugin indent on " required"基础配置let mapleader=','let g:indentLine_enabled = 1color desert "颜色设置syntax on "语法高亮set number "自动显示行号set cursorline "突出显示当前行set ts=4 "设置tab长度为4set shiftwidth=4 "设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4"解决中文编码乱码let &amp;termencoding=&amp;encodingset fileencodings=utf-8,gbk let g:NERDSpaceDelims=1 " 注释后面自动加空格"set clipboard=unnamed" python-mode 配置let g:pymode_python = 'python3' "设置pyhton3模式let g:pymode_trim_withespaces = 1 " 保存是删除多于空格let g:pymode_doc = 0 "" let g:pymode_doc_bind = 'K' "" let g:pymode_rope_completion = 1" let g:pymode_rope_complete_on_dot = 1" let g:pymode_rope_completion_bind = '&lt;C-Tab&gt;'" let g:pymode_indent = 1 时候用pep8风格的缩进let g:pymode_folding = 1let g:pymode_run_bind = '&lt;leader&gt;r'" let g:pymode_motion = 1let g:pymode_rope_goto_definition_bind = "&lt;C-]&gt;"let g:pymode_options_max_line_length = 140" let g:pymode_lint_on_write = 1" let g:pymode_lint_checkers = ['pyflakes','pep8']let g:pymode_rope_completion = 1let g:pymode_rope_complete_on_dot = 1let g:pymode_rope_completion_bind = '&lt;C-Tab&gt;'" let g:pymode_lint_error_symbol = 'EE'" nerdtree配置nmap ,v :NERDTreeFind&lt;cr&gt;nmap ,g :NERDTreeToggle&lt;cr&gt;let NERDTreeShowHidden=1let NERDTreeIgnore = [ \ '\.git$', '\.hg$', '\.svn$', '\.stversions$', '\.pyc$', '\.pyo$', '\.svn$', '\.swp$', \ '\.DS_Store$', '\.sass-cache$', '__pycache__$', '\.egg-info$', '\.ropeproject$', \ ]nnoremap &lt;leader&gt;t : TagbarToggle&lt;CR&gt;" ale 配置let g:ale_sign_error = '✗'let g:ale_linters = &#123;'python': []&#125;"easy-align配置" xmap ga &lt;Plug&gt;(EasyAlign)" nmap ga &lt;Plug&gt;(EasyAlign) 之后在vim中运行:PlugInstalll即可 三、插件介绍与配置3.1 pyhton开发神器：python-mode12345678910111213141516" python-mode 配置 let g:pymode_python = 'python3' "设置pyhton3模式 let g:pymode_trim_withespaces = 1 " 保存是删除多于空格 " let g:pymode_doc = 0 " " let g:pymode_doc_bind = 'K' "let g:pymode_rope_completion = 1let g:pymode_rope_complete_on_dot = 0let g:pymode_rope_completion_bind = '&lt;C-Tab&gt;'" " let g:pymode_indent = 1 时候用pep8风格的缩进" " let g:pymode_motion = 1 let g:pymode_lint = 1 let g:pymode_rope_goto_definition_bind = "&lt;C-]&gt;" let g:pymode_options_max_line_length = 120" " let g:pymode_lint_on_write = 0 let g:pymode_lint_checkers = ['pyflakes','pep8'] let g:pymode_folding = 1 上面的配置是python-mode中的一些配置，包括补全，缩进，折叠 折叠相关快捷键： 快捷键 作用 zo 展开当前函数 zc 折叠当前函数 zn 展开所有函数 zN 折叠所有函数 3.2 文件管理插件：Nerd-tree12345678 " nerdtree配置 nmap ,v :NERDTreeFind&lt;cr&gt; nmap ,g :NERDTreeToggle&lt;cr&gt; let NERDTreeShowHidden=1let NERDTreeIgnore = [ \ '\.git$', '\.hg$', '\.svn$', '\.stversions$', '\.pyc$', '\.pyo$', '\.svn$', '\.swp$', \ '\.DS_Store$', '\.sass-cache$', '__pycache__$', '\.egg-info$', '\.ropeproject$', \ ]]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文复现实验思路-数据预处理（二）]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F20%2F18tmc3%2F</url>
    <content type="text"><![CDATA[继续数据预处理工作，在缓慢的批流工作进行了将近三天之后，完成了三个原始数据样本（不到2G）的数据的批流，进行完批流得到的是一个flow一个pcap文件，接下来需要做的工作就是通过python的Scapy库逐个读取flow，统计所需的统计属性 12345import numpy as npimport pandas as pdfrom scapy.all import *import osfrom config import * 上面是导入的库 一、获取所有的flow路径1234567891011def GetPathList(data_path): ''' 获取流文件的路径信息 ''' try: flow_path_list = [data_root_path + x for x in os.listdir(data_root_path)] flow_path_list = sorted(flow_path_list,key= lambda x: int(x.split('/')[-1].split('.')[-2])) return flow_path_list except: print("GetPathList Error!") return [] 这个函数没有什么太多好讲的，只是有两点技巧说一下： 列表生成表达式：在第6行使用列表生成表达式的形式生成列表，[含x表达式 for x in 列表] lambda表达式 ：在 排序等函数中，可以 通过lambda表达式指定排序的关键字，即通过元素的那一部分进行排序 二、加载flow并得到统计数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960def LoadOnePcap(flow_path): ''' 加载一个flow的pcap文件，计算需要的统计数据 ''' packets = rdpcap(flow_path) Volume = 0 # 数据总量 Duration = 0 # 持续时间 for packet in packets: Volume += len(packets) StartTime = packets[0].time #开始时间 EndTime = packets[-1].time #结束时间 Duration = EndTime - StartTime if Duration &gt; 0: Rate = Volume / Duration else: Rate = 0 # sleep time通过连续的两个flow之间的时间计算，不在这个函数中计算 # DNS 变量用于存储dns查询,DNS_FLAG 表示是否含有DNS DNSQuery = '' DNS_FLAG = False NTPQuery = '' NTP_FLAG = False # 下面的这个循环遍历整个flow查找是否含有DNS查询 for packet in packets: if packet.haslayer('DNS'): DNS_FLAG = True if packet.haslayer('NTP'): NTP_FLAG = True ## 获取DNS查询的域名 if DNS_FLAG: DNSQuery = bytes.decode(packets[0]['DNS'].qd.qname) if NTP_FLAG: NTPQuery = packets[0]['UDP'].id # 下面几行处理得到远程端口号 TCP_FLAG = packets[0].haslayer('TCP') UDP_FLAG = packets[0].haslayer('UDP') if TCP_FLAG: TransPro = 'TCP' elif UDP_FLAG: TransPro = 'UDP' RemotePort = packets[0][TransPro].dport # 下面一行得到mac地址 Mac = packets[0]['Ethernet'].src flow_features = &#123; 'Volume': Volume, 'StartTime':StartTime, 'EndTime':EndTime, 'Duration':Duration, 'Rate':Rate, 'DNSQuery':DNSQuery, 'NTPQuery':NTPQuery, 'RemotePort':RemotePort, 'TransPro':TransPro, 'Mac':Mac &#125; print('%s文件夹中,第%s个flow分析完毕！'%(flow_path.split('/')[-2],flow_path.split('/')[-1].split('.')[-2])) print(flow_features) return flow_features 通过上面的代码可以分析出，其实逻辑很简单，从每个flow中提取出10个值，有的直接值特征值，有一些是为了以后计算特征值而提取的中间值，每个值的含义如下： 变量名 含义 计算方法 Volume flow的数据大小 累加整个flow的所有数据包 StartTime flow的起始时间 第一个packet的time EndTime flow的结束时间 最后一个packet的time Duration flow的持续时间 结束时间减去其实时间 Rate flow的平均速率 数据量除以持续时间 DNSQuery DNS查询字段 如果有DNS查询，找到对应包的DNS查询 NTPQuery NTP查询字段 如果有NTP查询，找到对应包的NTP查询 RemotePort 远程端口 第一个packet的目的端口号 TransPro 协议类型 协议类型是flow五元组的组成之一 Mac flow本端的Mac地址 第一个packet的源Mac 将上述所有的值提取出来之后保存在字典中传出即可]]></content>
      <categories>
        <category>学习科研</category>
      </categories>
      <tags>
        <tag>流量</tag>
        <tag>python</tag>
        <tag>Scapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文复现实验思路-数据预处理（一）]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F19%2F18tmc2%2F</url>
    <content type="text"><![CDATA[最近阅读完论文《Classifying IoT Devices in Smart Environments Using Network Traffic Characteristics》，在复现的过程中出现了很多问题，现对于自己的复现过程和一下思考进行一下记录 一、批流由于论文中机器学习算法使用的特征值都是在flow意义上的统计信息，而不是单纯的packet的信息，例如流的大小，流的持续时间、流的平均速率等，所以必须要将杂乱无章的数据包按照一个一个flow分开，然后对于每个flow进行统计，计算这个flow的统计信息。 1.1 flow的理解这里想 补充说一下flow的意义，关于这个概念我查了一些 资料，目前感觉最准确的说法就是五元组（源ip、源端口、目的ip、目的端口、传输层协议类型 ）一致的数据包是属于一个flow。我理解的flow即流的 含义就是两个主机一段时间之内的完整通信流程（可能不准确），在wireshark上进行了相关实验，得到了 一定的验证。 wireshark上提取一个flow的过滤关键字是tcp.stream == [seq],这里的tcp可以换成udp表示过滤udp流 通过上图可以看出，同一个flow中的五元组是一致的，只是这是双向的，就是源和目的主机的ip和端口是可以对调的。 再利用wireshark画出flow图，可以得到如下的结果： 通过flow图看出来，一个flow应该就是一次通信过程的所有的数据包。 1.2 批流处理Scapy处理在批流的过程中尝试了两种方法，首先是通过python的Scapy库对pcap进行解析，之后按照五元组进行批流,但是这样处理会出现很多 问题 。问题记录 如下： 使用rdpcap函数读取pcap文件，十分占用内存 ，读取 90M左右的pcap文件占用将近2-3G内存，并且读取速度 十分缓慢，不易于操作（虽然后来发现PcapReader函数读取速度上来了，但是之后的问题还是没办法解决） Scapy库对数据包的解析不完整，有些协议解析不出来，比如出现以下的情况，IP层之后直接就是Raw载荷了，猜想这里的raw数据是其他协议层 的数据，只是scapy没有解析出来 由于出现了以上的问题，导致后来就没有按照这种方法进行 下去，而是采用tshark的方法 Tshark处理在经过导师的指点之后发现用tshark的处理效率很高。就开始使用tshark处理，tshark是wireshark的命令行版本，拥有wireshark的大部分功能，能用相关的过滤规则直接进行批流，下面是进行批流的脚本 123456789101112131415161718192021222324#! /bin/bashfind ./rawpcap -name '*.pcap' &gt; pcapfilename.txtwhile read line do echo "$(line)" filedir=$(echo "$(line)" | awk -F '/' '&#123;print $3&#125;' | awk -F '.' '&#123;print $1&#125;') echo $filedir dir="./streampcap/"$&#123;filedir&#125; mkdir -p $dir tshark -r $line -T fields -e tcp.stream | sort -n | uniq -c | awk -F ' ' '&#123;if ($2&gt;=0)print $2 &#125;' &gt; tcp_stream_number.txt while read tcpnumber do stream=`tshark -r $line -Y "tcp.stream eq $(($tcpnumber)) " -w$dir/$tcpnumber.pcap` if [ ! $stream ] then echo "IS NULL" else echo $stream fi done &lt;tcp_stream_number.txtdone &lt; pcapfilename.txt 脚本的仔细解释在我的另一篇博客《shell编程一》里面已经详细介绍过，所以不再仔细赘述，这里主要介绍一下其中关于tshark的几个命令 获取所有的流号 1tshark -r $line -T fields -e tcp.stream | sort -n | uniq -c | awk -F ' ' '&#123;if ($2&gt;=0)print $2 &#125;' &gt; tcp_stream_number.txt tshark的-e 参数打印指定的字段，之后经过排序，去重，分割等操作得到流号保存在txt文件中 批流，每一个flow保存为对应流号的pcap文件 1tshark -r $line -Y "tcp.stream eq $(($tcpnumber)) " -w$dir/$tcpnumber.pcap 这样就将所有的pcap文件中的tcp flow提取出来了，之后在进行udp流的提取就可以了。 二、目前为止出现的一些问题 原始数据中除了tcp flow和udp flow之外还有一些arp 、icmp、igmp之类的报文信息，这些信息感觉上是没有flow概念的，因为都没有五元组的概念，所以这些报文是不是需要丢弃目前暂时只提取tcp和udp flow 批流完成之后需要对flow文件进行读取，统计flow的信息 ，包括flow 大小、flow持续时间、flow速率和sleep time，这里的这个sleep time不知道是如何处理的，由于在批流的过程中都不是按照时间顺序的，所以flow文件的序号并不是按照时间顺序排列的，所以无法通过前后两个flow的数据包的相对时间来计算sleep time，目前的想法是按照每个flow的起始时间进行排序。之后用每个flow的后后一个flow之间的时间差算作sleep time，这样的话就要将tcp和udp整理在一起排序。 整理完所有的flow之后，会发现tcp flow中没有dns 和ntp的查询，所以这两个特征为空，怎么解决空值问题，目前的想法是将所有的空值都归为一类]]></content>
      <categories>
        <category>学习科研</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>IoT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell编程（一）]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F18%2Ftshark%2F</url>
    <content type="text"><![CDATA[最近由于需要在Linux中处理大量的网路数据，没有可视化的wireshark可用，转而时候命令行版本的tshark，但是用于在命令行中运行，当数据量巨大的时候操作繁杂，所以写了一个小脚本自动化运行，记录一下自己从零开始学shell编程的过程 脚本功能 统计每个pcap文件中的tcp流号 将每个pcap文件中的所有数据包按照同一个flow分开，每一个flow保存为一个pcap文件，即批流 由于批流之后的小文件特别多，所以注意命名和文件的存放管理 脚本编写过程概览123456789101112131415161718192021222324#! /bin/bashfind ./rawpcap -name '*.pcap' &gt; pcapfilename.txtwhile read line do echo "$(line)" filedir=$(echo "$(line)" | awk -F '/' '&#123;print $3&#125;' | awk -F '.' '&#123;print $1&#125;') echo $filedir dir="./streampcap/"$&#123;filedir&#125; mkdir -p $dir tshark -r $line -T fields -e tcp.stream | sort -n | uniq -c | awk -F ' ' '&#123;if ($2&gt;=0)print $2 &#125;' &gt; tcp_stream_number.txt while read tcpnumber do stream=`tshark -r $line -Y "tcp.stream eq $(($tcpnumber)) " -w$dir/$tcpnumber.pcap` if [ ! $stream ] then echo "IS NULL" else echo $stream fi done &lt;tcp_stream_number.txtdone &lt; pcapfilename.txt 语法解读 找到所有pcap文件并将文件路径保存到pcapfilename.txt文件中 1find ./rawpcap -name '*.pcap' &gt; pcapfilename.txt find命令后接两个参数，第一个参数./rawpcap表示查找的路径，-name指定按照给定的名称格式查找，使用正则表达式匹配所有pcap结尾的文件 通过重定向符&gt;将find 的结果输出到pacpfilename.txt中 逐行读取文本文件pcpafilename.txt 123456while read line do ... ... ...done &lt; pcapfilename.txt 上面这种结构是shell脚本中逐行读取文本文件的标准格式 line是读取文本文件中每一行的值的变量，后面对line进行操作 done &lt;后面的文件名是要读取的文件名 Linux三剑客之一awk的简单使用方法 1echo "$(line)" | awk -F '/' '&#123;print $3&#125;' | awk -F '.' '&#123;print $1&#125;' 利用管道符将echo的输出结果向后传递，之后类似 awk命令的 -F 参数指定分隔符 后面第二个参数的用法&#39;{字符串1 字符串2}&#39;其中字符串1 指定命令，上面用的是print表示输出，第二个字符串是$2表示输出分割之后的第二部分（从1开始数） 将某一行命令的运行结果传送给某个变量 1filedir=$(echo "$(line)" | awk -F '/' '&#123;print $3&#125;' | awk -F '.' '&#123;print $1&#125;') 使用$()格式，括号中的内容是要运行的命令 shell脚本中两个字符串的连接 1dir="./streampcap/"$&#123;filedir&#125; 如上所示，直接将两个字符串放一起，不要空格就行 tshark的使用 1tshark -r $line -T fields -e tcp.stream | sort -n | uniq -c | awk -F ' ' '&#123;if ($2&gt;=0)print $2 &#125;' &gt; tcp_stream_number.txt -r 参数指定输入文件 -e 指定输出字段 sort -n排序 uniq -c去重 if判定语句格式 123456if [ 逻辑表达式 ]then ...else ...fi 脚本解读 第3行找到./rawpcap文件夹中所有的pcap文件，并将文件所在路径名存放在pcapfilename.txt中 第4-24行的大循环逐行遍历文件pcapfilename.txt，将每一行的内容读取到变量line中 第6-10行通过awk工具找到路径中需要的部分路径名（除了文件名之外的路径名），保存在变量中，并相应穿件对应的文件夹用于存放批流之后的流文件 第11行通过tshark遍历line变量所指向的pcap文件，提取出所有的flow号，保存在tcp_stream_number.txt中 第12-22行的小循环遍历每一个flow号，将其保存在tcpnumber变量中 第14行用tshark进行批流处理，从line指向的文件中提取出所有flow号为tcpnumber的所有数据包保存为名称为tcpnumber的pcap文件]]></content>
      <categories>
        <category>学习科研</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python scapy库分析pcap流量文件]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F17%2Fscapy%2F</url>
    <content type="text"><![CDATA[安装并导入12pip install scapyfrom scapy.all import * 使用读取pcap文件1packets = rdpcap('../../IoT/pcaps/16-09-23.pcap')]]></content>
      <categories>
        <category>学习科研</category>
      </categories>
      <tags>
        <tag>网络流量</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对论文《Classifying IoT Devices in Smart Environments Using Network Traffic Characteristics》的翻译]]></title>
    <url>%2Fsunpages%2F2019%2F09%2F12%2F18tmc%2F</url>
    <content type="text"><![CDATA[摘要物联网被誉为社会的下一个发展浪潮，智能家居、企业和城市装备着大量的物联网设备，然而这些智能环境的控制者并没有充分意识到这些物联网设备的价值，更不用说能否让这些设备抵御网络攻击了。在这片论文中，我们通过使用在网络级获得的流量特性开发用于物联网设备的强大的（robust）框架来应对（address）这个挑战。我们的工作主要分为四个部分。首先，我们搭建了一个拥有28个不同IoT设备的的智能环境，这些IoT设备包括监控摄像头、灯、插座、传感器以及健康监控传感器，我们从这些基础环境中收集并整合长达6个月的网络流量，这些流量的一个子集将会被公开用于开源社区研究；第二，我们使用统计属性对底层网络流量特性提供了一些见解，这些统计属性包括活动周期、端口号、信号模式和加密模式;第三，我们开发了一个基于分类算法的多级机器学习模型（multi-stage machine）并且演示（demonstrate ）它在区分具体的IoT设备的能力，基于他们的网络活动准确率超过99%；最后我们讨论了成本、速度之间的权衡（trade-offs）和应用于真实网络的表现。我们的研究推动了智能环境管理者监控他的IoT设备的表现、功能和网络安全性的方式，而不需要任何特殊设备和协议。 介绍联网设备的数量正在急剧膨胀（balloon）,迎来（ushering）物联网的时代。物联网（IoT）指的是数以亿计的低功耗设备与设备之间或与远端的服务器之间在互联网上自主（autonomously）的通信。IoT设备包括每天都在使用的物品，例如台灯、照相机、传感器、门锁、温控器（thermostats）、电源开源和家用电器，这些出货量已经达到了接近200亿在2020年。无数的IoT设备期待找到它们未来在家庭、企业、校园、城市中的方式，创造（engender）有利于我们社会和生活的智能环境。 IoT设备的数量增长的很快，然而带来了一个重要的问题。智能环境的管理者发现很难去确定哪些设备连接了他们的网络，更加难以探知（ascertain）每个设备是否工作正常，这是一个组织管理这些资产的主要任务，往往需要几个不同的部门合作。举例来说，在一个地区委员会（council）来说，灯管传感器可能由基础设施团队安装、污水和垃圾传感器可能被卫生部门（sanitation department）安装、求生摄像头可能被地区机房管理，协调各部门以获取IoT设备的信息不仅耗时繁重而且错误率高，使得在任何时候用弄清楚哪些IoT设备正在运行成为不可能。及时获得IoT设备的可见性对于管理者来说至关重要。那些负责确保设备的网络安全任务的人员需要提供必要的服务质量、并在出现问题的时候迅速隔离.思科最近的安全报告一直在强调（emphasize）可见性的重要性，特别是最近出现的两件事显得尤为突出。2017年7月组成赌场的鱼缸传感器和2017年2月从自己的自动售货机攻击大学校园网。这两个例子中，网络分段都有可能阻止攻击，更好的可见性可以快速隔离，以限制网络攻击对企业网络的破坏 可以预期，可以通过其MAC地址和DHCP协商来识别设备。然而，这将面临几个挑战：首先IoT设备制造商通常使用第三方提供的NIC（网卡），因此，MAC地址的组织唯一标识符（OUI）前缀可能无法传达有关IoT设备的任何信息；其次，恶意设备可能会欺骗MAC地址;许多物联网设备不在其DHCP请求中设置主机名选项；事实上，我们发现我们研究的大约一半的物联网设备没有显示它们的主机名，如表1所示; 即使物联网设备暴露其主机名，它也可能并不总是有意义的（例如表1中的Withings婴儿监视器的WBP-EE4C）；最后，用户可以更改这些主机名（例如HP打印机可以被赋予任意主机名）。由于这些原因，基于DHCP并不是一个很好的解决方案用于正确识别大规模的设备。 这篇论文中，我们通过开发一个强大的框架来解决上述问题，该框架除了使用网络流量特征导出的统计属性的高精度的一类非物联网设备外，还对每个物联网设备进行分类，从定性上讲，大多数物联网设备都会偶尔发送短时间的数据。定量的来说，我们在[6]中的初步工作是首次尝试研究IoT设备在一次流量爆发期间发送多少流量以及它们在活动之间闲置多长时间。我们还评估了它们执行了多少信号量（例如域名查询使用DNS，时间同步使用NTP）与他们产生的数据流量进行比较。本文通过对包含28种不同物联网设备的试验台在更长时间（6个月）内捕获的跟踪数据采用更全面（comprehensive）的属性集，对我们之前的工作进行了重大扩展。 毫无疑问，了解物联网流量的性质变得越来越重要，这样做有助于包含不必要的多播/广播流量，从而减少它们对其他应用程序的影响，它还使智能城市和企业的运营商能够根据环境，健康或安全应用所需的可靠性，损失和延迟来确定其网络的适当性能水平。然而，表征物联网流量的最令人信服的理由是检测和减轻网络安全攻击。众所周知，物联网设备的性质和设计易于渗透，关于物联网设备如何被破坏并用于发动大规模攻击的新故事正在出现.物联网设备的巨大异构性促使研究人员提出网络级安全机制，分析流量模式以识别攻击,这些方法的成功依赖于对“正常”物联网流量配置文件的良好理解。 我们在这项工作中的主要重点是建立一个基于各种网络流量特性的机器学习框架，以识别和分类网络上物联网设备的默认（即基线）行为,未来可能会使用这样的框架来检测物联网设备的异常行为（可能是由于网络攻击）,这种异常检测方案超出了本文的范围。本文基于网络流量特征填补了与物联网设备分类相关的文献中的重要空白。我们的贡献是： 我们使用28个IoT设备搭建了一个实验室，以实现智能环境。这些设备包括相机，灯，插头，运动传感器，电器和健康监视器。我们从这种环境中收集和综合数据，为期6个月。我们的数据子集可供研究社区使用。 我们确定关键的统计属性，如活动周期，端口号，信令模式和密码套件，并使用它们来深入了解基础网络流量特征 我们开发了一种基于多阶段机器学习的分类算法，并证明了它能够根据网络行为识别具有超过99％精度的特定物联网设备 我们通过检查分类器的成本，速度和准确性之间的权衡来实时评估分类框架的部署。 本文的其余部分安排如下：§2描述了相关的先前工作。我们在§3中介绍了IoT设置和数据跟踪，并在§4中描述了各种IoT设备的流量属性。在§5中，我们提出了基于机器学习的多阶段设备分类方法并评估其性能，然后在§6中讨论了所提出的系统的实时操作。该论文在§7中得出结论。 相关工作有大量的工作表征一般的互联网流量。这些先前的工作主要集中在应用程序检测（例如Web浏览，游戏，邮件，Skype VoIP，点对点等）。然而，专注于表征物联网流量（也称为机器对机器或M2M流量）的研究仍处于起步阶段。 实证痕迹分析:[20]中的工作是第一次深入研究M2M流量性质的大规模研究之一。需要了解M2M流量是否对蜂窝网络的设计和管理提出了新的挑战.该工作使用跨越一级蜂窝网络运营商一周的流量跟踪，并将M2M流量与传统智能手机流量从多个不同角度进行比较 - 时间变化，移动性，网络性能等。该研究通知网络运营商在管理网络时要认识到这些因素 在[21]中，作者指出单个M2M设备产生的流量可能很小，但数百或数千个M2M设备产生的总流量将是巨大的,这些观察结果在某种程度上得到了[22]，[23]的证实，其中指出，远程患者监测应用预计每天产生约0.35 MB，智能电表每天产生约0.07 MB。 聚合流量模型:在[24]中提出了耦合马尔可夫调制泊松过程框架来捕获单个机器类型通信的行为以及数万个M2M设备的集体行为。CMMPP框架的复杂性随着M2M设备的数量呈线性增长，使其有效地大规模合成M2M流量,在[25]中，作者表明可以将M2M设备的（流量）状态分为三个通用类别，即定期更新，事件驱动和有效负载交换，以及一些使用这些类型的建模策略。通过车队管理中的用例示出了模型配件的图示，该车辆管理包括由运输公司运行的1000辆卡车.该拟合基于来自2G / 3G网络的测量的M2M流量,在[26]中构建了一个简单的模型，用于估算无线传感器网络中连接的家庭中产生的M2M流量。由于传感器的行为非常特定于应用，因此该工作识别可归因于任何传感器设备的某些常见通信模式.使用这些属性，提出了四个广义方程来估计由传感器网络启用的连接公寓/家庭产生的流量。 使用机器学习：在文献中已经提出了各种基于机器学习的分析方法来对交通应用进行分类或识别典型计算机网络的恶意软件/僵尸网络。[27]中的工作使用深度学习来分类流，例如HTTP，SMTP，Telnet，QUIC，Office365和YouTube，通过考虑六个特征，即源/目的端口号，有效载荷量，TCP窗口大小，到达间隔时间和从流的前20个包中提取的流量方向。[28]中开展的工作表明，僵尸网络具有可识别的流量模式，可以通过考虑连续流量之间的平均时间，流量持续时间，入站/出站流量以及流量开始时间内的傅里叶变换等特征进行分类。通过将这些流级特征与包级别属性（包括包大小，有效载荷的字节分布，包的到达间隔时间和TLS握手元数据）相结合，在[29]和[30]中增强了对网络上恶意活动的检测（即密码套件代码）。此外，作者发布了一个名为Joy [31]的基于libpcap的开源工具，用于从网络流量的被动捕获中提取这些功能 在物联网的背景下，[32]使用机器学习来对来自网络上的授权设备的单个TCP流进行分类。它使用了300多个属性（数据包级和流级），但最有影响力的是数据包生存时间（TTL）的最小值，中值和平均值，发送和接收的总字节数，包的总数重置（RST）标志，以及服务器的Alexa排名 虽然上述所有工作都做出了重要贡献，但他们并未在智能环境（如家庭，城市，校园或企业）中对物联网设备进行细粒度表征和分类。此外，还没有开发出能够根据网络流量特征进行物联网设备分类的统计模型，最重要的是，先前的工作不会公开任何数据集供研究社区使用和构建。我们的工作克服了这些缺点。 物联网流量收集和整合在本节中，我们将介绍用于收集和合成来自各种物联网设备的流量的智能环境基础架构 实验试验台图1描述了“智能环境”的真实体系结构，它通过其（有线/无线）网络基础设施为各种物联网和非物联网设备提供服务，并允许它们通过网关与互联网服务器通信。使用OpenWrt固件版本Chaos Calmer（15.05.1，r48532）刷新的TP-Link接入点充当公共互联网的网关。我们还在网关上安装了额外的OpenWrt软件包，即用于捕获流量的tcpdump，用于编写脚本的bash（4.3.39-1），用于在网关上安装外部USB存储的块安装包，kmod-usb-core和kmod-usb-storage（3.18.23-1），用于将流量跟踪数据存储在USB存储器上。 在我们的实验室设置中，TP-Link接入点的WAN接口通过大学网络连接到公共Internet，而IoT设备分别连接到LAN和WLAN接口。我们的智能环境共有28个独特的物联网设备，代表不同的类别以及几个非物联网设备，在这里，物联网是指特定用途的互联网连接设备（例如摄像机和烟雾传感器），而通用设备（例如电话和笔记本电脑）属于非物联网类别。 物联网设备包括摄像头（Nest Dropcam，Sam-sung SmartCam，Netatmo Welcome，Belkin摄像头，TP-Link日夜云摄像头，Withings智能婴儿监视器，金丝雀摄像头，八月门铃，铃铛门铃），开关和触发器（iHome） ，TP-Link智能插头，Belkin Wemo运动传感器，Belkin Wemo Switch），集线器（Smart Things，Amazon Echo），空气质量传感器（NEST Protect烟雾报警器，Netatmo气象站，Awair空气质量监测器），电子设备（Triby扬声器， PIXSTAR Photoframe，惠普打印机，Hello芭比娃娃，谷歌Chromecast），医疗设备（带智能秤，Withings Aura智能睡眠传感器，Blipcare血压计）和灯泡（Phips Hue和LiFX智能灯泡）。一些非物联网设备也连接到测试平台，如笔记本电脑，手机和Android平板电脑。平板电脑用于配置各个设备制造商推荐的物联网设备 跟踪数据使用在OpenWrt上运行的tcpdump工具收集LAN端的所有流量。在流量跟踪中，物理设备与已知MAC地址（由于处于同一LAN中）或IP地址（即无NAT）之间进行一对一映射非常重要。捕获LAN上的流量允许我们使用MAC地址作为设备的标识符，以将其流量与包括网络中的许多其他设备的流量混合隔离。我们开发了一个脚本来自动化数据收集和存储过程。生成的跟踪作为pcap文件存储在连接到网关的1 TB存储的外部USB硬盘驱动器上，此设置允许连续几个月记录流量 我们从2016年10月1日至2017年4月13日开始在智能环境中记录网络流量为期26周。原始跟踪数据包含数据包标头和有效负载信息，数据收集和存储过程每天在当地时间午夜开始，使用OpenWrt上的Cron作业。我们在OpenWrt上编写了一个监控脚本，以确保数据收集/存储顺利进行。该脚本以5秒的间隔检查网关上运行的进程。如果日志记录过程未运行，则脚本会立即重新启动它，从而将任何数据丢失事件限制为仅5秒。为了使跟踪数据公开可用，我们在大学数据中心的虚拟机（VM）上设置了Apache服务器，并编写了一个脚本，用于定期将存储在硬盘驱动器上的前一天的跟踪数据传输到VM上。 两周的跟踪数据可以从http://iotanalytics.unsw.edu.au/下载。每日日志的大小在61 MB到2 GB之间变化，平均为365 MB IoT流量特征我们现在使用对26个物联网设备的流量进行无源数据包级分析，在26周内进行观察，我们研究了广泛的物联网流量特性，包括活动模式（例如活动/睡眠期间的音量/时间分布）和信令（例如，请求的域名，使用的服务器端端口号和TLS握手交换） Iot流量构成： 由设备自主产生的流量 - 例如不受人为干预影响的DNS，NTP等 由于用户与设备交互而产生的流量 - 例如Belkin Wemo传感器响应移动检测，Amazon Echo响应用户发出的语音命令，LiFX灯泡根据用户要求改变颜色和强度，Netatmo Welcome相机检测到占用者并指示LiFX灯泡打开并具体显示颜色，等等。 我们的数据集很好地捕获了来自代表生活智能环境的实验室的这两种类型的物联网流量（即覆盖人类在环境中存在或不存在的时期）。 为了提供有关物联网流量特征的见解，我们在图2中显示了Amazon Echo和LiFX灯泡在24小时内看到的网络流量的桑葚图，选择这些设备仅用于说明目的，每个图描绘了由相应设备生成的流级信息。流量包括： 单播或多播/广播 发往本地主机（LAN）或Internet服务器（WAN 绑定到协议（TCP，UDP，ICMP或IGMP）和端口号。 图2提供了描绘两个设备所展示的潜在流量标志的视觉辅助，例如，Amazon Echo和LiFX灯泡都使用DNS（端口号53）和NTP（端口号123）。虽然Amazon Echo使用HTTP（端口号80），HTTPS（端口号443）和ICMP（端口号0），但LiFX灯泡不使用任何这些应用程序，此外，每个设备似乎与WAN服务器上的唯一端口号通信;用于Amazon Echo的TCP 33434和用于LiFX灯泡的UDP 56700，如图2（a）和2（b）中的顶部流程所示。最后，我们观察到Amazon Echo访问了许多域名，包括softwareupdates.amazon.com，device-metrics-su.amazon.com，example.org，pindorama.amazon.com和pool.ntp.org。然而，LiFX灯泡仅与两个域通信，即v2.broker.lifx.co和pool.ntp.org。 IoT活动和卷模式（暂时先这么翻译）我们从IoT设备的活动模式开始，这些模式由其流量属性定义，我们在每个流级别定义四个关键属性，以根据其网络活动来表征物联网设备： 流量：即下载和上传字节的总和 流持续时间：即流中第一个和最后一个数据包之间的时间 平均流量：即流量除以流量持续时间 设备休眠时间：（即物联网设备没有活动流的时间间隔） 我们使用在26周内收集的跟踪数据，在图3中绘制了一组选定的IoT设备的上述四个属性的概率分布，从图3a中可以看出每个物联网设备倾向于每个流交换少量数据。对于LiFX灯泡的情况（用红色条表示），26％的流量在[130,140]字节之间传输，20％在[120,130]字节之间传输，Belkin运动传感器的流量（由绿色条表示）略高;超过35％的流量在[2800,3800]字节之间传输。对于Amazon Echo（由蓝条表示），超过95％的流量传输少于1000个字节。虽然我们仅为少数设备提供流量直方图，但我们的大多数物联网设备都呈现出类似的可预测模式。 流动持续时间也出现类似的模式。参考图3（b），我们注意到Amazon Echo的流量持续时间为53秒，流量持续时间超过40％，而LiFX灯泡和Belkin运动传感器的持续时间为60秒分别为50％和21％。对于平均流速属性，图3（c）显示平均速率相当小，以每秒位数为单位，如定性预期。定量地，该图显示LiFX灯泡的平均流速为每秒18位，接近60％的时间。近30％的Belkin流的比特率在59到60比特/秒的范围内，而近40％的Amazon Echo流的比特率在70到71比特每秒的范围内。 最后，就设备的睡眠时间而言，图3（d）显示Belkin运动传感器和LiFX灯泡表现出明显的睡眠模式，持续时间为1秒和60秒，概率分别为73％和48％。然而，对于Amazon Echo，观察到具有小概率的多个睡眠时间。这是因为Amazon Echo使其TCP连接保持活动状态，并且只有在断开Internet连接时才会进入休眠状态。我们的测试台中的其他设备也表现得像Echo，并且似乎没有占主导地位的睡眠模式。 IoT信令模式我们现在关注应用层协议，使用端口号推断，物联网设备主要用于在LAN本地和/或外部与公共互联网上的服务器进行通信. 服务端口号图4显示了从各种IoT设备发起的所有流的服务器端端口号的文字云。对于每个设备，如果更频繁地使用端口，则在相应的字云中以更大的字体大小显示它。子标题（即{}内的数字）报告每个设备的唯一服务器端口数。可以看出，IoT设备各自与少数服务器端口唯一通信，而非IoT设备使用更广泛的服务（即图4（h）中显示了2382个独特端口，其中许多非常罕见） 。我们观察到非标准端口33434,56700,8883和25050分别在源自Amazon Echo，LiFX灯泡，Awair空气质量监测器和Netatmo气象站的流量中突出显示，如图4的顶行所示。此外，我们注意到来自同一制造商的设备共享某些端口，例如，端口号8443和3478在Belkin的运动传感器，电源开关和相机之间是常见的，如图4（e）-4（g）所示。我们也注意到，众所周知的标准端口号（如53（DNS），123（NTP），0（ICMP）和1900（SSDP））被许多物联网设备以及具有各种频率的非物联网使用，如图所示在图4中。此外，许多物联网设备也使用服务器端端口号443（TLS / SSL）。 DNS查询DNS是几乎所有联网设备使用的常见应用程序。由于物联网设备是为特定目的而定制设计的，因此它们访问与其供应商特定的端点服务器相对应的有限数量的域，我们在图5中绘制了由几个IoT设备以及非IoT访问的域名的词云 可以看出，IoT设备可以通过它们与之通信的域名进行相当区分，例如，如图5（a）-5（c）所示，Amazon Echo经常请求诸如example.com，example.net和example.org之类的域。hp.com和hpeprint.com的子域在HP打印机的DNS查询中可见。但是，我们也看到一些着名的域名在不同的设备之间共享。例如，belkin.com和d3gjecg2uu2faq.cloudfront.net通常被Belkin设备（即摄像机，运动传感器和电源开关）使用，如图5（d）-5（f）所示。或者pool.ntp.org在Google Dropcam，Awair空气质量监测器和LiFX灯泡产生的交通流量方面非常突出，如图5（b）-5（h）所示，再次考虑图5（i）中的非IoT，我们看到大约12000个访问过的唯一域，与IoT设备相比，其中只有少数域被重复访问。 我们还发现IoT设备在使用DNS协议的频率方面存在差异，我们从流量跟踪中观察到物联网设备在其运行的不同阶段生成DNS查询;例如，仅在启动阶段（例如Google Dropcamp）或与用户（例如Hello Barbie）交互时或定期（例如Amazon Echo）如图6所示，某些IoT设备在其DNS查询的频率中表现出特征签名。 LiFX灯泡和Amazon Echo非常频繁地发送DNS查询（即每5分钟），但像Belkin运动传感器这样的设备每30分钟只请求一次域名。 NTP查询如前所述，NTP是物联网设备使用的另一种流行协议，因为精确和可验证的时序对于物联网操作至关重要。许多物联网设备倾向于以周期性方式使用NTP协议（UDP端口123），以便将它们的时间与公共可用的NTP服务器同步。例如，Awair空气质量监测器，LiFX灯泡和Google Dropcam从pool.ntp.org获取时间服务器的IP地址。我们还发现时间同步在我们的测试台中反复出现，并且许多物联网设备在使用NTP时表现出可识别的模式。例如，Belkin电源开关，LiFX灯泡和SmartThings集线器分别每隔60,300和600秒发送NTP请求，如图7的直方图所示。 密码套件许多物联网设备使用TLS / SSL协议（端口号443）与Internet上 各自的服务器进行通信，为了启动TLS连接并与服务器协商安全算法，设备通过发送“客户端Hello”数据包开始握手，该数据包具有可以支持的“密码套件”列表，按其优先顺序排列。例如，图8（a）和8（b）描绘了Amazon Echo向两个不同的Amazon服务器提供的密码套件。每个密码套件（即4位代码）可以采用380个可能值中的一个，并表示密钥交换，批量加密和消息认证码（MAC）的算法 例如，由Amazon服务器协商的密码002f分别使用RSA，AES 128 CBC和SHA协议进行密钥交换，批量加密和消息认证。 在我们的设置中，我们发现28个IoT设备中有17个，包括Amazon Echo，August Doorbell Cam，Awair空气质量监视器，Belkin相机，Canary相机，Drop-cam，Google Chromecast，Hello Barbie，HP ENVY打印机,iHome，Netatmo欢迎相机，飞利浦Hue灯泡，皮克斯相框，Ring Doorbell，Trilby，Withings Aura智能睡眠传感器和Withings Scale，使用TLS / SSL进行通信.我们发现，当将SSL传送到不同的服务器时，Amazon Echo总共使用五个不同的密码套件字符串，Triby扬声器使用两个字符串，而Pixtar相框仅使用一个字符串进行所有SSL通信。 我们将图9中这三个设备的唯一密码套件字符串绘制为离散信号：x轴是出现在提供的套件中的4位密码的顺序，y轴是各个密码的索引（即来自{1,2，…，380}的值。 可以看出，密码套件信号的集合为每个IoT设备发出了唯一的签名。在特殊情况下，我们发现Pixtar photoframe与8个门铃使用的18个套件中的一个共享其单个密码套件 - 我们将在§5.2中看到，仅依靠密码套件属性将无法有效地对Pixtar相框流量进行分类.. 然而，有许多设备很少交换密码套件，而是希望长时间保持其TLS连接存活。例如，Google Dropcam在启动时建立与其自身服务器的TLS连接，并且只要它具有网络连接就维持此连接，而Amazon Echo和Pixstar照相框每小时分别启动平均1和2个TLS连接。 总结：在本节中，我们根据物联网设备的基础网络流量特征确定了8个关键属性。它们是流量，流量持续时间，平均流量，设备休眠时间，服务器端口号，DNS查询，NTP查询和密码套件。虽然可以通过仅考虑一个或两个流量属性（例如域名，端口号或密码套件列表）来唯一地识别某些设备（例如，Amazon Echo或LiFX灯泡），但这些设备都存在挑战。例如，在流量中很少观察到诸如密码套件列表之类的强属性（例如，每天仅一次）。作为另一示例，来自相同供应商的不同类型的设备访问类似的域并使用相同的端口号来访问云服务器。捕获诸如这些属性的出现次数（例如，访问域的次数或使用该端口的流的数量）等方面，结合其他属性，极大地提高了区分来自同一制造商的设备的预测能力。在下一节中，我们将使用这些属性的组合开发基于多阶段机器学习的算法，以帮助高精度地对物联网设备进行分类。 基于分类模型的机器学习为了从我们的跟踪数据合成属性，我们首先使用Joy工具将原始pcap文件转换为每小时流量,然后，对于给定的IoT设备，我们计算上一节中针对每小时实例定义的流量活动和信令属性。从跨越26周的跟踪中获得的每个设备的实例数取决于诸如设备在线的持续时间或设备如何生成流量（自主或交互式）等因素,例如，Blipcare BP监视器只有13个小时实例，因为它仅在用户使用设备时才生成流量。另一方面，我们为Google Dropcam收集了4177个实例 多级设备分类架构我们注意到我们的三个属性，即“域名集”，“远程端口号集”和“密码套件集”是名义上的（即不被视为数值）和多值（例如，{“ 53“：3，”123“：1，”443“：2}表示一组远程端口号，其中三个出现端口号53，两次出现端口123，一次出现端口号443）。因此，我们为IoT分类器采用了两阶段分层架构，如图10所示。 除了这些独特的单词之外，我们将非IoT设备的所有相应单词聚合为“其他” - 每个Stage-0矩阵中称为“其他”的列表示在IoT流量中未看到的单词。该矩阵的每个单元格是给定实例中这种唯一单词的出现次数。如图10所示，阶段0的每个分类器产生两个输出，即暂定类和置信水平，其与其他单值定量属性（即流量，持续时间，速率，睡眠时间，DNS，NTP）一起（）间隔）被送入Stage-1分类器，产生最终输出（即设备识别具有置信水平）。 第0级-字袋分类器我们使用朴素贝叶斯多分类器来分析我们机器的第0阶段中的每个单词包。已经表明[35]，当处理大量独特单词时，该分类器在文本分类中表现良好。在训练阶段，分类器采用单词的分布，例如个人独特的域名，并使用以下方法计算给定课程的每个单词的概率： 其中wj是训练数据集中的唯一单词（例如，端口号56700）; ci是类别标签（例如LiFX灯泡）; D是所有实例的数量。$n_l,c_i,w_j^{train}$是类标签为ci的每个实例中的wj出现次数，N是唯一字的总数（例如，我们的数据集中有N = 421个唯一端口号，在测试阶段，分类器需要为所有可能的类计算以下概率： 其中$W^{test}$表示${w_1:n_1^{test},w_2:n_2^{test},…,w_N:n_N^{test}}$；而$n_j^{test}$是wj在一个测试实例中的出现次数,$Pr(c_i^{train})$整个训练数据集中类ci的存在概率,（即ci训练实例的数量除以所有训练实例的总数）分类器最终选择给出一组给定单词及其出现的（2）中最大概率的类。请注意，如果训练实例在各个类之间公平分布，那么Naive Bayes Multinomial分类器就能很好地运行[35]。 第1级-分类器我们有一个阶段1分类器，它可以获取所有定量属性以及每个阶段0分类器的输出对。由于阶段1属性不是线性可分的，并且阶段0分类器的输出是标称值，因此我们使用基于随机森林的阶段1分类器。选择随机森林的另一个原因是与其他决策树分类器相比，对过度拟合的高容忍度。]]></content>
      <categories>
        <category>学习科研</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>IoT</tag>
        <tag>网络流量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器安装ftp服务]]></title>
    <url>%2Fsunpages%2F2019%2F05%2F05%2Fvsftp%2F</url>
    <content type="text"><![CDATA[ubuntu16.04配置vsftp服务器安装vsftpd 安装 1sudo apt-get install vsftpd 配置 /etc/vsftp.conf 1234567891011121314151617181920# 允许匿名用户和本地用户登录，本地用户即/etc/passwd中的用户anonymous_enable=YESlocal_enable=YES# 禁止全局写命令write_enable=YES# 禁止匿名用户上传和创建文件夹anon_upload_enable=NOanon_mkdir_write_enable=NO# 只允许userlist的用户登录userlist_enable=YESuserlist_deny=NOuserlist_file=/etc/vsftpd.user_list# 注意：使用了vsftpd.user_list后，要在其中加入anonymous才能使用匿名用户登录，如以下内容，表示只有匿名用户和名为ftp的用户，以及本地用户ubuntu可以登录anonymousftpubuntu 创建/etc/vsftpd.user_list文件 12ubunturoot 基本操作 启动、重启、关闭 123sudo /etc/init.d/vsftpd startsudo /etc/init.d/vsftpd stopsudo /etc/init.d/vsftpd restart]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器搭建ss]]></title>
    <url>%2Fsunpages%2F2019%2F05%2F01%2Fss%2F</url>
    <content type="text"><![CDATA[Ubuntu16.04服务器搭建ss服务 安装unzip wget 1sudo apt-get install unzip wget 安装shadowsocks 12345wget https://github.com/ToyoDAdoubi/doubi/archive/master.zipunzip master.zipcd ./mastersudo chmod 777 ssr.shsudo ./ssr.sh 安装过程一路都有提示，十分简单]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux/MacOS 配置oh-my-zsh]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F28%2Fzsh%2F</url>
    <content type="text"><![CDATA[Linux/Mac OS下安装oh my zsh并配置主题和插件安装oh my zsh 安装git 、zsh Linux(Ubuntu16.04) 1sudo apt-get install zsh git Mac OS 12#先自行百度安装homebrewbrew install git 安装oh my zsh(两种系统命令相同) 1sh -c "$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)" 修改主题：vim ～/.zshrc 12#找到对应行改为ZSH_THEME="agnoster" source ~/.zshrc 配置插件 wd 它的作用就是能够快速的切换到常用的目录。 ​ 我们用命令行时经常会遇到这样一种情况， 我们常用的目录就那么几个，而这些目录有时候会再很深的层级中。 使用 cd 命令在这些深层级目录中切换就比较耗费时间了。 ​ 例如 Nginx的wwwroot目录/usr/share/nginx/html ,我们进入这个目录，输入wd add html #这个html这个名称是可以随便取的. 下次再进入这个目录就可以直接输入 wd thml wd用法： 12345678910111213141516171819202122Usage: wd [command] [point]Commands: add &lt;point&gt; Adds the current working directory to your warp points add Adds the current working directory to your warp points with current directory&apos;s name add! &lt;point&gt; Overwrites existing warp point add! Overwrites existing warp point with current directory&apos;s name rm &lt;point&gt; Removes the given warp point rm Removes the given warp point with current directory&apos;s name show &lt;point&gt; Print path to given warp point show Print warp points to current directory list Print all stored warp points ls &lt;point&gt; Show files from given warp point (ls) path &lt;point&gt; Show the path to given warp point (pwd) clean! Remove points warping to nonexistent directories -v | --version Print version -d | --debug Exit after execution with exit codes (for testing) -c | --config Specify config file (default ~/.warprc) -q | --quiet Suppress all output help Show this extremely helpful text sudo 连按两次Esc添加或去掉sudo zsh-syntax-highlighting ​ #高亮可用命令 Linux 1git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-syntax-highlighting Mac OS 12brew install zsh-syntax-highlightingsource /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh zsh-autosuggestions ​ #记录上一条命令，并自动建议 1git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions 安装 在～/.zshrc下配置 12345678# Add wisely, as too many plugins slow down shell startup.plugins=( git zsh-autosuggestions zsh-syntax-highlighting wd sudo) 最后source ~/.zshrc]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>极客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云命令行上载工具使用]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F24%2Fqshell%2F</url>
    <content type="text"><![CDATA[Linux/Mac OS 下七牛云同步工具qshell的配置与使用@TOC 下载与安装 在官方下载页面下载即可，qshell 下载后解压，并将系统所对应版本重命名为qshell 配置环境变量 编辑～/.zshrc 或者～/.bashrc文件将qshell路径添加到环境变量中，我的路径为 1export PATH=$PATH:/home/sun/文档/tools/qiniu 使配置文件生效 1source ~/.zshrc 登录账户1qshell account ak sk 马赛克位置分别填写个人的ak 和sk qupload的使用 配置文件qupload.json,每个参数的具体作用请参考官方文档 12345678910111213141516&#123; "src_dir" : "/home/sun/图片", "bucket" : "ydm-ng", "up_host" : "http://upload-z1.qiniu.com", "ignore_dir" : false, "overwrite" : false, "check_exists" : true, "check_hash" : false, "check_size" : false, "rescan_local" : true, "log_file" : "upload.log", "log_level" : "info", "log_rotate" : 1, "log_stdout" : false, "file_type" : 0&#125; 执行命令为 1qshell qupload [&lt;ThreadCount&gt;] &lt;LocalUploadConfig&gt; 第一个为可选参数，一般选10，第二个为配置文件路径 一般为了节省操作时间，在zshrc配置别名 1alias qupload="qshell qupload 10 /Users/sun/Documents/tools/qshell/qupload.json" 在生效source ~/.zsh即可]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>极客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在服务器上部署jupyterbook]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F21%2Fjupyter-notebook%2F</url>
    <content type="text"><![CDATA[Linux服务器配置jupyter-notebook实现远程访问下载anaconda在清华镜像上下载anaconda对应版本123wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.2.0-Linux-x86_64.shsudo chmod +x Anaconda* 注意安装过程中配置环境变量并且是环境变量生效 生成配置文件1jupyter notebook --generate-config 生成秘钥 进入ipython123451. In [1]: from notebook.auth import passwd2. In [2]: passwd()3. Enter password:4. Verify password:5. Out[2]: 'sha1:ce23d945972f:34769685a7ccd3d08c84a18c63968a41f1140274' 复制秘钥，后面要用 修改配置文件 vim ~/.jupyter/jupyter_notebook_config.py1231. c.NotebookApp.ip='服务器IP'2. c.NotebookApp.password = u'sha:ce...刚才复制的那个秘钥'3. c.NotebookApp.open_browser = False 后台启动jupyter-notebook12```bashnohup jupyter notebook &gt; jupyter.log &amp; 后台启动jupyter-lab1nohup jupyter-lab &gt;&gt; ./jupyter-notebook/jupyter-lab.log &amp; 后台运行并且生成配置文件]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Linux</tag>
        <tag>极客</tag>
        <tag>开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统dd命令使用]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F17%2Fdd%2F</url>
    <content type="text"><![CDATA[Linux下用dd命令制作U盘启动盘 在manjaro系统下测试 查询U盘对应文件sudo fdisk -l 12345678910111213141516171819202122Disk /dev/nvme0n1：238.5 GiB，256060514304 字节，500118192 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：gpt磁盘标识符：09CDCE5C-F487-42C9-83BF-B41ACD262434设备 起点 末尾 扇区 大小 类型/dev/nvme0n1p1 4097 618497 614401 300M EFI 系统/dev/nvme0n1p2 618498 481648510 481030013 229.4G Linux 文件系统/dev/nvme0n1p3 481648511 500103449 18454939 8.8G Linux swapDisk /dev/sda：28.7 GiB，30752000000 字节，60062500 个扇区单元：扇区 / 1 * 512 = 512 字节扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0xcad4ebea设备 启动 起点 末尾 扇区 大小 Id 类型/dev/sda4 * 256 60062499 60062244 28.7G c W95 FAT32 (LBA) 发现U盘对应的是/dev/sda4 使用dd命令写入iso文件 1sudo dd if=/home/sun/manjaro.iso of=/dev/sda4 bs=4M]]></content>
      <categories>
        <category>命令</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音乐下载工具]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F14%2FCoolMusic%2F</url>
    <content type="text"><![CDATA[CoolMusic的使用方法MusicDownloaderMusicDownloader 是基于python的一个音乐下载项目。 项目地址:https://github.com/Michel-liu/MusicDownloader其主要功能有： 批量下载网易云音乐歌单 通过关键字搜索，搜索并下载特定的音乐 使用说明 登陆自己的网易云音乐账号。 在当前界面进入开发者工具，进入网络选项卡，并重新加载界面。 使用搜索工具，随意搜索你歌单中的一个关键字，定位到一个名字以detail?csrf_token开头的文件。 选中该文件，在右侧Headers选项卡中拉到页末，找到Form Data，将其中的params与encSecKey复制到我们项目的config.py中。 将config.py中的FileSaveDir改为你自己在本地想要保存的路径。 运行main.py文件即可。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSR命令行版本配置]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F11%2FCLI_ss%2F</url>
    <content type="text"><![CDATA[ubuntu 16.04配置shadowsocks+proxychains4 实现终端代理安装Python-pip ubuntu16.04默认安装Python2.7，所以不需要安装python，安装python的包管理工具就行了 1sudo apt-get install python-pip 安装shadowsocks 1sudo pip install shadowsocks 配置本地vim /home/ubuntu/shadowsocks.json 12345678&#123; "server":"11.22.33.44",# 你服务端的IP "server_port":50003, # 你服务端的端口 "local_port":1080, #本地端口，一般默认1080 "password":"123456", #ss服务端设置的密码 "timeout":600, #超时设置 和服务端一样 "method":"aes-256-cfb" #加密方法 和服务端一样&#125; 创建服务启动脚本shadowsocks.sh 1sslocal -c /home/ubuntu/shadowsocks.json 可能会报错]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>极客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ryu控制器实现集线器]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F06%2F2%2F</url>
    <content type="text"><![CDATA[2 Switching Hub[TOC]2.1 Switching Hub 交换集线器有很多种不同的功能，在这我们看看拥有以下功能的集线器： 能够学习集线器端口连接主机的MAC地址并将其保存在MAC地址表中 当收到MAC地址已知的报文时，将其转发到对应端口 当收到地址未知的报文的时候，进行泛洪 让我们用ryu来实现这种功能的交换机 2.2 openflow交换集线器openflow交换机可以实现下列功能通过接受控制器的指令(例如ryu控制器) 改写接受数据包的地址或者从特定端口转发数据包 转发数据包到控制器(packet-In) 控制器从指定端口转发数据包(Packet-Out) 可以实现组合了这些功能的交换集线器。首先，您需要使用Packet-In功能来学习MAC地址。控制器可以使用Packet-In函数从交换机接收数据包。交换机分析收到的数据包，以了解主机的MAC地址和有关连接端口的信息。学习之后，交换机传输接收的数据包。交换机调查数据包的目的MAC地址是否属于已知主机。根据调查结果，交换机执行以下处理。 如果主机已经是已知主机…使用Packet-Out功能从连接的端口转发数据包。 如果主机是未知主机…使用Packet-Out功能执行泛洪 以下使用附图以逐步的方式说明上述操作： 初始状态 初始状态下流表为空，假设主机A连接端口1，主机B连接端口4，主机C连接端口3 主机A-&gt; 主机B 当数据包从主机A发送到主机B的时候，一个Packet-In消息将会被发送到控制器并且主机A的MAC地址将会被端口1学习。但是由于主机B的端口还不知道，因此数据包被泛洪到除了端口1以外的所有端口并且被主机B和主机C接受。 Packet-In： 入端口:1 目的主机：B 源主机：A Packet-Out： 动作：输出：泛洪 主机B-&gt;主机A 当主机B回应主机A的数据包返回的时候，由于已经有一个流表项被加入到流表中所以数据包将被转发到端口1，所以主机C将不会收到B发送的数据包 Packet-In: 入端口：4 目的主机：主机A 源主机：主机B Packet-Out: 动作：输出：端口1 主机A-&gt;主机B 当主机A再一次向主机B发送数据包的时候，由于前面主机B回应数据包的时候，端口4已经学习到主机B的MAC地址，所以这一次数据包将会直接向端口4发送 Packet-In 入端口：1 目的主机：主机B 源主机：主机A Packet-Out： 动作：输出：端口4 下面我们来看看交换集线器的ryu源码实现 2.3 使用Ryu实现交换集线器源码在ryu/app/example_switch_13.py 除了上述之外，还有simple_switch.py（OpenFlow 1.0）和simple_switch_12.py（OpenFlow 1.2），具体取决于OpenFlow的版本，但我们看一下支持OpenFlow 1.3的实现 源代码很短，因此我们在下面显示了完整的源代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101# Copyright (C) 2016 Nippon Telegraph and Telephone Corporation.## Licensed under the Apache License, Version 2.0 (the "License");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or# implied.# See the License for the specific language governing permissions and# limitations under the License.from ryu.base import app_managerfrom ryu.controller import ofp_eventfrom ryu.controller.handler import CONFIG_DISPATCHER, MAIN_DISPATCHERfrom ryu.controller.handler import set_ev_clsfrom ryu.ofproto import ofproto_v1_3from ryu.lib.packet import packetfrom ryu.lib.packet import ethernetclass ExampleSwitch13(app_manager.RyuApp): OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION] def __init__(self, *args, **kwargs): super(ExampleSwitch13, self).__init__(*args, **kwargs) # initialize mac address table. self.mac_to_port = &#123;&#125; @set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER) def switch_features_handler(self, ev): datapath = ev.msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser # install the table-miss flow entry. match = parser.OFPMatch() actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER, ofproto.OFPCML_NO_BUFFER)] self.add_flow(datapath, 0, match, actions) def add_flow(self, datapath, priority, match, actions): ofproto = datapath.ofproto parser = datapath.ofproto_parser # construct flow_mod message and send it. inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS, actions)] mod = parser.OFPFlowMod(datapath=datapath, priority=priority, match=match, instructions=inst) datapath.send_msg(mod) @set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER) def _packet_in_handler(self, ev): msg = ev.msg datapath = msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser # get Datapath ID to identify OpenFlow switches. dpid = datapath.id self.mac_to_port.setdefault(dpid, &#123;&#125;) # analyse the received packets using the packet library. pkt = packet.Packet(msg.data) eth_pkt = pkt.get_protocol(ethernet.ethernet) dst = eth_pkt.dst src = eth_pkt.src # get the received port number from packet_in message. in_port = msg.match['in_port'] self.logger.info("packet in %s %s %s %s", dpid, src, dst, in_port) # learn a mac address to avoid FLOOD next time. self.mac_to_port[dpid][src] = in_port # if the destination mac address is already learned, # decide which port to output the packet, otherwise FLOOD. if dst in self.mac_to_port[dpid]: out_port = self.mac_to_port[dpid][dst] else: out_port = ofproto.OFPP_FLOOD # construct action list. actions = [parser.OFPActionOutput(out_port)] # install a flow to avoid packet_in next time. if out_port != ofproto.OFPP_FLOOD: match = parser.OFPMatch(in_port=in_port, eth_dst=dst) self.add_flow(datapath, 1, match, actions) # construct packet_out message and send it. out = parser.OFPPacketOut(datapath=datapath, buffer_id=ofproto.OFP_NO_BUFFER, in_port=in_port, actions=actions, data=msg.data) datapath.send_msg(out) 让我们来看看各自实现的内容。 2.3.1 类定义和初始化为了实现一个ryu应用， ryu.base.app_manager.RyuApp被引用，此外，要使用OpenFlow 1.3，OpenFlow 1.3版本是为OFP_VERSIONS指定的。此外，定义了MAC地址表mac_to_port. 在OpenFlow协议中，已经定义了一些过程，例如Open-Flow交换机和控制器之间通信所需的握手。但是，由于Ryu的框架负责处理这些程序，因此在ryu app中不需要了解这些。 12345678class ExampleSwitch13(app_manager.RyuApp): OFP_VERSIONS = [ofproto_v1_3.OFP_VERSION] def __init__(self, *args, **kwargs): super(ExampleSwitch13, self).__init__(*args, **kwargs) # initialize mac address table. self.mac_to_port = &#123;&#125; 2.3.2 事件处理函数对于Ryu，当接收到OpenFlow消息时，生成对应于该消息的事件。 Ryu应用程序实现了与希望接收的消息相对应的事件处理程序。事件处理程序定义了一个具有参数的事件对象的函数，并使用ryu.controller.handler.set_ev_cls装饰器来装饰。 set_ev_cls指定支持接收消息的事件类以及参数的OpenFlow交换机的状态。事件类名称为ryu.controller.ofp_event.EventOFP + 。例如，在Packet-In消息的情况下，它变为EventOFPPacketIn。有关详细信息，请参阅Ryu的标题为API Reference的文档。对于状态，请指定以下之一或列表。 添加缺失流表项 在与OpenFlow交换机完成握手之后，将缺失流表项添加到交换机流表中以准备接收Packet-In消息。具体地，在接收到交换机特征（特征回复）消息时，添加表缺失流条目。 12345@set_ev_cls(ofp_event.EventOFPSwitchFeatures, CONFIG_DISPATCHER) def switch_features_handler(self, ev): datapath = ev.msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser 在ev.msg中，存储与该事件对应的OpenFlow消息类的实例。在本例中，它是ryu.ofproto.ofproto_v1_3_parser.OFPSwitchFeatures。在msg.datapath中，存储与发出此消息的OpenFlow交换机对应的ryu.controller.controller.Datapath类的实例。Datapath类执行重要的处理，例如与OpenFlow交换机的实际通信以及与接收的消息相对应的事件的发布。Ryu应用程序使用的datapath主要属性如下： Ryu应用程序中使用的Datapath类的主要方法如下： send_msg（msg） 发送OpenFlow消息。 msg是与发送OpenFlow消息对应的ryu.ofproto.ofproto_parser.MsgBase的子类。交换集线器并不特别使用收到的交换机功能消息本身。它被作为事件处理以获得添加表缺失流条目的定时。 123456def switch_features_handler(self, ev): # install the table-miss flow entry. match = parser.OFPMatch() actions = [parser.OFPActionOutput(ofproto.OFPP_CONTROLLER, ofproto.OFPCML_NO_BUFFER)] self.add_flow(datapath, 0, match, actions) Table-miss流条目具有最低（0）优先级，并且该条目匹配所有分组。在该条目的指令中，通过指定输出到控制器端口的输出动作，如果接收的数据包与任何正常流条目都不匹配，则发出Packet-In。生成空匹配以匹配所有数据包。匹配在OFPMatch类中表示。接下来，生成OUTPUT操作类（OFPActionOutput）的实例以传输到控制器端口。控制器被指定为输出目的地，OFPCML_NO_BUFFER被指定为max_len，以便将所有数据包发送到控制器。最后，为优先级指定0（最低），并执行add_flow（）方法以发送Flow Mod消息。 add_flow（）方法的内容将在后面的部分中介绍。 Packet-In 消息 创建Packet-In事件处理程序的处理程序，以接受具有未知目标的已接收数据包 123456@set_ev_cls(ofp_event.EventOFPPacketIn, MAIN_DISPATCHER) def _packet_in_handler(self, ev): msg = ev.msg datapath = msg.datapath ofproto = datapath.ofproto parser = datapath.ofproto_parser 常用的OFPPacketIn类属性如下所示： 更新MAC地址表 12345678910def _packet_in_handler(self, ev): # get the received port number from packet_in message. in_port = msg.match['in_port'] self.logger.info("packet in %s %s %s %s", dpid, src, dst, in_port) # learn a mac address to avoid FLOOD next time. self.mac_to_port[dpid][src] = in_port $\qquad$从OFPPacketIn匹配中获取接收端口（in_port）。目标MAC地址和发送方MAC地址使用Ryu的数据包库从接收到的数据包的以太网报头中获取。基于获取的发送方MAC地址和接收的端口号，更新MAC地址表。$\qquad$为了支持与多个OpenFlow交换机的连接，MAC地址表被设计为针对每个OpenFlow交换机进行管理。datapath ID用于标识OpenFlow交换机。 判断转发目的端口 当MAC地址表中存在目的MAC地址时，使用相应的端口号。如果未找到，则生成OUTPUT操作类的实例，该实例指定输出端口的泛洪（OFPP_FLOOD） 123456789101112131415def _packet_in_handler(self, ev): # if the destination mac address is already learned, # decide which port to output the packet, otherwise FLOOD. if dst in self.mac_to_port[dpid]: out_port = self.mac_to_port[dpid][dst] else: out_port = ofproto.OFPP_FLOOD # construct action list. actions = [parser.OFPActionOutput(out_port)] # install a flow to avoid packet_in next time. if out_port != ofproto.OFPP_FLOOD: match = parser.OFPMatch(in_port=in_port, eth_dst=dst) self.add_flow(datapath, 1, match, actions) $\qquad$如果找到目标MAC地址，则会在OpenFlow交换机的流表中添加一个条目。与添加Table-miss流条目一样，指定匹配和操作，并执行add_flow（）以添加流条目。 $\qquad$与Table-miss流条目不同，此次设置匹配条件。这次实现了交换集线器，指定了接收端口（in_port）和目标MAC地址（eth_dst）。例如，由端口1接收的寻址到主机B的分组是目标。$\qquad$对于此次的流条目，优先级指定为1,值越大，优先级越高，因此，此处添加的流条目将在Table-miss流条目之前进行评估。$\qquad$根据包含上述操作的摘要，将以下条目添加到流表中。将端口1接收到的主机B（目标MAC地址为B）的数据包传输到端口4。 对于OpenFlow，在选项中规定了一个名为NORMAL的逻辑输出端口，当为输出端口指定NORMAL时，交换机的L2 / L3功能用于处理数据包。这意味着，通过指示将所有数据包输出到NORMAL端口，可以使交换机作为交换集线器运行。但是，我们使用OpenFlow实现每个处理 添加流表项 Packet-In处理程序的处理尚未完成，但这里将介绍添加流表项的方法。 1234567def add_flow(self, datapath, priority, match, actions): ofproto = datapath.ofproto parser = datapath.ofproto_parser # construct flow_mod message and send it. inst = [parser.OFPInstructionActions(ofproto.OFPIT_APPLY_ACTIONS, actions)] 对于流表项，设置指示目标数据包条件的匹配，以及指示对数据包的操作，条目优先级和有效时间的指令。在交换集线器实现中，Apply Actions用于设置指令，以便立即使用指定的操作。最后，通过发出Flow Mod消息向流表添加条目 1234def add_flow(self, datapath, priority, match, actions): mod = parser.OFPFlowMod(datapath=datapath, priority=priority, match=match, instructions=inst) datapath.send_msg(mod) 与Flow Mod消息对应的类是OFPFlowMod类。生成OFPFlowMod类的实例，并使用Datapath.send_msg（）方法将消息发送到OpenFlow交换机。OFPFlowMod类的构造函数有很多参数。其中许多通常可以是默认值。括号内是默认值。 datapath 这是支持流表操作的OpenFlow交换机的Datapath类实例。通常，指定从传递给处理程序的事件中获取的那个，例如Packet-In消息。 cookie(0) 控制器指定的可选值，可在更新或删除条目时用作过滤条件。这不用于数据包处理。 cookie_mask(0) 更新或删除条目时，如果指定了0以外的值，则使用条目的cookie值将其用作操作目标条目的过滤器 table_id 指定操作目标流表的表ID command (ofproto_v1_3.OFPFC_ADD)、 指定要执行的操作。 idle_timeout(0) 指定此条目的有效期，以秒为单位。如果未引用该条目并且idle_timeout指定的时间过去，则删除该条目。引用该条目时，将重置已用时间。删除条目后，会向控制器发送Flow Removed消息。 hard_timeout (0) 指定此条目的有效期，以秒为单位。与idle_timeout不同，使用hard_timeout，即使引用了条目，也不会重置已用时间。也就是说，无论条目的引用如何，都在指定的时间过去时删除该条目。与idle_timeout一样，当删除条目时，将发送Flow Removed消息。 priority(0) 指定此条目的优先级顺序。值越大，优先级越高。 buffer_id (ofproto_v1_3.OFP_NO_BUFFER) 指定OpenFlow交换机上缓冲的数据包的缓冲区ID。在分组输入消息中通知缓冲区ID，并且当指定的处理与发送两个消息时相同，即，为输出端口和流模式消息指定了OFPP_TABLE的分组输出消息。当命令为OFPFC_DELETE或OFPFC_DELETE_STRICT时，将忽略此项。如果未指定缓冲区ID，请设置OFP_NO_BUFFER out_port 如果命令为OFPFC_DELETE或OFPFC_DELETE_STRICT，则输出端口将过滤目标条目。如果命令为OFPFC_ADD，OFPFC_MODIFY或OFPFC_MODIFY_STRICT，则忽略该命令。要禁用输出端口的过滤，请指定OFPP_ANY。 out_group(0) 与out_port一样，按输出组过滤。要禁用，请指定OFPG_ANY。 flag(0) 您可以指定以下标志组合 match(None) 具体的match instructions ([]) 指定指令列表 数据包转移 现在我们返回Packet-In处理程序并解释最终处理。无论是否从MAC地址表中找到目的地MAC地址，最后都发出分组输出消息并传送接收的分组。 123456def _packet_in_handler(self, ev): out = parser.OFPPacketOut(datapath=datapath, buffer_id=ofproto.OFP_NO_BUFFER, in_port=in_port, actions=actions, data=msg.data) datapath.send_msg(out) 与Packet-Out消息对应的类是OFPPacketOut类。 OFPPacketOut的构造函数的参数如下： datapath 指定OpenFlow交换机对应的Datapath类的实例 buffer_id 指定OpenFlow上缓冲的数据包的缓冲区ID。如果未缓冲，则指定OFP_NO_BUFFER。 in_port 指定接收数据包的端口。如果不是收到的数据包，则指定OFPP_CONTROLLER actions 指定操作列表。 data 指定数据包的二进制数据。当为buffer_id指定OFP_NO_BUFFER时使用此方法。使用OpenFlow交换机的缓冲区时，省略 $\qquad$在交换集线器实现中，已经为buffer_id指定了Packet-In消息的buffer_id。如果已禁用Packet-In消息的buffer-id，则为发送数据包的数据指定收到的Packet-In数据包。 2.4 ryu应用执行因为xterm是从Mininet启动的，所以使用mn命令启动Mininet环境。要构建的环境具有简单的结构，具有三个主机和一个交换机。mn命令参数如下：]]></content>
      <categories>
        <category>RYU控制器</category>
      </categories>
      <tags>
        <tag>SDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[页面置换算法实验]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F05%2Flab4%2F</url>
    <content type="text"><![CDATA[实验四 实验报告 孙汉武 16281047 16281047 实验源码链接:https://github.com/sunhanwu/16281047_OperatingSystemExperiment/tree/master/lab4 一 概要设计 实验源码请参考test.h 1.1 模块说明$\qquad$本实验共包含测试模块在内一共有7个模块，其中五个模块是算法模块，分别实现最佳置换算法、先入先出算法、最久未使用算法、改进的Clock算法、PBA页面缓冲算法和主模块。详细的细节如下： 模块 文件 说明 测试模块 test.h 包含页面帧结构体的定义、随机访问序列的生成等测试函数 最佳置换算法模块 Optimal.h 包含最佳置换算法函数 先入先出算法模块 FIFO.h 包含先入先出算法函数 最久未使用算法模块 LRU.h 包含最久未使用算法函数 改进Clock算法模块 Clock.h 包含改进的Clock算法函数 PBA页面缓冲算法模块 PBA.h 包含页面缓冲算法函数 主模块 main.cpp 主函数 1.2 接口说明$\qquad$1.1 中所说的的各个模块中，测试模块是一个最基本的模块，它包含最基本的页面帧结构体的定义和随机访问序列生成函数等基本数据结构和函数。而六个算法模块都会引用测试模块中的数据结构和随机访问序列生成函数。而在主函数中进行对各个算法模块的调用。下面图示了各个模块之间的关系： 1.3 数据结构说明$\qquad$在本实验定一个很重要的表示页面帧的结构体，其成员变量及其作用如下图所示： WorkItem(表示帧结构体) 1234567typedef struct WorkItem&#123; int seq; int priority; char Used; char Modified;&#125;WorkItem; 变量名 作用 变量名 作用 seq 访问的序列号 priority 优先级 Used Clock中的使用位 Modified Clock中的修改位 MemSchedule(表示内存分配调度结构体) 12345678910111213141516171819202122typedef struct MemSchedule&#123; WorkItem* WorkSpace=NULL; int *VisitSeq=NULL; int N=64; int p=0; //工作集大小 int e=5; int m=1; //定义访问序列长度o int length; //当前已使用物理块数 int work_len=0; //发生替换的物理块号 int change=0; float t,r;// 队列长度 int queue_free_len = 0; int queue_modified_len = 0; WorkItem free[2]; WorkItem Modified[2];&#125;MemSchedule; 变量名 作用 变量名 作用 WorkSpace 工作区间结构体数组 VisitSeq 访问序列数组 N 虚拟内存大小 p 工作集起始位置 e 工作区间大小 m 工作区间移动效率 length 访问序列长度 work_len 工作集中使用长度 chang 上一次发生替换的物理块号 t,r 随机访问序列算法参数 queue_free_len PBA中的空闲队列长度 queue_modifie_len PBA中修改队列长度 free PBA中的空闲队列 Modified PBA中的修改队列 1.4 随机访问序列生成算法$\qquad$实验中需要使用到随机访问序列，所以生成一个好的随机访问序列能很好的测试出各个算法的性能。下面是本实验中的随机算法访问序列生成算法的源码 12345678910111213141516171819202122232425262728293031MemSchedule GeneVisitSeq(int l)&#123; MemSchedule schedule1; printf("是否设定调度算法参数(Y/N):"); char flag; scanf("%c",&amp;flag); if (flag=='Y') &#123; schedule1=SetMemSchedule(schedule1); &#125; schedule1.t=rand()%1000/1000.0; schedule1.VisitSeq=(int *)malloc(l*sizeof(schedule1.m)); printf("生成随机内存访问序列：\n"); for (int i=0;i&lt;l;i++) &#123; for (int j=0;j&lt;schedule1.m;j++) &#123; schedule1.VisitSeq[i*schedule1.m+j] = rand()%schedule1.e+schedule1.p; printf("%d ",schedule1.VisitSeq[i*schedule1.m+j]); &#125; schedule1.r=rand()%1000/1000.0; if(schedule1.r&lt;schedule1.t) &#123; schedule1.p=(schedule1.p+1)%schedule1.N; &#125; &#125; printf("\n"); schedule1.length=l*schedule1.m; schedule1.WorkSpace = (WorkItem *)malloc(schedule1.e *sizeof(WorkItem)); return schedule1;&#125; 下面是其流程图： 其描述为： 首先生成算法需要的N p e m t等基本参数 生成m个范围在p到p+e之间的随机数加入到序列中 生成随机小数r 比较t和r，如果t比r小；则取一个新的p值；否则p=p+1 mod N 如果需要继续加长访问序列，则返回第二部继续执行；否则结束 1.5 算法通用流程$\qquad$各个页面置换算法中，大部分流程是一致的，只是在选择要替换的页面的时候选择的算法不一样，下面是这些算法的通用流程，而每个算法选择替换页号的时候将在后面仔细解释。 其描述为： 在访问序列中取出下一个要访问的页号，序列为空的话结束。 查看分配的内存内存块中是否还有剩余空间，有的话进行第三步；没有进行第四步 查看要访问的页号在以装入内存中是否存在，存在的话直接去下一个要访问的页号，从第一步开始执行；不存在则将新的物理块装入内存 查看要访问的页号在以装入内存中是否存在，存在的话直接去下一个要访问的页号，从第二部开始执行；不存在则利用算法找到要替换的内存块号，并将其替换，返回第一步 二 最佳置换算法 实验源码请参照github中Optimal.h 算法描述 $\qquad$最佳置换算法是一个理想的算法，其选择淘汰的页面是以后用不使用的，或者在将来最长时间用不使用的页面。采用最佳置换算法通常可以保证最低的缺页率。 算法模拟 | 访问页面 | 4 | 4 | 3 | 5 | 6 | 3 | 6 | 7 | 9 | 7 | 10 | 9 | 11 | 12 | | ———— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | | 内存块1 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 9 | 9 | 9 | 9 | 9 | 9 | | 内存块2 | | | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 10 | 10 | 11 | 11 | | 内存块3 | | | | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 12 | | 内存块4 | | | | | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | | 内存块5 | | | | | | | | 7 | 7 | 7 | 7 | 7 | 7 | 7 | 上面是算法执行过程中页面的替换过程 算法实现 $\qquad$在概要设计中给出了各个算法的通用算法流程，但是各个算法在选择替换的内存块号的时候是不一致的。下面的是最佳置换算法中的实现。 1234567891011121314151617if (flag == 0)&#123; //min表示最小优先级的那个内存块号 int min_pri=0xffffff; for ( int m=0;m&lt;s1.work_len;m++) &#123; int n = SearchVisitSqe(s1.VisitSeq,i-1,s1.WorkSpace[m].seq,0,s1.length-s1.work_len+m); s1.WorkSpace[m].priority = n; if (n &lt; min_pri) &#123; s1.change = m; min_pri = n; &#125; &#125; //表示发生替换变化的块号s1.change s1.WorkSpace[s1.change].seq = pointer;&#125; $\qquad$在这个代码片段中可以看到，通过SearchVisitSeq函数找到当前内存块中的页号下一次在访问序列中出现的距离，并将该距离最为优先级的值更新给每个内存块。最后判断哪个优先级小，说明那个物理块将来出现的时间越长，将替换它。 在主函数中调用最佳置换算法函数，会得到如下结果： 带有@符号的表示这是新替换的页面，带有@的一行说明发生了缺页 算法性能评价 $\qquad$程序设计中给出了两个评价算法性能的指标，分别是缺页率，下面将会给出在不同的虚拟内存和工作集的情况下两个指标的变化情况。 $\qquad$由于时间开销在算法中无法模拟，只能通过了理论的分析得到。下面只给出缺页率与工作集大小和虚拟内训大小之间的关系。 ​ 工作集大小与缺页率之间的关系： $\qquad$对应的曲线为： $\qquad$对于这个曲线做出的解释如下： 当工作集比较小的时候，频繁的发生缺页导致缺页率高 当工作集增大时，由于内存块数增多，减少页面的发生，缺页率减少。 当工作集再继续增大的时候，前面物理块空闲的时候页面装入也算做缺页，所以缺页率再次上升 当工作集大小达到一定程度的时候，缺页率会一直减小 当工作集不变的时候，更改虚拟内存的时候分析缺页率的变化： 其对应的曲线图为： 三 先入先出置换算法 实验源码请参考github中的FIFO.h 算法描述 是最简单的页面置换算法。这种算法的基本思想是：当需要淘汰一个页面时，总是选择驻留主存时间最长的页面进行淘汰，即先进入主存的页面先淘汰。其理由是：最早调入主存的页面不再被使用的可能性最大。 算法模拟 | 访问页面 | 4 | 4 | 3 | 5 | 6 | 3 | 6 | 7 | 9 | 7 | 10 | 9 | 11 | 12 | | ———— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | | 内存块1 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 9 | 9 | 9 | 9 | 9 | 9 | | 内存块2 | | | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 11 | 11 | | 内存块3 | | | | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 10 | 10 | 10 | 10 | | 内存块4 | | | | | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 12 | | 内存块5 | | | | | | | | 7 | 7 | 7 | 7 | 7 | 7 | 7 | 算法实现 在概要设计中给出了各个算法的通用算法流程，但是各个算法在选择替换的内存块号的时候是不一致的。下面的是先入先出置换算法中的实现。 12345678910111213141516171819if (flag == 0)&#123; //min表示最小优先级的那个内存块号 int min_pri=0xffffff; for ( int m=0;m&lt;s1.work_len;m++) &#123; //和其他算法的区别只有优先级排序计算的方式不同 int n = s1.WorkSpace[m].priority; if (n &lt; min_pri) &#123; s1.change = m; min_pri = n; &#125; &#125; //表示发生替换变化的块号s1.change s1.WorkSpace[s1.change].seq = pointer; //设置新换入的页面优先级为work_len s1.WorkSpace[s1.change].priority = s1.e;&#125; $\qquad$在先入先出置换算法中每次新置换一个内存块将其优先级设置为工作区大小，之后每次运行一次，工作区中的所有内存块的优先级都减一，替换的时候找到优先级最小的替换就行了。 运行结果 四 最久未使用置换算法 实验源码请参考github中的LRU.h文件 算法描述 这种算法的基本思想是：利用局部性原理，根据一个作业在执行过程中过去的页面访问历史来推测未来的行为。它认为过去一段时间里不曾被访问过的页面，在最近的将来可能也不会再被访问。所以，这种算法的实质是：当需要淘汰一个页面时，总是选择在最近一段时间内最久不用的页面予以淘汰。 算法模拟 | 访问页面 | 4 | 4 | 3 | 5 | 6 | 3 | 6 | 7 | 9 | 7 | 10 | 9 | 11 | 12 | | ———— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | | 内存块1 | 4 | 4 | 4 | 4 | 5 | 4 | 4 | 4 | 9 | 9 | 9 | 9 | 9 | 9 | | 内存块2 | | | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 11 | 11 | | 内存块3 | | | | 5 | 5 | 5 | 5 | 5 | 5 | 5 | 10 | 10 | 10 | 10 | | 内存块4 | | | | | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 12 | | 内存块5 | | | | | | | | 7 | 7 | 7 | 7 | 7 | 7 | 7 | 算法实现 在概要设计中给出了各个算法的通用算法流程，但是各个算法在选择替换的内存块号的时候是不一致的。下面的是最久未使用置换算法中的实现。 1234567891011121314151617if (flag == 0)&#123; //min表示最小优先级的那个内存块号 int min_pri=-10000; for ( int m=0;m&lt;s1.work_len;m++) &#123; int n = SearchVisitSqe(s1.VisitSeq,i,s1.WorkSpace[m].seq,1,i); s1.WorkSpace[m].priority = n; if (n &gt; min_pri) &#123; s1.change = m; min_pri = n; &#125; &#125; //表示发生替换变化的块号s1.change s1.WorkSpace[s1.change].seq = pointer;&#125; $\qquad$在LRU算法中，使用函数SearchVisitSeq向访问序列中已经访问过的序列反向查找与当前页号相同的页号的距离，并将其最为优先级赋值给内存块，每次替换前更新所有的内存块的优先级；替换的时候找到优先级最大的进行替换。 运行结果 五 改进的Clock置换算法 算法描述 $\qquad$LRU算法的性能接近于OPT,但是实现起来比较困难，且开销大；FIFO算法实现简单，但性能差。所以操作系统的设计者尝试了很多算法，试图用比较小的开销接近LRU的性能，这类算法都是CLOCK算法的变体。 $\qquad$简单的CLOCK算法是给每一帧关联一个附加位，称为使用位。当某一页首次装入主存时，该帧的使用位设置为1;当该页随后再被访问到时，它的使用位也被置为1。对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。由于该算法循环地检查各页面的情况，故称为CLOCK算法，又称为最近未用(Not Recently Used, NRU)算法。 $\qquad$CLOCK算法的性能比较接近LRU，而通过增加使用的位数目，可以使得CLOCK算法更加高效。在使用位的基础上再增加一个修改位，则得到改进型的CLOCK置换算法。这样，每一帧都处于以下四种情况之一： 最近未被访问，也未被修改(u=0, m=0) 最近被访问，但未被修改(u=1, m=0) 最近未被访问，但被修改(u=0, m=1) 最近被访问，被修改(u=1, m=1) 算法执行如下操作步骤： + 从指针的当前位置开始，扫描帧缓冲区。在这次扫描过程中，对使用位不做任何修改。选择遇到的第一个帧(u=0, m=0)用于替换。 + 如果第1)步失败，则重新扫描，查找(u=0, m=1)的帧。选择遇到的第一个这样的帧用于替换。在这个扫描过程中，对每个跳过的帧，把它的使用位设置成0。 + 如果第2)步失败，指针将回到它的最初位置，并且集合中所有帧的使用位均为0。重复第1步，并且如果有必要，重复第2步。这样将可以找到供替换的帧。 算法模拟 | 访问页面 | 4 | 4 | 3 | 5 | 6 | 3 | 6 | 7 | 9 | 7 | 10 | 9 | 11 | 12 | | ———— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | —— | | 内存块1 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 4 | 10 | 10 | 10 | 12 | | 内存块2 | | | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 3 | 11 | 11 | | 内存块3 | | | | 5 | 5 | 5 | 5 | 5 | 9 | 9 | 9 | 9 | 9 | 9 | | 内存块4 | | | | | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | 6 | | 内存块5 | | | | | | | | 7 | 7 | 7 | 7 | 7 | 7 | 7 | 算法实现 改进的Clock算法比前几个算法来讲比较复杂，下面是其核心的实现过程， 12345678910111213141516171819202122232425262728293031323334353637if (flag == 0)&#123; //表示内存块中没有出现过 for(int t=0;t&lt;2;t++) &#123; int flag = 0; for (int m=0;m&lt;s1.work_len;m++) &#123; if (s1.WorkSpace[m].Used =='N' &amp;&amp; s1.WorkSpace[m].Modified =='N') &#123; s1.change =m; flag =1; break; &#125; &#125; if (flag == 0) &#123; for (int m=0;m&lt;s1.work_len;m++) &#123; if(s1.WorkSpace[m].Used =='N' &amp;&amp; s1.WorkSpace[m].Modified =='Y') &#123; s1.change = m; flag = 1; break; &#125; s1.WorkSpace[m].Used = 'N'; &#125; &#125; if(flag!=0) break; &#125; s1.WorkSpace[s1.change].seq = pointer; s1.WorkSpace[s1.change].Used = 'Y'; s1.WorkSpace[s1.change].Modified = 'N';&#125; 通过下面的流程图来解释该算法在选择替换物理块的时候的流程。 算法描述： 首先查找有没有(0，0)类型的页面，有的话替换该页面，没有的话进行第二步 查找有没有(0，1)类型的页面，有的话替换该页面，没有的话进行第三步 如果第一步第二步都没有找到的话就将所有页面的使用位都置为0然后重复第一步 运行结果 运行结果中的的第一个’Y/N’表示使用位,第二个’Y/N’表示修改位，@表示是新置换的页面 六 页面缓冲算法PBA 实验源码请参考github中的PBA.h 算法描述 $\qquad$严格意义上说PBA算法是一种页面缓冲算法，意义在于提高算法性能，减少从磁盘读取物理块到内存中的时间，提高算法的效率。而真正的页面置换算法采用的是前面所述的几种页面置换算法。本实验中采用的是FIFO置换算法。 $\qquad$在PBA算法中使用了两个队列，分别是使用空闲页面队列和修改页面队列。采用可变分配和基于先进先出的局部置换策略，并规定被淘汰页先不做物理移动，而是依据是否修改分别挂到空闲页面链表或已修改页面链表的末尾 $\qquad$空闲页面链表同时用于物理块分配。当已修改页面链表达到一定长度如Z个页面时，一起将所有已修改页面写回磁盘，故可显著减少磁盘I/O操作次数 算法模拟 算法实现 12345678910111213141516171819if (flag == 0)&#123; //min表示最小优先级的那个内存块号 int min_pri=0xffffff; for ( int m=0;m&lt;s1.work_len;m++) &#123; //和其他算法的区别只有优先级排序计算的方式不同 int n = s1.WorkSpace[m].priority; if (n &lt; min_pri) &#123; s1.change = m; min_pri = n; &#125; &#125; //表示发生替换变化的块号s1.change s1.WorkSpace[s1.change].seq = pointer; //设置新换入的页面优先级为work_len s1.WorkSpace[s1.change].priority = s1.e;&#125; $\qquad$PBA 算法在页面置换的时候算法实现和FIFO一致。这里不再赘述 运行结果]]></content>
      <categories>
        <category>操作系统实验</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pintos操作系统安装]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F02%2Fpintos-install%2F</url>
    <content type="text"><![CDATA[在QEMU虚拟机中安装pintos 下载pintos源码 1git clone http://cs140.stanford.edu/pintos.git 编译安装 123cd ~/pintos/src/threadsmake../utils/pintos --qemu -- run alarm-multiple 修改utils/pintos 脚本 1my (@cmd) = ('/usr/local/src/qemu/bin/qemu'); 将pintos脚本中第622行修改成如上图所示，引号中的内容是qemu可执行程序的绝对路径。 出现下面的截图说明正确安装好了]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qemu虚拟机的安装]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F02%2Fqemu%2F</url>
    <content type="text"><![CDATA[QEMU虚拟安装 下载源码 123git clone https://git.qemu.org/git/qemu.gitcd qemugit checkout v2.10.0 # 使用2.10.0版本 安装依赖库 1sudo apt-get install libsdl2-dev libsdl2-gfx-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-net-dev libsdl2-ttf-dev 1sudo apt-get install build-essential flex bison cmake automake libtool gcc-multilib g++-multilib libpixman-dev libfdt-dev 编译安装i386版本虚拟机 12345mkdir buildcd build../configure --prefix=/usr/local/src/qemu --target-list="i386-softmmu" --enable-debug --python=/usr/bin/python2makesudo make install 添加软连接 12cd /usr/local/src/qemu/bin/sudo ln -s qemu-system-i386 qemu]]></content>
      <tags>
        <tag>Pintos 操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pintos实验一全解]]></title>
    <url>%2Fsunpages%2F2019%2F04%2F02%2Fthread%2F</url>
    <content type="text"><![CDATA[操作系统Pintos 实验一 Thread 全解孙汉武 2019.04.02 内容简介操作系统课程的必修内容是实现斯坦福大学开发的pintos操作系统。通过对pintos的开发与运行，实现对操作系统各个部分的理解与深入。 本实验一律采用Ubuntu 16.04 Server版作为运行环境。 本教程旨在记录使用pintos实验一的全过程，涉及到安装、调试、开发等等方面，将持续进行更新，希望大家多多支持。 组员 刘 欢 16281044 计科1601 孙汉武 16281047 安全1601 杨涵晨 16281052 计科1601 王晗炜 16281049 计科1601 邢飞龙 16281050 计科1601 谭天云 16281048 计科1601 Pintos的安装与简介 安装准备：git，bochs，git和bochs的详细安装教程请自行google。 sudo apt-get install git 提醒bochs使用make命令前，请使用 ./configure --enable-gdb-stub --with-nogui命令安装命令行版的bochs工具。 pintos的源代码下载安装： pintos源码下载：git clone http://cs140.stanford.edu/pintos.git 当前目录将出现pintos文件夹 源码下载完毕后，目录结构(pintos/src)如下图所示 文件夹功能说明： threads:为基核准备的源代码，在实验一中我们会进行修改。 userprog:为装载用户程序的源代码，在实验二我们会进行修改。 vm:基本上空的目录，在实验三我们实现虚拟内存。 filesys:基本文件系统的源代码，从实验二开始使用，实验四开始修改。 devices:键盘、定时器、硬盘等等IO设备的接口源代码，在实验一中我们会修改定时器。其他情况我们不会进行修改。 lib:标准C库的子集实现。这个目录中的代码被编译到内核中，并且从实验二开始，用户程序也会在其下运行。在内核代码和用户程序中，我们可以使用#include&lt;...&gt;的方式引用这个目录中的header文件。我们基本上不用修改本目录中的源代码。 lib/kernal:这个目录中的代码仅被内核使用。还包含在内核代码中可以自由使用的一些数据类型的实现：位图、双向链表和哈希表。在内核代码中，我们可以使用#include&lt;...&gt;的方式引用这个目录中的header文件。 lib/user:这个目录中的代码仅被用户程序使用。在用户程序中，我们可以使用#include&lt;...&gt;的方式引用这个目录中的header文件。 test:每个项目的测试。如果它可以帮助您测试提交用例，可以自行修改。 examples:从实验二开始使用的示例用户程序。 misc &amp; utils:如果尝试在自己的计算机上运行Pintos才会用到这些文件。请在当前用户目录下的.zshrc或.bashrc文件中添加utils文件夹的环境变量。 编译Pintos，进入到threads目录，使用make命令 此时目录中将会出现一个build文件夹，里面包含了Makefile和一些子目录，随后在其中构建内核。在此我们分析一下build文件夹中的内容。 build文件夹内容分析： Makefile：pintos/src/Makefile.build的复制。它描述了如何构建内核。 kernel.o:整个内核的对象文件。这是将各个单独内核源文件编译目标文件链接到单个目标文件的结果。 kernel.bin:内核的内存映像，即加载到内存中运行Pintos内核的二进制文件。是被剥离调试信息的kernel.o，这节省了大量空间，使得内核不会被内核加载器512KB容量所限制。 loader.bin:内核加载器的内存映像，使用汇编语言编写的小块代码，用于将内核从磁盘读出内存并启动它。它刚好是512字节长度，大小被PC BIOS所固定。 构建的文件夹中同样包含子文件夹，子文件夹中的内容由.o与.d文件组成，分别对应编译器生成的目标文件与依赖项文件。依赖项告诉make在更改其他源文件或头文件时，需要重新编译哪些源文件。 运行pintos，使用命令pintos -v -- run alarm-multiple测试pintos样例 参数详解： ​ -v 关闭VGA显示 ​ -- 参数引导头 ​ run 调用运行命令 ​ alarm-multiple 内置测试样例 中途无报错即为安装成功。最后使用Control + c退出程序。 特别提醒，安装过程中非常容易出现各种各样的库缺失的报错现象，请大家按照报错提示，自行google处理。我遇到的问题是一个叫做warning: can&#39;t find squish-pty, so terminal input will fail的问题。解决方案是在pintos/src/utils目录中执行make命令后，使用sudo ln squish-pty /usr/local/bin/解决。 在安装成功pintos系统并通过基本的测试用例后，我们可以开始正式的实验了，接下来我将通过分模块的方式，依次记录各个实验的详细的步骤。如果你在安装过程中遇到了问题，并无法通过google解决，欢迎在文章下方留言，我会尽快回复。 Mission 1 ALARM CLOCK实验说明重新实现timer_sleep()，在devices / timer.c中定义。虽然当前代码提供了一个工作实现，但是它的实现方式我们称为“忙等待”，即它在循环中检查当前时间是否已经过去ticks个时钟，并循环调用thread_yield()直到循环结束。重新实现它以避免繁忙的等待。 暂停执行调用timer_sleep()的线程，暂停ticks个时钟。除非系统处于空闲状态，线程不需要在ticks个刻度之后唤醒，而将它放在就绪队列中。 timer_sleep()对于实时操作的线程很有用，例如每秒闪烁一次光标。timer_sleep()的参数以计时器刻度表示，而不是以毫秒或任何其他单位表示。每秒有TIMER_FREQ计时器刻度，其中TIMER_FREQ是在devices / timer.h中定义的宏。默认值为100，不建议更改此值，因为任何更改都可能导致许多测试失败。 在timer.c中，还存在timer_msleep()、timer_usleep()、timer_nsleep()函数，用于实现睡眠特定的毫秒、微秒和纳秒，但是它们会在必要时候调用timer_sleep()我们无需修改它们。 实验过程首先阅读源代码的timer_sleep()函数的实现原理： 当前执行进程调用timer_sleep(ticks)时，函数通过判断循环条件当前时间是否已经大于或等于了ticks个计数器刻度，如果条件不满足，则会调用thread_yield()函数，将当前进程直接加入到就绪队列，并调用进程切换的相关函数将CPU让给在就绪队列中的进程(如果就绪队列中有的话)。 可以发现，调用timer_sleep()的进程，在CPU就绪队列及CPU运行队列间来回切换，即尽管没有到ticks个计数器刻度，但CPU仍会通过激活改进程，以通过循环的方式来判断是否进程还需要再次执行thread_yield()，这个过程中，浪费了进程反复切换之间需要的CPU时间。 深入思考这个问题产生的原因，是尽管进程阻塞要求时间未到，但在该进程未被重新调度完成前，操作系统本身不知道到底进程被阻塞了多少计数器刻度。而解决这个问题的合理方式，我们也自然可以想到，在操作系统中描述进程的是struct thread，只要我们在这个进程PCB中记录了当前阻塞的时间和总共要被阻塞的时间或还要被阻塞多长时间，我们就可以在不切换进程前确认进程是否应该被加入就绪队列。 修改后的timer_sleep()函数如下： 我们在函数中，将要sleep的时间ticks传入到进程PCB中的ticks_blocked用于记录当前PCB指示的进程还需要阻塞多长时间。通过thread_block()函数，设置进程的阻塞状态，并调用进程切换。 既然引入了ticks_block这个变量，我们需要在结构体struct thread中加入对其的声明，并在进程创建函数thread_creade()加入对ticks_block赋初值0的操作。随后我们要做的就是在每个时钟中断时检查，哪些进程使block状态并且休眠时间还有剩余。值得注意的是，这里必须要求同时满足两个条件，因为操作系统中存在进程因为等待锁而阻塞的状态，这些进程并非因为主动调用timer_sleep()函数而阻塞。 所以接下来的工作就变成了，在系统时钟中断处理函数中加入进程检查函数，对因为timer_sleep()而阻塞的进程，执行阻塞时间自减或加入CPU就绪队列操作。首先寻找CPU时钟中断处理函数，在timer.c文件中： 首先，通过pit_configure_channel (0, 2, TIMER_FREQ)函数，向8254定时器设置了每秒执行TIMER_FREQ计时器刻度次的周期定时，使用的通道是0通道，计数方式是mode2即周期性脉冲。根据硬件编程，实现了计数器0向8259A芯片0号管脚发送中断请求的操作。由于CPU将0-15号中断向量占用，所以通过pic_init()函数，将中断0-15传送到32-47，具体的代码及注释如下。它在Boot引导完毕前执行完毕。 随后，通过intr_register_ext (0x20, timer_interrupt, &quot;8254 Timer&quot;)函数，我们向32中断向量注册了timer_interrupt()函数，这个函数就是每秒执行TIMER_FREQ次的时钟中断处理函数。即我们需要在这个函数中实现我们之前设计的逻辑。原函数如下图所示： 实现的功能一是CPU时钟计数自加。二是用户进程时间片用完后，当出现外部中断时，中断服务程序处理完毕后，阻塞进程执行(调用thread_yield()函数)。详细代码在interrupt.c的intr_handler()函数中。 我们在时钟中断处理函数中，加入一行即可，实现对每个进程都调用blocked_thread_check函数： 最后再实现blocked_thread_check函数，实现具体对传入进程的上述逻辑功能。 当当前待检进程为阻塞状态并且阻塞时间剩余大于0个计时器刻度时执行，剩余刻度自减。若减为0，调用thread_unblock函数将当前进程加入到就绪队列。 实验结果我们到/src/thread目录下执行make check，可以进行测试。 至此，MISSION_1 ALARM CLOCK编写完毕，执行测试有如下结果： Mission 2 PRIORITY SCHEDULING实验说明及过程本实验主要涉及的是进程的优先级调度问题，这里我们先找到线程结构的定义struct thread: 我们可以看到这里已经定义了线程优先级的数据成员：priority，这是进行优先级调度的基础，那么我们现在可以思考如何实现这一机制。 pintos中给出的调度函数schedule()中使用了next_thread_to_run()函数获取下一个需要调度执行的进程，当就绪队列中还存在进程则返回队列的首元素，而这个队列是怎么维护的呢？我们通过查找thread.c源程序中的与ready_list相关的函数我们可以发现有以下三个函数来向队列中添加成员： init_thread() thread_unblock() thread_yield() 它们都调用了函数list_push_back来增加队列中的成员，在list.c中我们可以找到此函数的具体实现：直接在队列的队尾插入。 如此一番调研之后我们就完全搞清楚了pintos的原始调度机制：先来先服务。这与我们所需要的优先级调度还存在较大差别，而在此基础上我们其实不难想出改进的方法：原始的线程结构体中已经给出了整数类型的优先级大小成员，我们只要能够通过比较各个线程的优先级大小维护一个优先级从大到小的优先级队列就能完成此种调度。 至此我们又有了两种思路： 每次调度之前对就绪队列根据优先级大小进行一次排序 每次插入成员之时按照优先级大小进行插入 很容易看出这两种方式都能达到目的，但后一种方式的效率要远远高于第一种方式。因此我们便开始着手实现第二种方式，而当我们继续浏览list.c文件时可以发现其中已经存在list_sort和list_insert_ordered函数，其功能分别为将列表排序和按序插入列表，我们在此自然选择使用其后一个插入函数，根据其传入的参数可知我们只需要重新实现一个比较函数（list_less_func *less）就可调用此函数完成优先级队列的维护。 下面给出优先级比较函数，根据传入的成员优先级大小返回一个布尔值。 至此我们初步完成了优先级队列的维护，这也是实现优先级调度的第一步。 继续阅读pintos官方文档种的优先级调度要求，我们可以看见如下一段话： Implement priority scheduling in Pintos. When a thread is added to the ready list that has a higher priority than the currently running thread, the current thread should immediately yield the processor to the new thread. Similarly, when threads are waiting for a lock, semaphore, or condition variable, the highest priority waiting thread should be awakened first. A thread may raise or lower its own priority at any time, but lowering its priority such that it no longer has the highest priority must cause it to immediately yield the CPU. 这段话中提到当就绪队列中存在一个优先级比当前线程优先级更高的线程时，系统要立刻进行调度，先执行优先级较高的线程，当优先级较高的线程存在的时候，优先级较低的线程一定会放弃CPU。 根据此要求结合我们阅读过的thread.c中的源代码，我们可以发现系统当前并不会对优先级大小的变化做到即时敏感：当有新的线程创建或者已有的线程优先级发生改变时系统并不会马上进行分析并调度，其中当创建新线程时它只会维护就绪队列，而队列中或当前线程优先级发生变化之时并不会有其它操作随之产生。 针对这一问题我们其实很快就能想出解决的方案：当任何与线程优先级改变相关的操作发生时，进行一个判断分析，若操作之后产生的新优先级高于当前线程的优先级，调用thread_yield函数进行线程调度并维护优先级队列，实现线程的抢占式调度。 根据此思路我们从源码中找出与优先级变化相关的函数，经过查找分析我们可以看到只有以下两个函数符合条件： 其中init_thread是初始化线程的函数，这属于我们分析的第一种情况：有新的线程产生，此时因为在函数的最后已经有对就绪队列维护的操作，因此我们只需判断其优先级大小是否高于当前线程，若高于则用thread_yield函数使当前线程放弃CPU。(因为函数在初始化时的状态为阻塞，需要在thread_create中调用unblock函数将其置于Ready状态，在这之后我们才能对其进行调度，因此此调度模块补充在thread_create函数中) 而thread_set_priority函数的作用使改变当前线程的优先级，而当优先级发生改变时影响就绪队列的情况十分常见，此时我们只需直接调用thread_yield函数便可完成对就绪队列的维护和线程的优先级调度。 下面给出修改之后这两个函数的代码： 完成了抢占式调度的涉及，我们接着分析pintos官方文档中的mission 2的任务指示，主要在2.2.3节中。 分析之后它主要提出了三个问题，我们先来看看这几个问题 When threads are waiting for a lock, semaphore, or condition variable, the highest priority waiting thread should be awakened first. A thread may raise or lower its own priority at any time, but lowering its priority such that it no longer has the highest priority must cause it to immediately yield the CPU. 总结来说就是，在有锁或者信号量的时候，我们如何安排进程优先级？ 在目前的pintos中 ，锁的申请机制较为简单，只涉及信号量的PV操作并设置锁的拥有线程，这里先给出lock_acquire的源码： 对于其他申请该锁的线程，并未在相关线程中记录，只是在信号量中维持了一个等待队列。 我们可以进一步探究这个队列的维护机制，查找与成员waiters相关的函数，我们可以发现只在信号量的PV操作中会对其进行操作，实现的机制和就绪队列一致：先来先服务。这无疑也不符合优先级调度的要求，我们需要在之后的实验中进行改进。 我们接着阅读官方给出的实验指导书： One issue with priority scheduling is “priority inversion”. Consider high, medium, and low priority threads H, M, and L, respectively. If H needs to wait for L (for instance, for a lock held by L), and M is on the ready list, then H will never get the CPU because the low priority thread will not get any CPU time. A partial fix for this problem is for H to “donate” its priority to L while L is holding the lock, then recall the donation once L releases (and thus H acquires) the lock. 这里涉及到的问题就是线程优先级的捐赠，我们通过以下案例分析对其进行说明： 刚开始有一个进程P_low 占用了CPU，并且申请了一个lock锁。这时有一个 P_med 进程进入了就绪队列，优先级比较高的进程, 根据thread_yield ()，P_low会让出cpu给P_med P_med 占用cpu，P_low放入等待队列ready_list,其还保存着对应的lock占用 此时P_high就绪，根据优先级调度其开始对CPU占用，P_med和P_low按序回到就绪队列中 那么，现在就会造成死锁。死锁存在于P_low-&gt;S_1-&gt;P_high之间。 至此我们可以得出结论：直接按照优先级调度的方式切换线程可能会造成死锁，结合就绪队列的调度机制会继续导致优先级处于二者之间的所有线程也被锁住。 死锁无疑造成操作系统的崩溃，因此必须给出一个解决的方案来破解。略经思考我们发现最高效的解决方案就是先运行其中一个线程，但这个操作也不能违背线程调度的优先级和锁机制。根据以上要求我们开始引入优先级捐赠机制。 根据实验指导书，优先级捐赠的机制如下：当发现高优先级的任务因为低优先级任务占用资源而阻塞时，就将低优先级任务的优先级提升到等待它所占有的资源的最高优先级任务的优先级。而当被捐赠线程释放该锁之后其优先级需要恢复至原始的优先级。 继续阅读余下的指导书。 You will need to account for all different situations in which priority donation is required. Be sure to handle multiple donations, in which multiple priorities are donated to a single thread. You must also handle nested donation: if H is waiting on a lock that M holds and M is waiting on a lock that L holds, then both M and L should be boosted to H’s priority. 这简短的一段话又给我们抛出了两个在优先级捐赠中会出现的问题： 如何实现多个线程对单个线程的优先级捐赠 如何实现多个线程之间的递归优先级捐赠 第一点的情况较为容易理解，我们在这里使用一个简单的案例介绍递归捐赠： P_Low正在占用锁Lock1,P_Med正在占用锁Lock2，P_Med正在申请Lock1，此时便会进行优先级的捐赠，P_Low的优先级变为Med，此时P_High开始申请Lock2,P_Med的优先级则会变为High，通过递归捐赠，P_Low的优先级也会变为High。 以上两点其实并不属于当前调度过程中存在的问题，需要我们在实现优先级捐赠时注意。 经过上面的问题分析，和对应的源代码分析，我们对这个任务余下的待实现需求做一个总结： 优先级队列 维持一个ready_list 优先级排队队列 将condition的waiters队列实现为优先级队列。 将信号量的等待队列实现为优先级队列。 单锁实现 当发现高优先级的任务因为低优先级任务占用资源而阻塞时，就将低优先级任务的优先级提升到等待它所占有的资源的最高优先级任务的优先级。 释放锁的时候若优先级改变则可以发生抢占。 多锁实现 如果一个线程被多个线程捐赠， 维持当前优先级为捐赠优先级中的最大值（acquire和release之时） lock 锁被释放的时候， 高进程应该收回优先级捐赠，并且停止unblock状态。 在对一个线程进行优先级设置的时候， 如果这个线程处于被捐赠状态， 则对base_priority进行设置， 然后如果设置的优先级大于当前优先级， 则改变当前优先级， 否则在捐赠状态取消的时候恢复base_priority。 在释放锁对一个锁优先级有改变的时候应考虑其余被捐赠优先级和当前优先级。 捐赠时间 线程处于ready_list中等待时 线程处于sleep状态，也就是block状态时，也可以改变优先级 基于以上需求，我们开始对pintos中的源码进行修改。 在上文的分析中我们就可以得知：若存在优先级的捐赠则必然会存在释放锁后被被捐赠线程的优先级恢复，因此单单在thread结构体中使用一个成员priority是无法完成的，我们需要一个额外的成员来储存线程在被捐赠之前的优先级，也就是base_priority。经过以上的实验我们也可发现原始thread结构体中并未设计与锁相关的成员变量（原l始的锁和信号量队列与优先级无关，和就绪队列一样属于先来先服务，不需要在结构体中添加这些），因此我们还需要在线程的结构体中添加两个成员变量：locks和lock_waiting，分别代表线程已经拥有的锁和正在申请的锁，前者为一个队列，后者只需设置为锁类型（lock）的变量，下面给修改后的thread结构体： 既然线程结构体中缺乏与锁相关的成员，自然锁结构体中也缺乏与线程相关的成员，我们找到lock的源码可以发现其中只存在两个成员：holder和semaphore，即拥有者和信号量，这对于实现优先级调度和优先级捐赠来说肯定是不够的，我们需要继续增加两个成员变量：elem和max_priority。这两个成员代表的意义也很好理解：前者是当前线程在信号量队列中位置（在原始的队列中，当前线程一定位于队列的首部），后者则是表示该锁的信号量队列中线程的最高优先级（用于优先级的捐赠），下面也给出修改过后的lock结构体代码： 有了这些修改过后的结构体我们就可以开始实现与锁相关的优先级调度程序。 因为前面涉及到了结构体的修改，那么我们势必要对其初始化函数进行修改，所以我们先对lock_init和init_thread进行修改，完成以上几项的初始化： 接下来我们不妨分析以下涉及锁的线程调度过程，根据之前阅读的代码，可以用以下流程图来梳理我们需要实现的过程： 根据流程图，我们首先着眼于lock_acquire函数，在锁的申请时我们首先考虑的就是锁是否已经被线程占用，若锁未被占用则直接将此线程占用该锁，对信号量进行P操作，而当该锁存在线程占用时，我们就需要将该锁的最大优先级和此线程的优先级进行比较，若此线程的优先级高则要进行优先级的捐赠，随后在被插入信号量的等待队列中。 所以我们这里需要先实现一个优先级捐赠函数thread_donate_priority，它的功能其实只有两个： 改变线程当前的优先级 若该线程处于就绪队列中需要对就绪队列重排 第一个任务很容易使我们想到之前实现抢占式调度时修改过的thread_set_priority函数，但仔细分析后我们可以发现此函数的逻辑并不适用与此：当前线程的优先级大小不仅和其本身的优先级相关，还与捐赠线程的优先级大小相关，之前修改的函数的本意其实是修改当前运行线程（这就意味着线程的状态一定为RUNNING，因此修改过后我们可以根据调整的优先级大小直接判断其是否调用thread_yield）的base_priority而非priority，且在原来的设置中，并不能指定任意线程进行修改。因此我们需要再次编写一个函数对任意线程的当前优先级进行更新，不过再次之前我们无疑要再次对thread_set_priority函数进行修改，设置base_priority并判断是是否满足重新调度的条件（没有锁约束或当前优先级发生改变），下面给出修改后的代码： 之后我们定义一个thread_update_priority函数来更新线程的当前优先级（我们目前只认为线程的当前优先级只会在捐赠优先级的条件下发生改变），此函数的功能也较为简单：将线程的base_priority和其所有锁的最大优先级进行比较，将当前优先级设置为其中的最大值。如此实现的优先级捐赠适用于多个线程对单个线程的优先级捐赠，而这里我们唯一的难点就是如何获取其所有锁的最大优先级的最大值，但稍加分析我们也能依照之前的方法简单实现：将locks（线程的锁队列）维护成一个优先级有序队列再取出第一个成员的优先级即可，维护的方法和就绪队列稍有不同，使用了前文提到的list_sort方式（此队列优先级改变的情况较为复杂，用插入的方式容易出现问题），下面一并给出排序函数和优先级更新函数的代码： 拥有锁的线程不一定是当前正在占用CPU的线程，因此我们还需考虑一种情况：此线程正处于优先队列之中，完成了更新之后我们必须重新对就绪队列进行维护。至此我们的捐赠函数的逻辑就完全设计完成 了，下面给出其完整代码： 至此我们退回lock_acquire函数，这里我们还需注意的是优先级的捐赠是一个递归的问题，我们需要将其关联的每一层锁的拥有线程调整为不比此线程低的优先级，这里我们会用一个while结构加以实现。解决了优先级捐赠的问题，我们可以开始进行信号量的P操作，这也不用太多赘述，我们只需再原有基础上将信号量的队列也维护成优先级有序队列，实现方式和就绪队列一致。 获取锁的最后一步就是将此线程变为锁的拥有者，但这一过程也并能沿用当前的方式，因为这会涉及到锁的最大优先级的改变：当一个线程拥有一个锁时，其优先级一定为此锁的最大优先级（包括优先级捐赠的情况）。接着我们还需要把该锁插入至线程的锁队列中，并修改锁的holder成员为当前线程。基于以上逻辑编写了函数thread_hold_the_lock。至此lock_acquire的编写随之完成，以下为两个函数的源码： 这里我们完成了获取锁的全部逻辑，接着只要补全释放锁的逻辑即可。相较于lock_acquire，lock_release的逻辑显得更简单一些，这里我们只需做三件事： 将对应锁从线程的锁队列中清除（线程脱离锁） 将锁设置为不被任何线程占用（锁脱离线程） 进行信号量的V操作 这三步都较为简单，第一步这里编写了一个`thread_remove_lock函数来实现，主要功能也很容易想到：将该所从其锁队列中移除，更新线程的优先级（若处于被捐赠的状态，还回此锁捐赠的优先级），实现代码如下： 第二步就更为简单，只需将lock的holder成员设置为NULL即可。 对于第三步，我们则要对原始的sema_up函数进行修改，其与sema_down函数的唯一不同点在于在对信号量序列中的最高优先级线程进行了unblock操作并改变信号量值之后需要马上使用thread_yield函数来保证抢占式调度。下面给出sema_up和lock_release函数的源代码： 以上就完成了mission2的全部代码编写，下面可以开始对其进行测试： 实验结果我们到/src/thread目录下执行make check，可以进行测试。 至此，MISSION_2 PRIOTITY SCHEDULING编写完毕，执行测试有如下结果： Mission 3 ADVANCED SCHEDULER实验说明实现类似于BSD调度程序的多级反馈队列调度程序，以减少在系统上运行作业的平均响应时间。 与优先级调度调度程序一样，高级调度程序同样基于进程的优先级来调度进程。但是高级调度程序不会执行优先级捐赠。必须编写必要的代码，以允许在Pintos启动时选择调度算法策略。 默认情况下，优先级调度程序必须处于活动状态，但必须能够使用-mlfqs内核选项选择4.4BSD调度程序。 在main()函数中parse_options()解析选项时，传递此选项会将threads / thread.h中声明的thread_mlfqs设置为true。 启用4.4BSD调度程序后，线程不再直接控制自己的优先级。 应忽略thread_create()的优先级参数，以及对thread_set_priority()的任何调用，并且thread_get_priority()应返回调度程序设置的线程的当前优先级。 高级调度程序不会在以后的任何项目中使用。 非常重要：可以在附录B中找到关于BSD调度程序的详细说明，这是我们编程的唯一指导基础。 实验指导通用调度程序的目标是平衡线程的不同调度需求。 执行大量I / O的线程需要快速响应时间以保持输入和输出设备忙，但需要很少的CPU时间。 另一方面，绑定计算的线程需要花费大量CPU时间来完成其工作，但不需要快速响应时间。 其他线程介于两者之间，I / O周期被计算周期打断，因此需求随时间变化。 精心设计的调度程序通常可以同时满足具有所有这些要求的线程。 对于项目1，必须实现附录B中描述的调度程序。 调度程序类似于[McKusick]中描述的调度程序，它是多级反馈队列调度程序的一个示例。 这种类型的调度程序维护几个可立即运行的线程队列，其中每个队列包含具有不同优先级的线程。 在任何给定时间，调度程序从最高优先级的非空队列中选择一个线程。 如果最高优先级队列包含多个线程，则它们以“循环”顺序运行。 调度程序的多个方面需要在一定数量的计时器滴答之后更新数据。 在每种情况下，这些更新应该在任何普通内核线程有机会运行之前发生，这样内核线程就不可能看到新增的timer_ticks()值而是旧的调度程序数据值。 4.4BSD调度程序不包括优先捐赠。 Niceness线程优先级由调度程序使用下面给出的公式动态确定。 但是，每个线程还有一个整数nice值，用于确定线程对其他线程的“好”程度。nice值为0不会影响线程优先级。 nice值从1至20，会降低线程的优先级，并导致它放弃一些原本会收到的CPU时间。 另一种情况，nice值从-20到-1，往往会从其他线程中抢占CPU时间。 初始线程nice值为0。 其他线程初始值从其父线程继承nice值。 必须实现下面描述的功能，供测试程序使用。 在threads / thread.c中为它们提供了框架定义。 12345// 返回当前进程的nice值int thread_get_nice (void);// 设置当前进程的nice值为new_nice，并重新计算进程的优先级，若正在运行的进程不再是最高优先级，则阻塞void thread_set_nice (int new_nice); 计算 Priority我们的调度程序有64个优先级，因此有64个就绪队列，编号为0（PRI_MIN）到63（PRI_MAX）。 较低的数字对应较低的优先级。因此优先级0是最低优先级，优先级63是最高优先级。 线程优先级最初在线程初始化时计算。 对于每个线程，每四个时钟周期也会重新计算一次。 在任何一种情况下，都由公式确定 priority=PRI\_MAX-(recent\_cpu/4)-(nice*2)recent_cpu是线程最近使用的CPU时间的估计值（见下文），而且公式中的nice值为当前进程的nice值。 结果应向下舍入到最接近的整数（截断）。 recent_cpu和nice的系数1/4和2，分别被发现在实践中很好地工作但缺乏更深的含义。 计算得到的优先级始终为位于PRI_MIN到PRI_MAX的有效范围内。 此公式为线程重新计算优先级提供了依据。 这是防止饥饿的关键：最近没有收到任何CPU时间的线程的recent_cpu值为0，除非有一个很高的nice值，否则它会很快就会收到CPU运行时间。 计算 recent_cpu我们希望recent_cpu可以表征每个进程“最近”收到多少CPU运行时间。此外，作为一种改进，最新收到的CPU时间应该比其之前的CPU时间权重更大。 一种方法是使用n个元素的数组来跟踪在最后n秒的每一个中接收的CPU时间。 然而，这种方法每线程需要O(n)空间，并且每次计算新加权平均值需要O(n)时间。 相反，我们使用指数加权移动平均线，它采用这种一般形式： x(0)=f(0),\\x(t)=ax(t-1)+(1-a)f(t),\\a=k/(k+1)其中x(t)是整数时间t≥0的移动平均值，f(t)是被平均的函数，k &gt; 0控制衰减速率。我们可以通过以下几个步骤迭代公式： x(1)=f(1),\\x(2)=af(1)+f(2),\\.\\.\\.\\x(5)=a^4f(1)+a^3f(2)+a^2f(3)+af(2)+f(5)f(t)的值在时间 t 的权重为1，在时间 t + 1 的权重为 a，在时间 t + 2 的权重为 2，等等。我们还可以将x(t)与 k 相关联：f(t)在时间 t + k 具有大约 1 / e 的权重，在时间 t + 2k 具有大约1 / e2 等等。从相反方向，f(t)在时间 t + loga w 衰减到 f(t)*w。 在创建的第一个线程中，recent_cpu的初始值为0，或者在其他新线程中为其父进程值。 每次发生定时器中断时，除非空闲线程正在运行，否则recent_cpu仅对正在运行的线程递增1。 此外，每秒一次，使用以下公式为每个线程（无论是运行，准备还是阻塞）重新计算recent_cpu的值： recent\_cpu=(2*load\_avg)/(2*load\_avg+1)*recent\_cpu+nice，其中load avg是准备运行的线程数的移动平均值（见下文）。 如果load avg为 1 ，表示单个线程正在竞争CPU，那么recent_cpu的当前值在log2 / 3 0.1 ≈ 6秒内衰减到原值的 0.1。 如果load_avg为2，则衰减到原值的 0.1需要 log3 / 4 0.1 ≈ 8秒。 结果是recent_cpu估计了线程“最近”收到的CPU时间量，衰减率与竞争CPU的线程数成反比。 某些测试所做的假设要求在系统计数器每达到一秒完全重新计算recent_cpu，即条件timer_ticks () % TIMER_FREQ == 0成立。 对于具有负nice值的线程，recent_cpu的值可能为负。 不要将负的recent_cpu设置为0。 需要考虑此公式中的计算顺序。先计算recent_cpu的系数，然后再做乘法，否则可能会产生溢出。 必须实现在threads/thread.c中的thread_get_recent_cpu()函数。 12// 返回当前线程recent_cpu值的100倍，四舍五入到最接近的整数int thread_get_recent_cpu (void); 计算 load_avg最后，load_avg（通常称为系统负载平均值）估计在过去一分钟内，在准备队列中的平均线程数。 像recent_cpu一样，它也是指数加权移动平均。 与priority和recent_cpu不同，load_avg是系统范围的，而不是特定于线程的。 在系统启动时，它被初始化为0。此后每秒一次，根据以下公式更新： load\_avg=(59/60)*load\_avg+(1/60)*ready\_threads，ready_thread是在更新时运行或准s备运行的线程数（不包括空闲线程）。 有些测试假设当计时器达到1秒倍数时，即当timer_ticks()%TIMER_FREQ == 0时，必须要重新更新load_avg，而不是在其它时间。必须实现位于threads/thread.c中的函数： 12// 返回当前系统 load_avg 的100倍，四舍五入到最接近的整数int thread_get_load_avg(void); 总结以下公式总结了实现高级调度程序所需的计算。 它们不是调度程序要求的完整描述。 每个线程在-20和20之间具有nice值。 每个线程也有一个优先级，介于0(PRI_MIN)到63(PRI_MAX)之间，每四个滴答使用以下公式重新计算： priority=PRI\_MAX-(recent\_cpu/4)-(nice*2).recent_cpu测量一个线程“最近”收到的CPU时间量。在每个CPU时钟中，正在运行的线程的recent_cpu增加1。每秒一次，每个线程的rencent_cpu以这种方式更新： recent\_cpu=(2*load\_avg)/(2*load\_avg+1)*recent\_cpu+nice.load_avg估计在过去一分钟内准备运行的平均线程数。 它在启动时初始化为0，并按每秒重新计算一次，如下所示： load\_avg=(59/60)*load\_avg+(1/60)*ready\_threads.ready_threads是在更新时运行或准备运行的线程数（不包括空闲线程）。 定点小数及其计算在上面的公式中，priority、nice和ready_thread是整数，但是recent_cpu和load_avg是实数。 但是，Pintos不支持内核中的浮点运算，因为它会使内核变得复杂和变慢。 出于同样的原因，真正的内核通常具有相同的限制。 这意味着必须使用整数模拟实数的计算。 本节介绍基础知识。 其基本思想是将整数的最右边的几位视为表示分数。例如，我们可以将带符号的32位整数的最低14位指定为小数位，这样整数x代表实数 x/214 。这个叫做 17.14 定点数，最大能够表示 (231-1)/214 ，近似 131071.999 。 假设我们使用 p.q 的定点数格式，并且设 f=2q 。根据上面的定义，我们可以通过乘以 f 将整数或实数转换为 p.q 格式。例如，基于17.14 格式的定点数转换 59/60 ，(59/60)214 = 16110。将定点数转换为整数则除以 f 。 C中的“/”运算符向零舍入，也就是说，它将正数向下舍入，向负数向上舍入。要舍入到最近，将 f / 2 先与正数相加再除，或者先在负数中减去 f / 2 再除。 下表总结了如何在C中实现定点算术运算。在表中，x和y是定点数，n是整数，定点数是带符号的p.q格式，其中p + q = 31，和f是1 &lt;&lt; q： 实验过程根据实验说明，我们可以知道bool变量thread_mlfqs指示是否启用高级调度程序，并且高级调度程序不应包含优先级捐赠的内容，所以，在Mission_2中实现的优先级捐赠代码，需要使用if判断以保证在使用高级调度程序时，不启用优先级捐赠。随后，我们可以根据实验指导中的详细说明一步步完成本次实验。 首先，根据上述给定点数的计算方法，编写定点数的计算方法，实现 16.15 格式定点数计算方法。 123456789101112131415161718192021222324252627/* Basic definitions of fixed point. */typedef int fixed_t;/* 16 LSB used for fractional part. */#define FP_SHIFT_AMOUNT 16/* Convert a value to fixed-point value. */#define FP_CONST(A) ((fixed_t)(A &lt;&lt; FP_SHIFT_AMOUNT))/* Add two fixed-point value. */#define FP_ADD(A,B) (A + B)/* Add a fixed-point value A and an int value B. */#define FP_ADD_MIX(A,B) (A + (B &lt;&lt; FP_SHIFT_AMOUNT))/* Substract two fixed-point value. */#define FP_SUB(A,B) (A - B)/* Substract an int value B from a fixed-point value A */#define FP_SUB_MIX(A,B) (A - (B &lt;&lt; FP_SHIFT_AMOUNT))/* Multiply a fixed-point value A by an int value B. */#define FP_MULT_MIX(A,B) (A * B)/* Divide a fixed-point value A by an int value B. */#define FP_DIV_MIX(A,B) (A / B)/* Multiply two fixed-point value. */#define FP_MULT(A,B) ((fixed_t)(((int64_t) A) * B &gt;&gt; FP_SHIFT_AMOUNT))/* Divide two fixed-point value. */#define FP_DIV(A,B) ((fixed_t)((((int64_t) A) &lt;&lt; FP_SHIFT_AMOUNT) / B))/* Get integer part of a fixed-point value. */#define FP_INT_PART(A) (A &gt;&gt; FP_SHIFT_AMOUNT)/* Get rounded integer of a fixed-point value. */#define FP_ROUND(A) (A &gt;= 0 ? ((A + (1 &lt;&lt; (FP_SHIFT_AMOUNT - 1))) &gt;&gt; FP_SHIFT_AMOUNT) \ : ((A - (1 &lt;&lt; (FP_SHIFT_AMOUNT - 1))) &gt;&gt; FP_SHIFT_AMOUNT)) 由于本实验涉及到的公式均与时钟中断有关，所以，我们将上述的公式迭代计算的相关代码，写入我们在Mission_1中详细介绍过的timer_interrupt()时钟中断处理函数中。其原函数为： 之前已经接介绍过，本实验在thread_mlfqs变量为true的情况下进行。所以，我们需要通过if对此条件进行判断，以免影响其他实验的正常运行。 包括，每个时钟中断都更新的recent_cpu、每一秒更新的load_avg、每四个时钟更新一次的priority，如下图所示。接下来，我们分别介绍这些函数。 首先是thread_mlfqs_increase_recent_cpu_by_one(void)，若当前进程不是空闲进程则当前进程加1，注意定点数加法。 接下来是thread_mlfqs_update_load_avg_and_recent_cpu(void)函数，首先根据就绪队列的大小计算load_avg的值，随后根据load_avg的值，更新所有进程的recent_cpu值及priority值。 最后，通过thread_mlfqs_update_priority (struct thread *t)函数，更新当前进程的priority值，注意，一定要保证每个线程的优先级介于0(PRI_MIN)到63(PRI_MAX)之间。 最后到了收尾工作，我们要在struct thread结构体中加入nice和recent_cpu这两个变量，其完整的定义如下： 并在init_thread()线程初始化时，将nice与recent_cpu置零。注意recent_cpu是定点数0。我们需要在thread.c中定义全局变量load_avg，注意是定点数类型。在thread_start()函数中初始化为0。 根据上述指导内容，在thread.c中将需要我们实现的函数全部写入。 实验结果我们到/src/thread目录下执行make check，可以进行测试。 至此，MISSION_3 ADVANCED SCHEDULER编写完毕，执行测试有如下结果： 致谢撰写本文的目的在于记录小组pintos实验一过程， 斯坦福官方实验指导书， Pintos-斯坦福大学操作系统Project详解 在此特别感谢以上作者。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程实验二]]></title>
    <url>%2Fsunpages%2F2019%2F03%2F21%2Flab3%2F</url>
    <content type="text"><![CDATA[实验三 实验报告 孙汉武 安全1601 16281047 实验源代码链接 Task 11.1 实验要求$\qquad$通过fork的方式，产生4个进程P1,P2,P3,P4，每个进程打印输出自己的名字，例如P1输出“I am the process P1”。要求P1最先执行，P2、P3互斥执行，P4最后执行。通过多次测试验证实现是否正确。 1.2 实验过程 实验源码 Task1.c 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;#include&lt;semaphore.h&gt;#include&lt;fcntl.h&gt;int main()&#123; sem_t *P1_signal,*P2_signal,*P3_signal; //主函数中的进程是P1 pid_t p2,p3,p4; P1_signal=sem_open("P1_signal",O_CREAT,0666,0); P2_signal=sem_open("P2_signal",O_CREAT,0666,0); P3_signal=sem_open("P3_signal",O_CREAT,0666,0); p2=fork();//创建进程P2 if(p2&lt;0) &#123; perror("创建进程p2出错！"); &#125; if(p2==0) &#123; sem_wait(P1_signal); printf("I am the process P2!\n"); sem_post(P1_signal); sem_post(P2_signal); &#125; if(p2&gt;0) &#123; p3=fork(); if(p3&lt;0) &#123; perror("创建进程p出错！"); &#125; if(p3==0) &#123; sem_wait(P1_signal); printf("I am the process P3!\n"); sem_post(P1_signal); sem_post(P3_signal); &#125; if(p3&gt;0) &#123; printf("I am the process P1!\n"); sem_post(P1_signal); p4=fork(); if(p4&lt;0) &#123; perror("创建进程p4出错！"); &#125; if(p4==0) &#123; sem_wait(P2_signal); sem_wait(P3_signal); printf("I am the process P4!\n"); sem_post(P2_signal); sem_post(P3_signal); &#125; &#125; &#125; sem_close(P1_signal); sem_close(P3_signal); sem_close(P2_signal); sem_unlink("P1_signal"); sem_unlink("P2_signal"); sem_unlink("P3_signal"); return 0;&#125; 原理解释 前趋图 前驱关系：`P1--&gt;P2`、`P1--&gt;P3`、`P2--&gt;P4`、`P3--&gt;P4` 前驱关系实现 题目要求产生的四个进程必须是P1最先执行，P2、P3在P1执行完后互斥执行，P4最后执行。于是根据要求有了上面的前驱关系和前驱图。但是如何实现这种进程间的前驱关系呢？比较自然的想到了是用信号量机制。如上面的代码所示，定义了三个信号量，P1_signal、P2_signal和P3_signal，其初值均为0 123P1_signal=sem_open("P1_signal",O_CREAT,0666,0); P2_signal=sem_open("P2_signal",O_CREAT,0666,0); P3_signal=sem_open("P3_signal",O_CREAT,0666,0); P1进程执行完打印任务之后对P1_signal信号量进行V操作，产生一个资源让等待P1_signal的进程P2和P3其中之一可以执行。由于P2和P3都是等待P1_signal信号量，但是P1进程只产生一个单位的信号，所以P2和P3的执行是互斥的，这样就满足了题目要求。最后在P2和P3执行完打印任务后对信号量P2_signal和P3_signal进行V操作从各产生一个单位的信号量，而进程P4会等待P2_signal和P3_signal，所以知道当P2和P3进程都完成才能进行P4进程。通过控制这三个信号量，这四个进程之间的前驱关系就满足了题目要求。 ![](http://ipic-picgo.oss-cn-beijing.aliyuncs.com/2019-04-29-173752.jpg) 进程产生实现 根据题目要求，通过fork的方式产生四个进程。fork函数会从当前位置复制进程，并且在父进程中返回的pid为复制进程的真实pid，在子进程中返回的pid为0。了解这些知识之后可以得到如下的流程图： 下面的流程图仅表示进程间的关系，前驱关系的实现请看上一小节. 进程树 编译源码 通过下面的命令编译源码，得到可执行程序 1gcc -g task1.c -o task1 -lpthrea 1.3 实验结果$\qquad$通过上面的实验已经得到满足实验要求的可执行程序task1,下面给出运行结果，经过多次测试，四个进程在屏幕上打印的顺序只有两种结果，分别如下： 顺序1：P1--&gt;P2--&gt;P3--&gt;P4 顺序2：P1--&gt;P3--P2--&gt;P4 1.4 现象解释$\qquad$测试的实验结果中出现两种执行顺序，通过1.2 节中的分析不难解释这种现象，由于P1是P2和P3的前驱，所以P1一定会在P2和P3之前执行，但是P2和P3是互斥关系，这两个进程谁先获得P1产生的信号量谁就先执行另一个进程等待。最后等P2和P3都执行完了再执行P4，所以会出现上面的两种执行顺序。 Task 22.1 实验要求$\qquad$火车票余票数ticketCount 初始值为1000，有一个售票线程，一个退票线程，各循环执行多次。添加同步机制，使得结果始终正确。要求多次测试添加同步机制前后的实验效果。 2.2 实验过程2.2.1未添加同步机制 实验源码 task2_1.c: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;#include&lt;semaphore.h&gt;#include&lt;sys/stat.h&gt;#include&lt;fcntl.h&gt;#include&lt;string.h&gt;int ticketCount=1000;void *SaleThread(void *arg)&#123; int num,temp; num=atoi(arg); for(int i=0;i&lt;num;i++) &#123; if(i % 10 ==0) printf("卖%d张票,剩余%d张票\n",i,ticketCount); temp=ticketCount; //放弃CPU，强制切换到另外一个进程 pthread_yield(); temp=temp-1; pthread_yield(); ticketCount=temp; &#125; return NULL;&#125;void *RefundThread(void *arg)&#123; int num,temp; num=atoi(arg); for(int i=0;i&lt;num;i++) &#123; if(i % 10 ==0) printf("退%d张票，剩余%d张票\n",i,ticketCount); temp=ticketCount; pthread_yield(); temp=temp+1; pthread_yield(); ticketCount=temp; &#125; return NULL;&#125;int main(int argc,char *argv[])&#123; if(argc!=3) &#123; printf("请正确输入参数！\n"); exit(0); &#125; printf("初始票数为：%d\n",ticketCount); pthread_t p1,p2; /* printf("%s %s",argv[1],argv[2]); */ pthread_create(&amp;p1,NULL,SaleThread,argv[1]); pthread_create(&amp;p2,NULL,RefundThread,argv[2]); pthread_join(p1,NULL); pthread_join(p2,NULL); printf("最终票数为：%d\n",ticketCount); return 0;&#125; 程序解释 在main函数中创建两个线程，分别是模拟售票的线程SaleThread和模拟退票的线程RefundThread，两个进程并发执行，不添加任何的同步机制。 模拟票数的变量ticketCount是全局变量 程序运行需要输入两个参数，第一个是售票数量，第二个数退票数量 程序运行结果 编译上述程序，得到可执行程序task2_1 1gcc -g task2_1.c -o task2_1 -lpthread 多次测试运行，运行结果可以分为两种类型，一种是售票数量比退票数量多，另一种是售票数量比退票数量少。两种情况的结果分别如下： 售票数量比退票数量多： 初始票数：1000 售票：100 退票：40 售票数量比退票数量少： 初始票数：1000 售票：50 退票：80 实验现象归纳 通过一系列的测试，归纳出的实现现象如下： 当售票数量大于退票数量的时候，最终票数等于总票数减去售票数 当售票数量小于退票数量的时候，最终票数等于总票数加上退票数 2.2.2 添加同步机制 实验源码 task2_2.c 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;#include&lt;semaphore.h&gt;#include&lt;sys/stat.h&gt;#include&lt;fcntl.h&gt;#include&lt;string.h&gt;volatile int ticketCount=1000;sem_t *flag=NULL;void *SaleThread(void *arg)&#123; int num,temp; num=atoi(arg); for(int i=0;i&lt;num;i++) &#123; if(i % 10 ==0) printf("卖%d张票,剩余%d张票\n",i,ticketCount); sem_wait(flag); temp=ticketCount; //放弃CPU，强制切换到另外一个进程 pthread_yield(); temp=temp-1; ticketCount-=1; pthread_yield(); ticketCount=temp; sem_post(flag); &#125; return NULL;&#125;void *RefundThread(void *arg)&#123; int num,temp; num=atoi(arg); for(int i=0;i&lt;num;i++) &#123; if(i % 10 ==0) printf("退%d张票，剩余%d张票\n",i,ticketCount); sem_wait(flag); temp=ticketCount; pthread_yield(); temp=temp+1; ticketCount+=1; pthread_yield(); ticketCount=temp; sem_post(flag); &#125; return NULL;&#125;int main(int argc,char *argv[])&#123; if(argc!=3) &#123; printf("请正确输入参数！\n"); exit(0); &#125; flag=sem_open("flag",O_CREAT,0666,1); printf("初始票数为：%d\n",ticketCount); pthread_t p1,p2; printf("%s %s",argv[1],argv[2]); pthread_create(&amp;p1,NULL,SaleThread,argv[1]); pthread_create(&amp;p2,NULL,RefundThread,argv[2]); pthread_join(p1,NULL); pthread_join(p2,NULL); printf("最终票数为：%d\n",ticketCount); sem_close(flag); sem_unlink("flag"); return 0;&#125; 程序解释 task2_2.c在task2_1.c的基础上增加了同步机制，其他部分完全一致，通过信号量flag的控制，让售票线程和退票线程一次只能执行一个，在一个没有执行完成之前另一个不能进入执行，这样就保证了售票操作和退票操作的原子性，避免了脏数据的读取。 flag初始值为设置为1，表示每次只允许一个线程操作ticketCount这个数据 售票线程和退票线程在进入操作之前都要sem_wait(flag)，等待信号量，在完成操作之后要sem_post(flag)，下图是售票线程中增加了信号量的操作： 程序运行结果 编译上述程序，得到可执行程序task2_2 1gcc task2_2.c -o task2_2 -lpthread 多次测试运行，测试主要分为两种类型，一种是售票数量比退票数量多，另一种是售票数量比退票数量少。两种情况的结果分别如下： 售票数量比退票数量多： 初始票数：1000 售票：100 退票：40 退票数量比售票数量多： 初始票数：1000 售票：50 退票：80 实验现象归纳 在第一个测试样例中，初始票数为1000，售票100并且退票40，最终总票数为940，结果正确； 在第二个测试样例中，初始票数为1000，售票50并且退票80，最终总票数为1030，结果正确。 通过上面的测试结果可以看出，不论是售票数量比退票数量多还是少，都不会发生类似前面2.2.1的问题，最终的票数是期待得到的结果。 上面的实验证实了增加了同步机制之后的多线程并发程序有效的解决了脏数据的读取问题 2.3 实验结果 通过2.2节的对比实验可以看出，在执行多进程并发程序的时候，由于多进程的切换可能发生在某个进程的中间，会导致在一个进程处理的数据未写入ticketCount之前另外一个进程读取该数据，这样就导致了脏数据的读取，导致最终结果的不正确。 在2.2节的后半部分通过怎加同步机制，保证售票进程和退票进程的的原子性，就是指在某个进程操作的时候，在它完成操作之前另外一个进程无法操作共享变量ticketCount,这样就避免了脏数据的发生，得到了预期的正确结果。 2.4 现象解释2.4.1 现象解释1在2.2.1节的实验中，以售票线程为例（代码如下图所示），没有添加同步机制，并且在进行temp=temp-1和temp=ticketCount的后面均加上了pthread_yield，这个函数的作用是放弃对CPU的使用权，切换到其他进程中，本实验中就是切换到退票进程中。 这样就能解释为什么2.2.1节中的实验现象，在2.2.1节中，不论售票数多还是退票数多，最终结果都是总票数加上或减去值比较大的那个数。通过分析可以得出解释，售票进程和退票进程同时进行，初始票数均为1000，售票进程完成一次是票数为999，售票进程开始下一次售票，但是在运行temp=ticketCount之前，退票进程处理的数据还没有写入到内存中，导致售票进程读取的还是自己之前计算的ticketCount值，而不是全局的值。退票进程也是同理。 但是为什么刚好就是总票数加上或减去值比较大的那个呢？按照道理来说因该售票进程执行temp=ticketCount在退票进程写入ticketCount值之前发生是存在一定概率的，但是在目前为止的所有测试结果全部都是在写入之前读取ticketCount值，对此的解释是由于ticketCount=temp和temp=ticketCount之间没有加pthread_yield操作，而现代的处理器运算速度足够快，在退票进程放弃CPU控制权的那个时间片已经完成了这两步操作，所以相当于售票进程读取的ticketCount一直是自己本身的值，退票进程处理的数据对售票进程并没有影响。 为了验证上面的猜想，在=如下图所示代码，在ticketCount之后增加一行代码，pthread_yield，放弃当前进程对CPU的控制权，即售票进程放弃对CPU的控制权转而交给退票进程，这个时候退票进程处理的数据就能写入到内存中，而当售票进程再次处理temp=ticketCount的时候，读取的就是退票进程已经写入的数据。如果猜想正确的话，期待的最终票数因该还会发生错误，但并不是像第一中那种恰好等于总票数加减数值大的那个数。 得到的结果如下，发现最终的票数不在是1000+50=1050，而是分布在1000~1050之间的数值。猜想得到验证。 针对上面的猜想（CPU运算速度过快，导致ticketCount=temp和temp=ticketCount两步操作在一个进程的时间片内完成导致的数据错误），另外的一种验证方式是将初始票数和售票退票数设置的足够大，当数据足够大的时候，就会存在一定概率出现在一个进程的ticketCount=temp和temp=ticketCount两步操作之间切换进程的问题，得到的结果就不会类似2.2.1中的那样，而是类似在ticketCount=temp下面加了pthread_yield那样。 再次运行，可以看到如下的实验结果： 2.4.2 现象解释2在2.2.2节中，当给售票进程和退票进程都加上同步机制后，保证了每个线程操作的原子性，每个线程操作的过程中其他的线程不能对共享的ticketCount变量进程修改，这样的话最终的结果就是正确的结果。 Task 33.1 实验要求$\qquad$一个生产者一个消费者线程同步。设置一个线程共享的缓冲区， char buf[10]。一个线程不断从键盘输入字符到buf,一个线程不断的把buf的内容输出到显示器。要求输出的和输入的字符和顺序完全一致。（在输出线程中，每次输出睡眠一秒钟，然后以不同的速度输入测试输出是否正确）。要求多次测试添加同步机制前后的实验效果。 3.2 实验过程 实验源码 task3.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;#include&lt;semaphore.h&gt;#include&lt;sys/stat.h&gt;#include&lt;fcntl.h&gt;char buf[10];sem_t *empty=NULL;sem_t *full=NULL;void *worker1(void *arg)&#123; for(int i=0;i&lt;10;i++) &#123; sem_wait(empty); /* fflush(stdin); */ /* printf("输入："); */ scanf("%c",&amp;buf[i]); sem_post(full); if(i==9) &#123; i=-1; &#125; &#125; return NULL;&#125;void *worker2(void *arg)&#123; for(int i=0;i&lt;10;i++) &#123; sem_wait(full); printf("输出：%c\n",buf[i]); sem_post(empty); sleep(1); if(i==9) &#123; i=-1; &#125; &#125; return NULL;&#125;int main(int argc,char *argv[])&#123; empty=sem_open("empty_",O_CREAT,0666,10); full=sem_open("full_",O_CREAT,0666,0); pthread_t p1,p2; pthread_create(&amp;p1,NULL,worker1,NULL); pthread_create(&amp;p2,NULL,worker2,NULL); pthread_join(p1,NULL); pthread_join(p2,NULL); sem_close(empty); sem_close(full); sem_unlink("empty_"); sem_unlink("full_"); return 0;&#125; 程序解释 work1是输入线程调用的函数，worker2是输出线程调用的函数。 设置两个信号量empty和ful来控制程序的执行，其中empty信号量用于保证输入线程在写入数据到缓存的时候缓存中还有空余的位置，保证写入线程后写入的数据不会把前面写入但是为输出的数据给覆盖掉，其初始值为10，表示最开始缓存中有10个空余的位置供给写入线程写入数据；full信号量是用于保证输出线程有数据输出，避免在写入线程还没有写入数据的情况下输出线程输出随机数据，其初始值为0，表示初始状态下缓存中没有数据可以输出 输入线程在写入一个数据前要等待empty信号量，进入后便消耗一个信号量；完成写入数据操作之后post一个full信号量，通知输出线程输出数据。 输出线程在输出一个数据之前哟啊等待full信号量，进出输出操作后便消耗一个full信号量；完成输出操作后post一个empty信号量，通知写入线程缓存又多一个空余位置以供写入数据。 输出线程每输出一个字符等待一秒钟，方便实验结果的查看。 编译源代码 1gcc task3.c -o task3 -lpthread 3.3 实验结果3.3.1 实验运行现象 随机输入字母和数字（10个以内）：124365abc 随机输入字母和数字(10个以上)：123456789abcdefg 不间断输入： 通过观察上面的实验现象，可以看到已经满足了实验题目的要求。 3.3.2 实验现象解释 在第一种类型的测试中，输入数据不大于10个字符的时候，由于empty的信号量初始值为10，所以输入进程会一直连续不断的向缓存中写入数据，每写入一个数据，便post一个full信号量，输出线程便能按序输出字符。 在第二种类型的测试中，输入数据大于10个字符的时候，由于empty的初始值为10，所以输入的字符中开始的时候只有前10个字符被写入缓存中，其他的在I/O缓冲区等待输入，当输出线程接收到输入线程post的信号量的时候便会开始输出，每输出一个字符便会post一个empty信号量，当输入线程接收到empty信号量的时候有开始从I/O缓冲区读取数据写入到缓存中。 第三种测试和第二种类似，在输出的过程中间输入数据，原理其实是一样的。 Task 44.1 实验要求 通过实验测试，验证共享内存的代码中，receiver能否正确读出sender发送的字符串？如果把其中互斥的代码删除，观察实验结果有何不同？如果在发送和接收进程中打印输出共享内存地址，他们是否相同，为什么？ 有名管道和无名管道通信系统调用是否已经实现了同步机制？通过实验验证，发送者和接收者如何同步的。比如，在什么情况下，发送者会阻塞，什么情况下，接收者会阻塞？ 消息通信系统调用是否已经实现了同步机制？通过实验验证，发送者和接收者如何同步的。比如，在什么情况下，发送者会阻塞，什么情况下，接收者会阻塞？ 4.2 实验过程 实验过程根据实验要求的三个部分，对应的过程也分为三个部分，具体如下所示 4.2.1 内存共享 实验源码 内存内存共享实验的源码分为两个部分，分别是Sender.c和Receive.c, Sender.c： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/* * Filename: Sender.c * Description: */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/sem.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[])&#123; key_t key; int shm_id; int sem_id; int value = 0; //1.Product the key key = ftok(".", 0xFF); //2. Creat semaphore for visit the shared memory sem_id = semget(key, 1, IPC_CREAT|0644); if(-1 == sem_id) &#123; perror("semget"); exit(EXIT_FAILURE); &#125; //3. init the semaphore, sem=0 if(-1 == (semctl(sem_id, 0, SETVAL, value))) &#123; perror("semctl"); exit(EXIT_FAILURE); &#125; //4. Creat the shared memory(1K bytes) shm_id = shmget(key, 1024, IPC_CREAT|0644); if(-1 == shm_id) &#123; perror("shmget"); exit(EXIT_FAILURE); &#125; //5. attach the shm_id to this process char *shm_ptr; shm_ptr = shmat(shm_id, NULL, 0); if(NULL == shm_ptr) &#123; perror("shmat"); exit(EXIT_FAILURE); &#125; //6. Operation procedure struct sembuf sem_b; sem_b.sem_num = 0; //first sem(index=0) sem_b.sem_flg = SEM_UNDO; sem_b.sem_op = 1; //Increase 1,make sem=1 while(1) &#123; if(0 == (value = semctl(sem_id, 0, GETVAL))) &#123; printf("\nNow, snd message process running:\n"); printf("\tInput the snd message: "); scanf("%s", shm_ptr); if(-1 == semop(sem_id, &amp;sem_b, 1)) &#123; perror("semop"); exit(EXIT_FAILURE); &#125; &#125; //if enter "end", then end the process if(0 == (strcmp(shm_ptr ,"end"))) &#123; printf("\nExit sender process now!\n"); break; &#125; &#125; shmdt(shm_ptr); return 0;&#125; Receiver.c 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/sem.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/shm.h&gt;#include &lt;sys/types.h&gt;#include &lt;string.h&gt;int main(int argc, char *argv[])&#123; key_t key; int shm_id; int sem_id; int value = 0; //1.Product the key key = ftok(".", 0xFF); //2. Creat semaphore for visit the shared memory sem_id = semget(key, 1, IPC_CREAT|0644); if(-1 == sem_id) &#123; perror("semget"); exit(EXIT_FAILURE); &#125; //3. init the semaphore, sem=0 if(-1 == (semctl(sem_id, 0, SETVAL, value))) &#123; perror("semctl"); exit(EXIT_FAILURE); &#125; //4. Creat the shared memory(1K bytes) shm_id = shmget(key, 1024, IPC_CREAT|0644); if(-1 == shm_id) &#123; perror("shmget"); exit(EXIT_FAILURE); &#125; //5. attach the shm_id to this process char *shm_ptr; shm_ptr = shmat(shm_id, NULL, 0); if(NULL == shm_ptr) &#123; perror("shmat"); exit(EXIT_FAILURE); &#125; //6. Operation procedure struct sembuf sem_b; sem_b.sem_num = 0; //first sem(index=0) sem_b.sem_flg = SEM_UNDO; sem_b.sem_op = -1; //Increase 1,make sem=1 while(1) &#123; if(1 == (value = semctl(sem_id, 0, GETVAL))) &#123; printf("\nNow, receive message process running:\n"); printf("\tThe message is : %s\n", shm_ptr); if(-1 == semop(sem_id, &amp;sem_b, 1)) &#123; perror("semop"); exit(EXIT_FAILURE); &#125; &#125; //if enter "end", then end the process if(0 == (strcmp(shm_ptr ,"end"))) &#123; printf("\nExit the receiver process now!\n"); break; &#125; &#125; shmdt(shm_ptr); //7. delete the shared memory if(-1 == shmctl(shm_id, IPC_RMID, NULL)) &#123; perror("shmctl"); exit(EXIT_FAILURE); &#125; //8. delete the semaphore if(-1 == semctl(sem_id, 0, IPC_RMID)) &#123; perror("semctl"); exit(EXIT_FAILURE); &#125; return 0;&#125; 程序解释 下面以sender.c为例解释一下如何创建共享内存并通过信号量机制实现互斥访问从而达到进程间通信的目的。 创建一个共享内存的ID,就是代码中的key 12key_t key;key = ftok(".", 0xFF); 通过ftok函数创建一个key_t类型的变量，作为共享内存的key，ftok函数的两个参数分别是文档名(一个存在的路径),上例中的路径是.表示当前路径，另一个参数是子序号 创建并初始化信号量 123456789101112int sem_id;sem_id = semget(key, 1, IPC_CREAT|0644);if(-1 == sem_id)&#123; perror("semget"); exit(EXIT_FAILURE);&#125;if(-1 == (semctl(sem_id, 0, SETVAL, value)))&#123; perror("semctl"); exit(EXIT_FAILURE);&#125; 通过semget()函数创建一个信号量，初始值为1，再通过semctl()函数初始化该信号量 创建共享内存并挂载在进程中 123456789101112131415//4. Creat the shared memory(1K bytes)shm_id = shmget(key, 1024, IPC_CREAT|0644);if(-1 == shm_id)&#123; perror("shmget"); exit(EXIT_FAILURE);&#125;//5. attach the shm_id to this processchar *shm_ptr;shm_ptr = shmat(shm_id, NULL, 0);if(NULL == shm_ptr)&#123; perror("shmat"); exit(EXIT_FAILURE);&#125; 在这部分代码中，首先通过shmget()函数创建了一个大小为1000B的共享内存，然后通过shmat函数，将刚刚创建的共享内存以可读写的方式挂载在进程上，并且指定系统将自动选择一个合适的地址给共享内存，将挂载的共享内存地址赋值给char型指针shm_ptr Sender主循环 123456789101112131415161718192021while(1)&#123; if(0 == (value = semctl(sem_id, 0, GETVAL))) &#123; printf("\nNow, snd message process running:\n"); printf("\tInput the snd message: "); scanf("%s", shm_ptr); if(-1 == semop(sem_id, &amp;sem_b, 1)) &#123; perror("semop"); exit(EXIT_FAILURE); &#125; &#125; //if enter "end", then end the process if(0 == (strcmp(shm_ptr ,"end"))) &#123; printf("\nExit sender process now!\n"); break; &#125;&#125; 主循环中首先判断表示共享内存访问情况的信号量是否为0(为0表示共享内存空闲)，如果为0的话提示用户输入想要输入的消息，并将用户输入的消息写入共享内存中，写完后通过semop函数将信号量加一，通知receiver读取消息。并且定义一个end命令表示退出当前进程。循环退出的时候取消共享内存的挂载 Receiver主循环 1234567891011121314151617181920while(1)&#123; if(1 == (value = semctl(sem_id, 0, GETVAL))) &#123; printf("\nNow, receive message process running:\n"); printf("\tThe message is : %s\n", shm_ptr); if(-1 == semop(sem_id, &amp;sem_b, 1)) &#123; perror("semop"); exit(EXIT_FAILURE); &#125; &#125; //if enter "end", then end the process if(0 == (strcmp(shm_ptr ,"end"))) &#123; printf("\nExit the receiver process now!\n"); break; &#125;&#125; 主循环中首先判断表示共享内存访问情况的信号量是否为1(为1表示共享内存已经写入消息，可以读取)，如果为1的话输出该消息，输出后通过semop函数将信号量减1，通知Sender可以再次写入消息。并且定义一个end命令表示退出当前进程。循环退出的时候取消共享内存的挂载 实验现象 将上述源码编译后进行测试，得到下面的结果。 可以看到sender进程发出的消息receiver进程均准确无误的收到 删除互斥访问相关的代码 程序主要的代码没有变化，只是在Sender和Receiver进程的主循环中将用于控制互斥访问共享内存的相关代码删除，注释后的结果如下： Sender_2.c: 123456789101112while(1)&#123; printf("\nNow, snd message process running:\n"); printf("\tInput the snd message: "); scanf("%s", shm_ptr); //if enter "end", then end the process if(0 == (strcmp(shm_ptr ,"end"))) &#123; printf("\nExit sender process now!\n"); break; &#125;&#125; Receiver_2.c: 12345678910111213while(1)&#123; printf(&quot;\nNow, receive message process running:\n&quot;); printf(&quot;\tThe message is : %s\n&quot;, shm_ptr); //if enter &quot;end&quot;, then end the process if(0 == (strcmp(shm_ptr ,&quot;end&quot;))) &#123; printf(&quot;\nExit the receiver process now!\n&quot;); break; &#125; sleep(3);&#125; 最后加一个sleep(1)用于控制打印的速度，便于观察现象 删除互斥访问后的实验现象 实验现象解释：当删除互斥访问之后，两个进程便没有限制的访问共享内存，Sender进程由于受限于用户输入的速度，会停留一直等待用户输入数据，但是Receiver进程会一直输出共享内存中的消息。 打印Sender和Receiver进程中共享内存的地址 在原始代码的基础上修改，具体代码文件分别是Sender_3.c和Receiver_3.c，具体修改就是如下： 在挂载共享内存后打印挂载后的地址 打印共享内存地址实验现象 可以看到实验现象，在两个进程中共享内存的地址不一样 ==现象解释：== 通过上面的现象可以看到共享内存在不同进程中是不相同的，总结有以下的原因导致共享内存在不同进程中的地址不一样： 进程在挂载内存的时候使用的shmat()函数中的第二个参数使用的是NULL，NULL参数的含义是进程让系统分配给共享内存合适的地址。在shmat()函数中，第二个参数有三种选择，分别是： | 参数值 | NULL | addr | addr || :——: | :—————————————: | :—————————————————————————————: | :—————————————————————————————: || 含义 | 系统将自动选择一个合适的地址 | 如果shmaddr非0 并且指定了SHM_RND 则此段连接到shmaddr -（shmaddr mod SHMLAB)所表示的地址上。 | 第三个参数如果在flag中指定了SHM_RDONLY位，则以只读方式连接此段，否则以读写的方式连接此 段。 | ​ 可以看到，当addr有具体的值的时候，便将共享内存挂载到指定的地址上 现代操作系统中都存在ASLR(地址空间随机化)，ASLR是⼀种针对缓冲区溢出的安全保护机制，具有ASLR机制的操作系统每次加载到内存的程序起始地址会随机变化。系统的这个随机化操作可能导致共享内存的地址不一致。 ==验证：== 指定Sender_4.c和Receiver_4.c中共享内存的挂载地址为0x7fcc2c0bb000 修改具体的代码如下： 运行结果： 实验结果结果佐证了上面的现象解释，通过指定挂载共享内存的地址，可以使共享内存的地址一致，可以随意指定改地址 关闭系统的ASLR操作 具体的关闭命令如下： 12 sudo susysctl -w kernel.randomize_va_space=0 + 运行结果： &lt;div align=&quot;center&quot;&gt;&lt;img src=&quot;&quot; width=&quot;800&quot; /&gt;&lt;/div&gt; ![](http://ipic-picgo.oss-cn-beijing.aliyuncs.com/2019-04-29-174000.jpg) &gt; 这个实验现象也佐证了系统的ASLR也对导致挂载的共享内存地址不一样 4.2.2 管道通信（1）无名管道 实验源码 pipe.c: 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; //for pipe()#include &lt;string.h&gt; //for memset()#include &lt;stdlib.h&gt; //for exit()int main()&#123; int fd[2]; char buf[20]; if(-1 == pipe(fd)) &#123; perror("pipe"); exit(EXIT_FAILURE); &#125; write(fd[1], "hello,world", 12); memset(buf, '\0', sizeof(buf)); read(fd[0], buf, 12); printf("The message is: %s\n", buf); return 0;&#125; 程序解释 通过pipe函数创建管道，函数传递一个整形数组fd，fd的两个整形数表示的是两个文件描述符，其中第一个用于读取数据，第二个用于写数据。两个描述符相当远管道的两端，一段负责写数据，一段负责读数据。 pipe管道是半双工的工作模式，某一时刻只能读或者只能写 读写管道就和读写普通文件一样，使用write和read 实验现象 无名管道同步机制验证 为了验证无名管道的同步机制，在上述代码的基础上进行修改，得到如下的代码 pipe_2.c: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt;#include &lt;unistd.h&gt; //for pipe()#include &lt;string.h&gt; //for memset()#include &lt;stdlib.h&gt; //for exit()int main()&#123; int fd[2]; char buf[200]=&#123;0&#125;; pid_t child; //创建管道 if(-1 == pipe(fd)) &#123; perror("pipe"); exit(EXIT_FAILURE); &#125; //创建子进程 child=fork(); if(child==-1) &#123; perror("fork"); exit("EXIT_FAILURE"); &#125; if(child==0) &#123; //关闭子进程中不需要的写描述符 close(fd[1]); while(1) &#123; if(read(fd[0],buf,sizeof(buf))&gt;0) printf("子进程接收的消息是:%s\n",buf); else printf("子进程:管道中没有数据\n"); sleep(2); if(strcmp(buf,"end")==0) break; memset(buf,0,sizeof(buf)); &#125; &#125; if(child&gt;0) &#123; close(fd[0]); while(1) &#123; printf("父进程中-请输入消息:"); scanf("%s",buf); write(fd[1],buf,strlen(buf)); if(strcmp(buf,"end")==0) break; &#125; &#125; return 0;&#125; 对于上述代码做出如下解释：父进程是消息的发送者，在父进程中创建了两个文件描述符，fork一个子进程的时候会复制这两个管道文件描述符，因此父进程和子进程都会将自己的那个用不到的文件描述符关闭。父进程中会持续向管道中写入用户输入的消息，子进程会一直输出管道中的消息，如果管道中没有消息就会阻塞等待。 无名管道同步机制实验现象 可以看到输出进程是按照输入进程输入的顺序输出数据，并且当输入进程没有数据输入，即管道中没有数据的时候，输出进程会阻塞。因此无名管道通信系统调用的时候已经yijing实现了同步机制 无名管道同步机制原理 通过上面的实验和查阅相关资料，得到无名管道如下的同步机制： 管道的读写通过两个系统调用write和read实现 发送者在向管道内存中写入数据之前，首先检查内存是否被读进程锁定和内存中是否还有剩余空间，如果这两个要求都满足的话write函数会对内存上锁，然后进行写入数据，写完之后解锁；否则就会等待(阻塞)。 写进程在读取管道中的数据之前，也会检查内存是否被读进程锁定和管道内存中是否有数据，如果满足这两个条件，read函数会对内存上锁，读取数据后在解锁；否则会等到(阻塞) （2）有名管道 实验代码 有名管道实验中设计两个代码文件fifo_send.c和fifo_rcv.c fifo_send.c: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;fcntl.h&gt;#define FIFO "./my_fifo"int main()&#123; char buf[] = "hello,world"; //1. check the fifo file existed or not int ret; ret = access(FIFO, F_OK); if(ret != 0) //file /tmp/my_fifo existed &#123; if(-1 == mkfifo(FIFO, 0766)) &#123; perror("mkfifo"); exit(EXIT_FAILURE); &#125; &#125; //3.Open the fifo file int fifo_fd; fifo_fd = open(FIFO, O_WRONLY); if(-1 == fifo_fd) &#123; perror("open"); exit(EXIT_FAILURE); &#125; //4. write the fifo file int num = 0; num = write(fifo_fd, buf, sizeof(buf)); if(num &lt; sizeof(buf)) &#123; perror("write"); exit(EXIT_FAILURE); &#125; printf("write the message ok!\n"); close(fifo_fd); return 0;&#125; fifo_rcv.c: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* *File: fifo_rcv.c */ #include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;fcntl.h&gt;#define FIFO "./my_fifo"int main()&#123; char buf[20] ; memset(buf, '\0', sizeof(buf)); //`. check the fifo file existed or not int ret; ret = access(FIFO, F_OK); if(ret != 0) //file /tmp/my_fifo existed &#123; if(-1==mkfifo(FIFO,0766)) &#123; perror("mkfifo"); exit("EXIT_FAILURE"); &#125; &#125;// 2.Open the fifo file int fifo_fd; fifo_fd = open(FIFO, O_RDONLY); if(-1 == fifo_fd) &#123; perror("open"); exit(EXIT_FAILURE); &#125; //4. read the fifo file int num = 0; num = read(fifo_fd, buf, sizeof(buf)); printf("Read %d words: %s\n", num, buf); close(fifo_fd); return 0;&#125; 程序解释 写进程fifo_send分为四个步骤执行，首先判断当前目录下是否已经存在my_fifo文件，不存在的话在当前目录下通过mkfifo()函数创建FIFO类型的文件my_fifo；再通过open()函数打开my_fifo文件，最后向文件中写入消息； 读进程的过程和写进程的类似，只没有了创建fifo文件的过程而已 实验现象 现象描述：在仅仅只运行fifo_send进程的时候，没有任何输出，进程一直阻塞，直到fifo_rcv进程运行，两个进程才开始输出信息。 当写进程和读进程都设置成阻塞状态的时候，不论先执行那个进程，先执行的进程都会阻塞等待，待另一个进程执行后两个进程才正常执行。 探究有名管道的同步和阻塞机制 通过fifo_fd=open(FIFO,O_RDONLY | O_NONBLOCK)设置为非阻塞状态，fifo_fd=open(FIFO,O_RDONLY)设置为阻塞状态，对应四个进程分别为fifo_send(阻塞)、fifo_rcv(阻塞)、fifo_send_1(非阻塞)、fifo_rcv_1(非阻塞) 读进程阻塞、写进程阻塞 先执行fifo_send后执行fifo_rcv，结果正确 截图请见上面的实验现象 先执行fifo_rcv后执行fifo_send，结果正确 具体的原因是读进程在open FIFO的时候由于没有s 通过查阅资料得到了FIFO管道的阻塞机制如下： 对于设置了阻塞的读进程而言： 读进程阻塞的原因有三种：FIFO 中没有数据、有其他的读进程正在读取这些数据、没有写进程打开FIFO文件 不论是哪种原因引起的阻塞，解开阻塞的原因都是FIFO有新的数据写入 如果一个读进程有多个read操作，那么只会阻塞第一个read，其他的不会发生阻塞 对于设置了阻塞的写进程而言： 当写入的数据量小于PIPE_BUF时，Linux保证写入原子性。如果此时管道中的空闲位置不足以容纳要写入的数据，泽写进程阻塞，直到管道中空间足够，一次性写入所有数据 当写入的数据量大于PIPE_BUF时，Linux不再保证写入的原子性。一旦管道中有空闲位置便尝试写入数据，直到所有数据写入完成后返回。 读进程阻塞，写进程非阻塞 先执行fifo_send_1后执行fifo_rcv，写进程open函数返回-1 先执行fifo_rcv后执行fifo_send_1，结果正常 读进程非阻塞，写进程阻塞 先执行fifo_send后执行fifo_rcv_1,结果正常 先执行fifo_rcv_1后执行fifo_send，程序崩溃 读写进程都是非阻塞 先执行fifo_send_1后执行fifo_rcv_1 先执行fifo_rcv_1后执行fifo_send_1 4.2.3 消息队列 实验代码 本实验代码文件分为Server.c和Client.c两个 Server.c: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/msg.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;signal.h&gt;#define BUF_SIZE 128//Rebuild the strcut (must be)struct msgbuf&#123; long mtype; char mtext[BUF_SIZE];&#125;;int main(int argc, char *argv[])&#123; //1. creat a mseg queue key_t key; int msgId; key = ftok(".", 0xFF); msgId = msgget(key, IPC_CREAT|0644); if(-1 == msgId) &#123; perror("msgget"); exit(EXIT_FAILURE); &#125; printf("Process (%s) is started, pid=%d\n", argv[0], getpid()); while(1) &#123; alarm(0); alarm(600); //if doesn't receive messge in 600s, timeout &amp; exit struct msgbuf rcvBuf; memset(&amp;rcvBuf, '\0', sizeof(struct msgbuf)); msgrcv(msgId, &amp;rcvBuf, BUF_SIZE, 1, 0); printf("Receive msg: %s\n", rcvBuf.mtext); struct msgbuf sndBuf; memset(&amp;sndBuf, '\0', sizeof(sndBuf)); strncpy((sndBuf.mtext), (rcvBuf.mtext), strlen(rcvBuf.mtext)+1); sndBuf.mtype = 2; if(-1 == msgsnd(msgId, &amp;sndBuf, strlen(rcvBuf.mtext)+1, 0)) &#123; perror("msgsnd"); exit(EXIT_FAILURE); &#125; //if scanf "end~", exit if(!strcmp("end~", rcvBuf.mtext)) break; &#125; printf("THe process(%s),pid=%d exit~\n", argv[0], getpid()); return 0;&#125; Client.c: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/msg.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;signal.h&gt;#define BUF_SIZE 128//Rebuild the strcut (must be)struct msgbuf&#123; long mtype; char mtext[BUF_SIZE];&#125;;int main(int argc, char *argv[])&#123; //1. creat a mseg queue key_t key; int msgId; printf("THe process(%s),pid=%d started~\n", argv[0], getpid()); key = ftok(".", 0xFF); msgId = msgget(key, IPC_CREAT|0644); if(-1 == msgId) &#123; perror("msgget"); exit(EXIT_FAILURE); &#125; //2. creat a sub process, wait the server message pid_t pid; if(-1 == (pid = fork())) &#123; perror("vfork"); exit(EXIT_FAILURE); &#125; //In child process if(0 == pid) &#123; while(1) &#123; alarm(0); alarm(100); //if doesn't receive messge in 100s, timeout &amp; exit struct msgbuf rcvBuf; memset(&amp;rcvBuf, '\0', sizeof(struct msgbuf)); msgrcv(msgId, &amp;rcvBuf, BUF_SIZE, 2, 0); printf("Server said: %s\n", rcvBuf.mtext); &#125; exit(EXIT_SUCCESS); &#125; else //parent process &#123; while(1) &#123; usleep(100); struct msgbuf sndBuf; memset(&amp;sndBuf, '\0', sizeof(sndBuf)); char buf[BUF_SIZE] ; memset(buf, '\0', sizeof(buf)); printf("\nInput snd mesg: "); scanf("%s", buf); strncpy(sndBuf.mtext, buf, strlen(buf)+1); sndBuf.mtype = 1; if(-1 == msgsnd(msgId, &amp;sndBuf, strlen(buf)+1, 0)) &#123; perror("msgsnd"); exit(EXIT_FAILURE); &#125; //if scanf "end~", exit if(!strcmp("end~", buf)) break; &#125; printf("THe process(%s),pid=%d exit~\n", argv[0], getpid()); &#125; return 0;&#125; 程序解释 程序分为服务器端和客户端，客户端向服务器发起通信，服务器端收到数据后将一模一样的数据返回 通过mgsrcv函数读取客户端传过来的消息，msgrcv的参数列表见下面。 int msgrcv(int msqid, void *ptr, size_t length, long type, int flag); | 参数 | msgid | ptr | length | type | flag || :—: | :——————: | :——————: | :—————: | :—————————————————————————————: | :——————————————————————————: || 含义 | 消息队列标识符 | 消息缓冲区指针 | 消息数据长度 | 决定从队列中返回那一条下消息 | 阻塞与否 || 备注 | | | | =0 返回消息队列中第一条消息&gt;0 返回消息队列中等于mtype 类型的第一条消息。&lt;0 返回mtype&lt;=type 绝对值最小值的第一条消息。 | msgflg 为０表示阻塞方式，设置IPC_NOWAIT 表示非阻塞方式 | 通过msgsnd函数向消息队列中加入消息，msgsnd的参数列表见下面。 int msgsnd(int msqid, const void *ptr, size_t length, int flag); | 参数 | msgid | ptr | length | flag || :—: | :——————: | :——————: | :—————: | :——————————————————————————: || 含义 | 消息队列标识符 | 消息缓冲区指针 | 消息数据长度 | 阻塞与否 || 备注 | | | | msgflg 为０表示阻塞方式，设置IPC_NOWAIT 表示非阻塞方式 | 客户端的子进程主要负责消息的接受，父进程主要负责消息的发送； 通过分析上面的代码可以知道，客户端和服务器端都是以阻塞的方式读取和写入消息 程序运行结果 探究消息队列的同步和阻塞机制 通过上面的程序解释中可以看出，消息队列通过msgrcv和msgsnd两个函数的flag参数控制是否阻塞，将其设置为IPC_NOWAIT表示不阻塞；如果客户端和服务器端都设置阻塞话，就可以达到同步的目的 现在做出如下探究： 客服端不阻塞(代码为Client_1.c),服务器端阻塞，得到结果如下。 可以看到当客户端不阻塞的话在客户端接受服务器端消息的时候会无限制的打印消息队列中的空消息，哪怕消息队列中没有任何消息 客户端阻塞，服务器端不阻塞(代码为Server_1.c) 可以看到当服务器端没有设置阻塞的时候，服务器端会一直接受消息队列中的空消息并向客户端转发。 Task 5 本实验分析进程上下文切换的代码，说明实现的保存和恢复的上下文内容以及进程切换的工作流程。 我们首先从devices/timer.c文件中的timer_sleep函数开始 分析，下面是该函数的具体代码： 123456789/* Sleeps for approximately TICKS timer ticks. Interrupts must be turned on. */void timer_sleep (int64_t ticks) &#123; int64_t start = timer_ticks (); ASSERT (intr_get_level () == INTR_ON); while (timer_elapsed (start) &lt; ticks) thread_yield ();&#125; 下面开始逐行分析这个函数，第5行的timer_ticks函数也在timer.c文件中，跳转到该函数中： 12345678/* Returns the number of timer ticks since the OS booted. */int64_t timer_ticks (void) &#123; enum intr_level old_level = intr_disable (); int64_t t = ticks; intr_set_level (old_level); return t;&#125; timer_ticks函数中第4行涉及一个名为intr_disable()的函数，该函数的具体定义在devices/interrupt.c文件中。 1234567891011/* Disables interrupts and returns the previous interrupt status. */enum intr_level intr_disable (void) &#123; enum intr_level old_level = intr_get_level (); /* Disable interrupts by clearing the interrupt flag. See [IA32-v2b] "CLI" and [IA32-v3a] 5.8.1 "Masking Maskable Hardware Interrupts". */ asm volatile ("cli" : : : "memory"); return old_level;&#125; 在看看返回值intr_level是个什么结构,代码在devices/interrupt.h中： 123456/* Interrupts on or off? */enum intr_level &#123; INTR_OFF, /* Interrupts disabled. */ INTR_ON /* Interrupts enabled. */ &#125;; 可以发现，intr_level这个枚举类型表示的是是否允许中断。于是分析得到intr_disable函数做了两件事。1. 调用intr_old_level函数 2. 直接执行汇编代码保证这个线程不能被中断。之后返回调用intr_old_level函数的返回值。 再看看intr_get_level函数的实现细节，该函数的定义也在devices/interrupt.c文件中 1234567891011/* Returns the current interrupt status. */enum intr_level intr_get_level (void) &#123; uint32_t flags; /* Push the flags register on the processor stack, then pop the value off the stack into `flags'. See [IA32-v2b] "PUSHF" and "POP" and [IA32-v3a] 5.8.1 "Masking Maskable Hardware Interrupts". */ asm volatile ("pushfl; popl %0" : "=g" (flags)); return flags &amp; FLAG_IF ? INTR_ON : INTR_OFF;&#125; 通过注释信息和分析汇编代码可以知道，intr_get_level这个函数的作用是返回当前的中断状态。intr_get_level函数弄清楚了之后，返回上一层函数中，到了intr_disable函数中，这样就可以清楚的知道intr_disable函数的作用： 获取当前中断状态 将当前中断状态更改为不可中断 返回先前的中断状态 弄清楚了intr_disable函数，接着看timer_ticks函数的5、6、7行 第5行通过一个int64_t类型的变量t获取全局变量ticks的值； 第6行intr_set_level(old_level)表示将当前中断状态设置为之前的中断状态。 第7行返回t 这样，函数timer_ticks的含义也就弄清楚了。其实timer_ticks函数的作用很简单，就是想获取当前系统的ticks值而已，而上面通过这么大篇幅的介绍timer_ticks函数的4、6两行的作用，原因是第4行和第6行通过先关闭中断，待t获取到ticks值之后载恢复之前的中断状态，来保证操作的原子性，简单的说就是在t获取全局变量ticks的值的时候，不能被打断。 然后接着分析timer_sleep函数的第6行ASSERT (intr_get_level () == INTR_ON);这里是一个断言，当intr_get_lvel函数获取的当前中断状态不是INTR_ON的时候发生警告且退出。 timer_sleep函数剩下的就是一个循环了： 12while (timer_elapsed (start) &lt; ticks) thread_yield (); 通过分析不难得出timer_elapsed()函数的作用是计算当前的系统ticks减去之前得到的start的差值，如果这个差值小于函数参数ticks的话一直执行thread_yield()函数。 再看看thread_yield函数的具体定义（在thread/thread.c文件中），分析一下该函数的作用： 1234567891011121314/* Yields the CPU. The current thread is not put to sleep and may be scheduled again immediately at the scheduler's whim. */void thread_yield (void) &#123; struct thread *cur = thread_current (); enum intr_level old_level; ASSERT (!intr_context ()); old_level = intr_disable (); if (cur != idle_thread) list_push_back (&amp;ready_list, &amp;cur-&gt;elem); cur-&gt;status = THREAD_READY; schedule (); intr_set_level (old_level);&#125; thread_yield函数第5行顾名思义，作用就是返回当前正在运行的线程，通过一个thread类型的结构体指针接受该函数返回值。 thread_yield函数的第7行通过断言的方式判断中断类型，如果是由于I/O等引起的硬中断则退出，如果是软中断的话正常运行。 再看第8行和第13行的之前也分析过，这是保证9-12行操作的原子性。 再分析9-12行： 9-10行：如何当前线程不是空闲的线程就调用list_push_back把当前线程的元素扔到就绪队列里面， 11行：把线程改成THREAD_READY状态 12行：调用schedule函数 再深入schedule函数(thread/thread.c文件)看看 1234567891011121314151617181920/* Schedules a new process. At entry, interrupts must be off and the running process's state must have been changed from running to some other state. This function finds another thread to run and switches to it. It's not safe to call printf() until thread_schedule_tail() has completed. */static void schedule (void) &#123; struct thread *cur = running_thread (); struct thread *next = next_thread_to_run (); struct thread *prev = NULL; ASSERT (intr_get_level () == INTR_OFF); ASSERT (cur-&gt;status != THREAD_RUNNING); ASSERT (is_thread (next)); if (cur != next) prev = switch_threads (cur, next); thread_schedule_tail (prev);&#125; schedule函数首先获取当前正在运行的线程指针cur和下一个运行的线程next，之后是三个断言。 ASSERT (intr_get_level () == INTR_OFF)：保证中断状态是开启的 ASSERT (cur-&gt;status != THREAD_RUNNING)：保证当前运行的线程是RUNNING_THREAD的 ASSERT (is_thread (next))：保证下一个线程有效 17-18行的作用是：如果当前线程和下一个要跑的线程不是同一个的话调用switch_threads返回给prev 下面再看看switch_threads函数(在threads/switch.S中)这是一个完全由汇编语言编写的函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &quot;threads/switch.h&quot;#### struct thread *switch_threads (struct thread *cur, struct thread *next);######## Switches from CUR, which must be the running thread, to NEXT,#### which must also be running switch_threads(), returning CUR in#### NEXT&apos;s context.######## This function works by assuming that the thread we&apos;re switching#### into is also running switch_threads(). Thus, all it has to do is#### preserve a few registers on the stack, then switch stacks and#### restore the registers. As part of switching stacks we record the#### current stack pointer in CUR&apos;s thread structure..globl switch_threads.func switch_threadsswitch_threads: # Save caller&apos;s register state. # # Note that the SVR4 ABI allows us to destroy %eax, %ecx, %edx, # but requires us to preserve %ebx, %ebp, %esi, %edi. See # [SysV-ABI-386] pages 3-11 and 3-12 for details. # # This stack frame must match the one set up by thread_create() # in size. pushl %ebx pushl %ebp pushl %esi pushl %edi # Get offsetof (struct thread, stack)..globl thread_stack_ofs mov thread_stack_ofs, %edx # Save current stack pointer to old thread&apos;s stack, if any. movl SWITCH_CUR(%esp), %eax movl %esp, (%eax,%edx,1) # Restore stack pointer from new thread&apos;s stack. movl SWITCH_NEXT(%esp), %ecx movl (%ecx,%edx,1), %esp # Restore caller&apos;s register state. popl %edi popl %esi popl %ebp popl %ebx ret.endfunc.globl switch_entry.func switch_entryswitch_entry: # Discard switch_threads() arguments. addl $8, %esp # Call thread_schedule_tail(prev). pushl %eax.globl thread_schedule_tail call thread_schedule_tail addl $4, %esp # Start thread proper. ret.endfunc 分析这段汇编代码，首先将4个寄存器的值压栈保护寄存器状态，这四个寄存器的值是switch_threads_frame的成员，switch_threads_frame结构的具体定义如下(thread/switch.h中定义)： 1234567891011/* switch_thread()'s stack frame. */struct switch_threads_frame &#123; uint32_t edi; /* 0: Saved %edi. */ uint32_t esi; /* 4: Saved %esi. */ uint32_t ebp; /* 8: Saved %ebp. */ uint32_t ebx; /* 12: Saved %ebx. */ void (*eip) (void); /* 16: Return address. */ struct thread *cur; /* 20: switch_threads()'s CUR argument. */ struct thread *next; /* 24: switch_threads()'s NEXT argument. */ &#125;; 全局变量thread_stack_ofs记录线程和栈之间的间隙，下面我们来看线程切换中保存现场的过程。 35-36行：先把当前的线程指针放到eax中， 并把线程指针保存在相对基地址偏移量为edx的地址中 40-41: 切换到下一个线程的线程栈指针， 保存在ecx中， 再把这个线程相对基地址偏移量edx地址（上一次保存现场的时候存放的）放到esp当中继续执行。 这里ecx, eax起容器的作用， edx指向当前现场保存的地址偏移量。简单来说就是保存当前线程状态， 恢复新线程之前保存的线程状态。 由此我们可以看出schedule函数是先将当前线程放入就绪队列，如果下一个线程和当前线程不一样的话切换到下一个线程。 再看看shcedule函数最后一行执行的操作，最后一行调用thread_schedule_tail函数，下面详细分析一下这个函数（thread/thread.c文件中）。 12345678910111213141516171819202122232425262728void thread_schedule_tail (struct thread *prev)&#123; struct thread *cur = running_thread (); ASSERT (intr_get_level () == INTR_OFF); /* Mark us as running. */ cur-&gt;status = THREAD_RUNNING; /* Start new time slice. */ thread_ticks = 0;#ifdef USERPROG /* Activate the new address space. */ process_activate ();#endif /* If the thread we switched from is dying, destroy its struct thread. This must happen late so that thread_exit() doesn't pull out the rug under itself. (We don't free initial_thread because its memory was not obtained via palloc().) */ if (prev != NULL &amp;&amp; prev-&gt;status == THREAD_DYING &amp;&amp; prev != initial_thread) &#123; ASSERT (prev != cur); palloc_free_page (prev); &#125;&#125; 首先是获得当前线程的的cur(切换之后的线程)，然后将cur的状态改为THREAD_RUNNING，然后thread_ticks清零开始新的线程切换时间片。然后调用diaoyongprocess_activate函数申请新的地址空间，再分析process_active函数(在useruserprog/process.c文件中定义) 123456789101112/* Sets up the CPU for running user code in the current thread. This function is called on every context switch. */void process_activate (void)&#123; struct thread *t = thread_current (); /* Activate thread's page tables. */ pagedir_activate (t-&gt;pagedir); /* Set thread's kernel stack for use in processing interrupts. */ tss_update ();&#125; 关键的就是pagedir_activate()函数和tss_update函数，这两个函数分别位于userprog/pagedir.c和userprog/tss.c文件中 下面再进入pagedir_activate()函数中查看。 1234567891011121314/* Loads page directory PD into the CPU's page directory base register. */void pagedir_activate (uint32_t *pd) &#123; if (pd == NULL) pd = init_page_dir; /* Store the physical address of the page directory into CR3 aka PDBR (page directory base register). This activates our new page tables immediately. See [IA32-v2a] "MOV--Move to/from Control Registers" and [IA32-v3a] 3.7.5 "Base Address of the Page Directory". */ asm volatile ("movl %0, %%cr3" : : "r" (vtop (pd)) : "memory");&#125; 这个汇编指令将当前线程的页目录指针存储到CR3（页目录表物理内存基地址寄存器）中，也就是说这个函数更新了现在的页目录表 再进入tss_update函数中： 1234567/* Sets the ring 0 stack pointer in the TSS to point to the end of the thread stack. */void tss_update (void) &#123; ASSERT (tss != NULL); tss-&gt;esp0 = (uint8_t *) thread_current () + PGSIZE;&#125; tss指的是 task state segment， 叫任务状态段， 任务（进程）切换时的任务现场信息。这里其实是把TSS的一个栈指针指向了当前线程栈的尾部， 也就是更新了任务现场的信息和状态。 到此process_activate函数的分析完毕，它做了两件事： 更新页目录表 更新任务现场信息（tss） 在继续看thread_schedule_tail函数的最后4行： 12345if (prev != NULL &amp;&amp; prev-&gt;status == THREAD_DYING &amp;&amp; prev != initial_thread) &#123; ASSERT (prev != cur); palloc_free_page (prev);&#125; 这里是说如果我们切换的线程状态是THREAD_DYING（代表欲要销毁的线程）的话， 调用palloc_free_page（thread/palloc.c文件中定义）： 12345/* Frees the page at PAGE. */void palloc_free_page (void *page) &#123; palloc_free_multiple (page, 1);&#125; 简单而言作用就是释放PAGE参数中的页面 到此，thread_schedule_tail函数分析完毕，其作用就是分配恢复之前执行的状态和现场， 如果当前线程死了就清空资源。 schedule函数的作用就是拿下一个线程切换过来继续运行。thread_yield函数的作用是shi把当前进程放在就绪队列里，调用schedule切换到下一个进程。 最后返回到最顶层的timer_sleep函数，他的作用就是在ticks的时间内nei，如果线程处于running状态就不断的把它放在就绪队列不让它执行。]]></content>
      <categories>
        <category>操作系统实验</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程实验]]></title>
    <url>%2Fsunpages%2F2019%2F03%2F11%2Flab2%2F</url>
    <content type="text"><![CDATA[实验二实验报告 孙汉武 16281047 安全1601 Task 11.1 实验步骤 打开一个vi进程 通过ps命令找到名字为vi的进程，命令如下 1ps -auxc | grep vi$ 这里对该命令中的参数做出解释 -aux: 显示所有进程 -c: 将command列输出更改为可执行文件名而不是命令名称 grep 正则表达式搜索 vi$ 匹配结尾为vi字符串 这里对ps命令的输出结果每一列的含义做出解释，ps -aux命令的输出结果一共有十一列，从左往右分别是： 列名 USER PID %CPU %MEM VSZ RSS 含义 进程所属用户名 进程ID 占用CPU百分比 占用内存百分比 虚拟大小 驻留中页的数量 示例 ubuntu 13716 0.0 0.5 40384 10144 列名 TTY STAT START TIME 含义 终端ID 进程状态 开始时间 累计CPU时间 实例 pts/2 S+ 20:33 0:00 寻找vi的父进程，直到init进程为止 使用如下命令查看指定进程的父进程的PID： 1ps -eo pid,ppid,user,command | grep -w ^.&lt;pid&gt; 说明： -eo 表示按照指定格式输出，这里指定的格式是pid,ppid,user,command \ 是要查询的pid号 \填写查询进程的pid. 通过步骤2可知vi的pid为13716，所以查询vi的父进程 1ps -eo pid,ppid,user,command | grep -w 13716 由图可知，vi的父进程的pid是7854 查询7854的父进程 1ps -eo pid,ppid,user,command | grep -w ^.7854 由图可知，7854的父进程的pid是7745 查询7745的父进程 1ps -eo pid,ppid,user,command | grep -w ^.7745 由图可知，7745的父进程的pid是1 查询1的父进程 1ps -eo pid,ppid,user,command | grep -w 1 综上所述，可以得到如下结果： | 进程号 | 父进程号 | 所属用户 | 命令 || ——— | ———— | ———— | —— || 13716 | 7854 | ubuntu | vi || 7854 | 7745 | ubuntu | -zsh || 7745 | 1 | ubuntu | tmux || 1 | 0 | root | init | 将步骤三得到的进程树和pstree得到的进程树比较 通过pstree命令得到如下结果： 左边的虚线代表init进程，可以看到两种方式得到的进程树是相同的。 两种方式各自的优点如下： pstree: 进程树比较直观，一目了然 能一次显示所有的进程的进程树 ps命令查询出的进程树 能查看每个中间进程的详细信息 ps命令自主性比较好，可以由用户自定义参数 Task 22.1 实验步骤 实验代码如下： 编译并运行程序 查看vi进程和父进程的状态 vi进程 ​ 可以看到vi进程的进程号为12703,父进程pid为12702，占用CPU和MEM分别为0.5%和0.6% vi进程父进程 对所有进程按照CPU占用率排序 方法一：使用htop命令，自动按照CPU占用率对进程排序 方法二：使用top命令按照CPU占用率对进程排序 ​ ​ Task 32.1 实验步骤 实验源码 对上述源码的分析包含以下几个方面： fork函数的功能和返回值： fork的功能是从当前行开始复制父进程，创建一个和父进程一样的子进程 fork的返回值在父进程中大于0，在子进程中等于0，如果创建子进程发生错误返回-1 程序流程如下： 程序解释： 结合上面的程序流程图，可以看到程序执行最初的那个进程就是父进程A，在一开始就通过fork函数创建一个子进程B，并用p1接受fork的返回值，由于p1在进程A和进程B的值不同，所以两个进程接下来执行的代码部分并不相同。进程A执行p1&gt;0的部分代码，并且在p1&gt;0的那部分代码中，进程A再次通过fork创建了一个子进程C。随后进程A和进程C分别打印自己的pid和ppid(父进程id)。在来看进程B，在p1==0的那部分代码中，进程B也是通过fork创建了一个子进程D,并将fork的返回值交给p2，在父进程B中，p2的值大于0，所以父进程B还创建了一个子进程E,而在子进程D中，p2\=\=0，所以不执行p2&gt;0代码块里面的语句，直接打印pid和ppid，之后分别是进程E和B打印pid和ppid。到此满足实验要求的进程树创建完毕。 编译执行 1gcc task3.c -o task3 调试分析 由于涉及的进程数比较多，所以通过调试的方式分析比较直观，所以下面利用gdb调试器进行调试。 首先是调试前的准备,在gcc编译的时候加上-g 参数以支持gdb调试: 1gcc -g task3.c -o task3 通过gdb task3命令进入调试器，首先是配置成多进程调试模式： 123# 在gdb中按照如下命令设置，可以设置成对进城调试模式set follow-fork-mode parentset detach-on-fork off 设置断点，在含有fork函数的所有地方设置断点 开始调试，首先通过r命令进入第一个进程开始调试，这里称此进程为A : 通过调试结果可以看出来进程A的进程号是28608，进程A的父进程pid是28570，并且p1=28613大于0，说明进程A走的是if (p1&gt;0)下面的那个分支。 分析源码可知，进程A在第6行和第7行分别创建了一个子进程，我分别称之为进程B和进程C. 下面切换到进程B中调试： 通过输出的调试信息可以看出，此时的p1的值为0，说明进程B执行的是P1==0下面的代码,而P2&gt;0说明此时进程B执行了if (p2&gt;0)后面的fork函数。最后得到进程B的pid为28613，进程B的父进程是进程A，其pid是28608，这与上面的进程A的pid是一直的。 在调试信息中可以看到，当进程B运行到13行和15行的时候分别创建了两个新的子进程，我们称这两个进程为进程D和进程E 接着对进程C进程分析，进程C是进程A在26行复制得到，并且后面没有创建任何其他的子进程。 ​ 通过调试信息可以看出，进程C的pid为28615，其父进程pid为28606,父进程为A，这与上面的信息一致。 ​ 再对进程D进程分析： ​ 通过上面分析可知，p1和p2均为0,所以说明进程D是进程B在13行创建的子进程，进程D的spid为28740，其父进程pid为28613，和前面的信息一致。 ​ 最后分析进程E： ​ 通过输出的信息可以看到p1=0,p2&gt;0，分析可知进程E是进程B在15行创建的子进程。进程E的pid是28741，其父进程pid是28613,恰好是进程B的pid ​ 分析上面可知，在本次调试过程中，得到的进程信息如下所示： 进程 A B C D E pid 28608 28613 28615 28740 28741 ppid 28570 28608 28608 28613 28613 ​ 于是可以得到这五个进程的进程树如下(与实验要求一致)： 遇到的问题及解决办法 问题 刚开始的时候由于没有考虑到父进程会在子进程之前结束的问题，导致所有的子进程在getppid()的时候父进程已经结束了，得到的是init进程的pid=1，所以在代码中加入sleep(1)，让父进程等待一秒钟再结束，等待子进程获取了其pid。 解决办法 在代码中中加入sleep(1),再次编译执行即可得到正确结果。 Task4 实验源码 代码和Task3中的代码基本一致，只是将输出信息编程循环输出，并且没打印一次后sleep一秒钟 打印进程树 可以看到进程树信息如上图所示 终止进程p2 采用kill -9的方式终止进程p2 删除之p2的子进程p4和p5挂载init上面。然后进程p1,p2,p3还是原来的进程，进程p2虽然被杀死，但是变成Z+的状态，成为退出状态进程的僵尸进程。 查看输出信息，发现进程p2的输出已经没有了 采用exit()正常退出进程 实验源码如下： 实验步骤 下面是进程p2在exit之前的进程树 代码中可以看到，进程p2在输出10次之后就会正常退出。下面是进程p2退出之后的进程树。 再查看进程p2的详细信息，得知进程p2的状态也变成了Z+，成为即将退出的僵尸进程。 采用段错误退出 实验代码 实验代码如上，在进程p2的进程段里面定义一个野指针，野指针没有初始化会产生段错误导致进程退出。 实验步骤 下面是进程p2在退出之前的的进程树 ​ 下面在p2进程退出之后的进程出，进程p2的子进程p4,p5挂载在init上，然后p2进程变成了状态为Z+ 的僵尸进程。 综上所述，三种方式的终止进程都会将进程变成僵尸进程，进程在退出的过程中，系统回收资源，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。这也是为什么进程p2终止之后在进程树中还能看到进程p2的信息等。]]></content>
      <categories>
        <category>操作系统实验</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在github部署gitbook教程]]></title>
    <url>%2Fsunpages%2F2019%2F03%2F01%2Fgitbook%2F</url>
    <content type="text"><![CDATA[gitbook使用本地修改 在本地利用 yu writer进行编辑之后使用git上传到github123git add &lt;修改的文件名&gt;git commit -m "修改的简述"git push -u github master 服务器从github同步数据1git pull github master 重启gitbook服务1234lsof -i:4000# 找到pid之后杀死进程kill -9 pidsetsid gitbook serve .]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>极客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件系统实验]]></title>
    <url>%2Fsunpages%2F2019%2F03%2F01%2Flab5%2F</url>
    <content type="text"><![CDATA[实验五-文件系统 实验报告 孙汉武 16281047 安全1601 实验源码链接:https://github.com/sunhanwu/16281047_OperatingSystemExperiment/tree/master/lab5 pdf下载 一 概要设计$\qquad$本次的实验的实验目的是在模拟的I/O系统中开发一个简单的文件系统，并且提供一些借口给用户用于交互，从实验目的可以看出，本实验重点在于构建模拟的I/O系统和基于I/O系统的文件系统。所以，在概要设计中，将详细介绍模拟I/O系统的设计、文件系统的设计和测试模块的设计这三个部分。 1.1 I/O系统设计 $\qquad$IO系设计首先要解决的是需要有一个物理磁盘，为此，我们通过定义一个三维的磁盘块结构体数组表示物理磁盘，该结构体数组的每一个维度分别表示物理磁盘中的一个层次。 $\qquad$我们模拟的磁盘如上所示，第一维表柱面，第二维表示磁头，最后一维表示扇区。磁盘定义好之后需要定义一系列的函数用于操作磁盘。IO系统工作的流程和结构如下所示： $\qquad$IO系统提供的操作磁盘的API如上图所示，主要分为五个大类，分别是初始化磁盘、磁盘搜索、磁盘读写、磁盘位图处理、磁盘与文件转化等，下面的表格分别介绍了各个类别提供的API的详细信息。 磁盘初始化 函数名 参数 返回值 功能 InitDisk() 无 无 初始化磁盘数组 磁盘搜索 函数名 参数 返回值 功能 SearchBitMap 无 空闲磁盘块号 搜索并返回最小的空闲磁盘块号 磁盘读写 函数名 参数 返回值 功能 ReadBlock int i :指定读取的磁盘块号char *p ：返回读取内容 无 读取指定磁盘块内容 WriteBlock int i：指定写入的磁盘块号char *p:写入的内容 无 写入内容到指定磁盘块 磁盘位图处理 函数名 参数 返回值 功能 InitBitMap 无 无 初始化位图 ChangeBitMap int i:要修改的磁盘块号char p:修改的内容(Y/N) 无 修改位图每一位的值 磁盘与文件的转化 $\qquad$由于是在内从中创建数组模拟物理磁盘，所以这种方式无法模拟物理磁盘断电不丢失信息的特性。为了满足这个要求，设计一下的函数用于将数组中的信息存储到文件中和文件中读取相关信息。 函数名 参数 返回值 功能 DiskToFile char filename[]：文件名 无 将磁盘数组信息存储为文件 FileToDsik char filename[]:文件名 无 将文件读取到磁盘数组中 1.2 文件系统设计$\qquad$在上一节设计的IO系统的基础上，进行文件系统的设计，文件系统设计时有两个很重要的概念，分别是文件描述符和目录项这两个数据结构的定以及在这个基础上进行的一系列操作。 用户接口 $\qquad$文件系统提供了一系列便于用户操作的接口，用于对文件系统中的文件进行增删改查，具体接口信息如下： 函数名 参数 返回值 功能 create char filename[] 无 创建文件 destroy char filename[] 无 删除文件 open char filename[] 无 打开文件 close char filename[] 无 关闭文件 read index:文件描述符号mem_area:读取的位置count:读取的字节数 无 读取文件内容 write index:文件描述符mem_area:x写入的位置count:写入字节数 无 向文件中写入信息 lseek index:文件描述符 号pos:位置 无 移动文件读写指针 $\qquad$文件系统提供的上述接口已经可以满足对文件系统的常规操作。上面的接口中提到的文件描述符在文件系统中是一个很重要的概念，每个文件都必须 通过一个文件描述符来表示 ，其文件长度信息 ，文件存储位置等常规 信息都存储在文件描述符中。 $\qquad$为此我设计了一个结构体FileDescriptor用于表示文件描述符，并且将该结构体进行4字节对齐，方便后续以二进制形式存储在文件中。 $\qquad$在文件系统中另外一个重要概念就是目录，因此定义一个结构体表示目录项，用于存储文件名和文件描述符号。 $\qquad$文件描述符和目录项在磁盘中存储的位置如上图所示，其中磁盘块的第一和第二块用于存储磁盘块的位图，第3-13块用于存储文描述符，14块用于存储目录项信息。 $\qquad$经过4字节对齐之后的文件描述符结构体大小为24字节，而一个磁盘块有512字节存储空间，所以一个磁盘块最多存储21个文件描述符，而本实验中设置的用于存储文件描述符的磁盘块为10块，最多可以存储210个文件描述符。 $\qquad$目录也可以看做一个文件，所以也会占据一个文件文件描述符，本实验中目录占用的文件描述符是第一个文件描述符。并且存储目录信息的磁盘是14号磁盘，经过4字节对齐的目录项结构体大小为16B，所以最多有32个文件。 $\qquad$文件系统的API如上图所示，我将文件系统的API分为初始化、用户接口、搜索和其他这四类，每一个大类具体的函数如下表所示： 文件系统初始化 函数名 参数 返回值 功能 InitFileDescriptor 无 无 初始化文件描述符数组 InitMenu 无 无 初始化目录项数组 文件系统用户接口(上面已经介绍过，不在赘述) 文件系统搜索 函数名 参数 返回值 功能 SearchFileDescriptor 无 无 搜索空闲的文件描述符 SearchMenuItem 无 无 搜索空闲的目录项 其他 $\qquad$这部分主要定义的是一些方便操作的函数，例如将文件描述符数组写入磁盘块中去，将目录系统写入磁盘块等等。 函数名 参数 返回值 功能 DiskToFileDescriptor 无 无 从磁盘块中恢复文件描述符数组 FileDescriptorToDisk 无 无 将文件描述符数组信息写入磁盘块 MenuToFileDescriptor 无 无 将目录项数组写入第一个文件描述符 FileDescriptorToMenu 无 无 将第一个文件描述符内容恢复到目录项数组 $\qquad$到此，文件系统部分所有数据结构和函数均介绍完毕 1.3 菜单系统设计$\qquad$完成IO系统的设计和文件系统的设计，需要对上述的功能设计一个外壳程序，即一个用户界面便于使用，总结文件系统的所有功能，设计的菜单驱动程序包含如下两层菜单。 一级菜单 创建新磁盘系统 从文件中恢复历史磁盘系统 二级菜单 查看目录 创建文件 删除文件 打开文件 修改文件 查看位图 保存磁盘 退出 二 I/O系统2.1 磁盘块结构体 I/O系统部分全部代码都在IO.h文件中 磁盘块结构体BLOCK $\qquad$设计整个I/O系统的基础就是设计模拟磁盘块的结构体，并用结构体数组代表磁盘，通过定义三维的结构体数组来模拟出整个磁盘的物理结构，这三维分别代表柱面、磁头和扇区。下面是磁盘块(逻辑块)结构体的定义： 12345678typedef struct BLOCK&#123; char Content[512]; //逻辑块存储的内容 int BlockNnum; //逻辑块号 int c; // 柱面号 int h; //磁头号 int b; //扇区号&#125;BLOCK; $\qquad$磁盘块结构体最重要的成员就是用于存储信息Content，这是一个字符型数组，大小为512个字节。而另外的逻辑块号，柱面号，磁头号和扇区号这四个成员是为了便于后续程序设计的。下面的表格详细表示每个成员的信息： 成员名 类型 大小 作用 Content 字符数组 512字节 存储磁盘块内容 BlockNum 整型 4字节 磁盘块的逻辑块号 c 整型 4字节 柱面号 h 整型 4字节 磁头号 b 整型 4字节 扇区号 物理磁盘(BLOCK数组) $\qquad$磁盘块结构体定义好之后，可以模拟出一个磁盘块，但是完整的磁盘是一个三维的磁盘块结构体数组构成的。 1234#define C 10 // 柱面号#define H 10 //磁头号#define B 10 //扇区号BLOCK ldisk[C][H][B];//磁盘模型 $\qquad$在IO.h直接定义ldisk数组，模拟物理磁盘。并且通过宏定义C、H和B三个量调整物理磁盘的大小。 磁盘初始化函数 $\qquad$在模拟物理磁盘的三维结构体数组定义好之后，需要对该数组进行初始化，对数组中的每个元素，即每个磁盘块进行初始化。 123456789101112void InitDisk(void)&#123; for(int i=0;i&lt;C;i++) for(int j=0;j&lt;H;j++) for(int k=0;k&lt;B;k++) &#123; ldisk[i][j][k].c=i; ldisk[i][j][k].h=j; ldisk[i][j][k].b=k; ldisk[i][j][k].BlockNnum=DiskNumToBlock(i,j,k);//计算对应的逻辑块号 &#125;&#125; $\qquad$可以看到对磁盘块数组进行初始化的方式非常简单，主要包含两个工作，一个就是顺序编号其柱面号、磁头号和扇区号；还有一个功能就是计算逻辑块号 2.2 磁盘读写$\qquad$说道磁盘系统的API函数，最重要的两个函数就是对磁盘块进行读写操作的两个函数。下面分别介绍这个两个函数的详细内容。 读磁盘块函数：ReadBlock(int i,char *p): 12345678void ReadBlock(int i,char *p)&#123; int c,h,b;//磁盘的柱面 磁道 扇区 c = i % (H*B);// h = (i -c*H*B) % B;// b = i-c*H*B - h*B;// memcpy(p,ldisk[c][h][b].Content,512);&#125; $\qquad$3-6行计算逻辑号为i的逻辑块在磁盘系统中的柱面号、磁头号和扇区号； $\qquad$第7行可以看作此函数的核心操作，完成的工作就是将制定磁盘块中的内容通过memcpy函数复制到字符型指针p中去。 注意：这里不能使用strcpy函数复制字符串，因为strcpy函数在复制的时候会遇到第一个\0就会停止复制，但是磁盘块中存储的信息可能不是连续的字符串，可能是一些其他信息，例如文件描述符等，这个时候就会碰到一些空位置用\0补充，但是后面还有有用的信息，所以使用memcp函数，按照指定字节数复制，而不考虑\0的问题 写磁盘块函数：WriteBlock(int i,char *p): 123456789void WriteBlock(int i,char *p)&#123; int c,h,b; b = i % B; h = ((i - b) / B) % H; c = (i -b -h*B) / (H*B); b = i -c*H*B -h*B ; memcpy(ldisk[c][h][b].Content,p,512);&#125; $\qquad$3-6行操作与上面相似，就是计算柱面号、磁头号和扇区号这三个参数 $\qquad$8第8行主要用于将参数p指针中的内容复制到磁盘块中 2.3 磁盘位图$\qquad$为了方便查询磁盘中的空闲磁盘块，直接遍历查询的效率非常低，所以本实验中采用了位图的方式来表示磁盘块的占用与否，一个字符表示一个磁盘块的占用与否，其中Y表示占用，N表示空闲。而位图编号就是磁盘块的逻辑块号数。 初始化磁盘位图函数：InitBitMap(void)： 12345678910void InitBitMap(void)&#123; //第0，1号磁盘已经被占用 ChangeBitMap(0,'Y'); ChangeBitMap(1,'Y'); for (int i=2;i&lt;C*H*B;i++) &#123; ChangeBitMap(i,'N'); &#125;&#125; $\qquad$可以看到初始化函数中将磁盘块数量(C*B*H)个单位的字符修改为N，表示为占用。4-5两行表示第一块和第二块物理磁盘初始化就被占用，因为这两块物理磁盘用于存储位图。 修改位图函数：ChangeBitMap(int i,char p): 1234567void ChangeBitMap(int i,char p)&#123; if(i &lt;512) ldisk[0][0][0].Content[i] = p; else ldisk[0][0][1].Content[i-512] = p;&#125; $\qquad$这个函数使用一个if结构判断逻辑块号，如果大于512的话存入 第二个磁盘块中，否则存入第一个磁盘块中。 2.4 磁盘文件的存取$\qquad$在内存中定义的磁盘块结构体数组无法满足断电后信息还能保存的特性，因此需要内存中的磁盘块数组中的信息保存到文件中去，需要的时候再加载出来。 将磁盘数组保存为文件：DiskToFile(char filename[])： 12345678910111213141516171819void DiskToFile(char filename[])&#123;// FileDescriptorToDisk(); FILE *fp; fp = fopen(filename,"wb"); //判断fp打开成功 if (fp ==NULL) &#123; printf("File Open Fail"); exit(1); &#125; // 循环遍历，将磁盘块内容写入二进制文件中去 for(int i=0;i&lt;C;i++) for(int j=0;j&lt;H;j++) for(int k=0;k&lt;B;k++) //以二进制的形式写入二进制文件中 fwrite(ldisk[i][j][k].Content,512,1,fp); fclose(fp);&#125; $\qquad$3-5行以二进制写入形式打开指定文件名的文件 $\qquad$7-11行判断文件是否打开成功，没打开成功的话输出错误信息并退出程序 $\qquad$13-17行，遍历磁盘数组，以二进制的形式将磁盘块中存储的内容写入到文件中去。最后关闭文件 加载文件到磁盘块数组：FileToDisk(char filename[])： 1234567891011121314151617181920212223242526//从文件中读取数据，恢复磁盘系统void FileToDisk(char filename[])&#123; FILE *fp; fp = fopen(filename,"rb"); if(fp == NULL) &#123; printf("File Open Fail"); exit(1); &#125; int index = 0; while(!feof(fp)) &#123; int c,h,b; b = index % B; h = ((index - b) / B) % H; c = (index -b -h*B) / (H*B); b = index -c*H*B -h*B ; fread(ldisk[c][h][b].Content,512,1,fp); ldisk[c][h][b].c = c; ldisk[c][h][b].h = h; ldisk[c][h][b].b = b; index++; &#125; fclose(fp);&#125; $\qquad$这段程序除了打开文件等常规操作之外，核心的代码是while循环中的，首先计算逻辑号为index的逻辑块的柱面号、磁头号和扇区号；之后每次读取512字节数据到对应磁盘块数组中的磁盘块中去。 2.5 空闲磁盘块搜索$\qquad$2.3节中定义了位图，用于存储磁块的空闲状态，所以当需要使用磁盘块的时候 ，需要查询位图找到一个空闲磁盘块号返回。 空闲磁盘块搜索函数：`SearchBitMap(void)： 1234567891011121314151617//搜索位图，找到空闲磁盘块号int SearchBitMap(void)&#123; for(int i=14;i&lt;C*H*B;i++) &#123; if(i&lt;512) &#123; if(ldisk[0][0][0].Content[i]=='N') return i; &#125; else &#123; if(ldisk[0][0][1].Content[i-512]=='N') return i; &#125; &#125;&#125; $\qquad$本函数的实现方式就是通过遍位图知道找到一个空闲的磁盘块。不过由于所有的位图 信息并不是全部存储在一个磁盘块中，而是两个磁盘块，所以在遍历的时候需要判断在哪个磁盘块。 三 文件系统 文件系统全部代码存储在FS.h文件中 3.1 文件描述符结构体 &amp; 目录项结构体 文件描述符结构体定义 $\qquad$文件系统采用文件描述符来记录每一个文件的信息，下面是文件描述符的结构体定义： 123456789#pragma pack(4)typedef struct FileDescriptor //此文件描述符总共占据磁盘24字节&#123; int Length;//文件长度 int DiskNum[DiskNumLen]; //第二个3只是表示每个磁盘块好最大长度是3位 int Num; //文件描述符号 char IsFree; //表示此文件描述符是否空闲&#125;FileDescriptor;#pragma pack(pop) 在这个结构体定义有一个特别的地方需要注意，就是使用了4字节对齐机制，因为后来这些结构体需要存储到字符型数组中，如果不采用对齐的话可能会导致不同结构体的长度不同，读取的时候就没办法读取. $\qquad$下面是该结构体各个成员的详细解释： 成员名 类型 大小 作用 Length 整型 4字节 存储文件大小 DiskNum 整型数组 12字节 存储文件内容的磁盘块好数组 Num 整型 4字节 文件描述符号 IsFree 字符型 4字节(对齐后) 表示当前描述符时候空闲 目录项结构体定义 $\qquad$目录是文件系统必不可缺的组成部分，本实验中通过目录项数组组成一个目录，而每个目录项由文件名和文件描述符号组成。下面是目录项结构体定义： 1234567#pragma pack(4)typedef struct MenuItem //目录对应0号文件描述符,一个目录项占据16字节，所以一个文件描述符可以存储96个文件&#123; char FileName[12]; //目录项中文件名的最大长度为16字节 int FileDescriptorNum;//文件描述符号&#125;MenuItem;#pragma pack(pop) 同样目录项结构体也是经过4字节对齐的，作用与上面的文件描述符结构体相似 成员名 类型 大小 作用 FileName 字符型数组 12字节 存储文件名 FileDescriptorNum 整型 4字节 文件描述符号 3.2 文件系统初始化$\qquad$文件系统的初始化包括对文件描述符数组的初始化和目录项数组的初始化，和IO系统中的磁盘数组初始化一样，文件系统的初始化也就是对这两个数组进行一些编号操作等基本操作。 文件描述符初始化：InitFileDescriptor(void): 1234567891011121314void InitFileDescriptor(void)&#123; for(int i=0;i&lt;256;i++) &#123; int DiskNum[3]; //磁盘号数组 DiskNum[0] = i; DiskNum[1] = -1; DiskNum[2] = -1; int FileDescriptorNum = i; //文件描述符号 ChangeFileDescriptor(&amp;filedescriptor[i],0,DiskNum,FileDescriptorNum,'Y'); &#125; filedescriptor[0].IsFree = 'N'; FileDescriptorToDisk();&#125; $\qquad$首先遍历整个文件描述符数组，进行编号并且初始化的时候文件描述符对应的三个磁盘块只分配一个。 目录项初始化 12345void InitMenu(void)&#123; for(int i=0;i&lt;32;i++) menuitem[i].FileDescriptorNum = i;&#125; 3.3 文件系统用户接口 创建文件：create(char filename[]): 1234567891011121314151617//下面是文件系统与用户直接的接口void create(char filename[])&#123; int FileDescriptorNum,MenuItemNum,DiskNum; //寻找空闲目录项 MenuItemNum = SearchMenuItem(); strcpy(menuitem[MenuItemNum].FileName,filename); //寻找空闲文件描述符 FileDescriptorNum = SearchFileDescriptor(); menuitem[MenuItemNum].FileDescriptorNum = FileDescriptorNum; //寻找空闲磁盘块 DiskNum = SearchBitMap(); filedescriptor[FileDescriptorNum].DiskNum[0] = DiskNum; filedescriptor[FileDescriptorNum].IsFree = 'N'; //修改磁盘位图 ChangeBitMap(DiskNum,'Y');&#125; $\qquad$创建一个新的文件的时候，首先需要搜索一个空闲的目录项，将文件名存储在目录项中，然后在搜索一个空闲的描述符，分配该文件描述符给他文件，在搜索 一个空闲的磁盘块，将该磁盘块存储在文件描述符中。最后修改文件描述符状态和位图对应磁盘块的状态为占用。 删除文件：destroy(char filename[])： 12345678910111213141516171819202122void destroy(char filename[])&#123; int MenuItemNum=-1; for(int i=0;i&lt;32;i++) if(strcmp(menuitem[i].FileName,filename)==0) MenuItemNum = i; if(MenuItemNum==-1) &#123; printf("目录中没有此文件！\n"); return; &#125; int FileDesCriptorNum = menuitem[MenuItemNum].FileDescriptorNum; //将目录项重置,重置时只需要将文件名删除，而不需要重置文件描述符，因为前面判断文件是否存在的条件是文件名是否存在 memset(menuitem[MenuItemNum].FileName,0, sizeof(menuitem[MenuItemNum].FileName)); //修改文件描述符为空闲状态 filedescriptor[FileDesCriptorNum].IsFree = 'Y'; for(int i=0;i&lt;3;i++) &#123; if(filedescriptor[FileDesCriptorNum].DiskNum[i]!=-1) ChangeBitMap(filedescriptor[FileDesCriptorNum].DiskNum[i],'N'); &#125;&#125; $\qquad$根据文件名在目录项数组中搜索对应的目录项，删除文件名，再找到目录项后读取该文件对应的文件描述符号，修改文件描述符状态为空闲；再讲文件描述符中记录的所有磁盘块状态全部改为空闲。 打开文件：open(char filename[]) 123456789101112131415int open(char filename[])&#123; int MenuItemNum=-1; for(int i=0;i&lt;32;i++) if(strcmp(menuitem[i].FileName,filename)==0) MenuItemNum = i; if(MenuItemNum==-1) &#123; printf("目录中没有此文件！\n"); return -1; &#125; else //返回文件描述符号 return menuitem[MenuItemNum].FileDescriptorNum;&#125; $\qquad$这个函数通过遍历目录项数组，找到文件名符合的目录项，读取其文件描述符号返回，没有找到的话打印错误信息并返回-1 读取文件：read(int index,int mem_area,int count)： 123456789char* read(int index,int mem_area,int count)&#123; char *temp; char block[512]; temp = (char *)malloc(count* sizeof(char)); ReadBlock(filedescriptor[index].DiskNum[0],block); memcpy(temp,&amp;block[mem_area],count); return temp;&#125; $\qquad$读取文件内容函数首先找到文件描述符中的磁盘号，然后调用IO系统提供的读取磁盘块的接口读取该磁盘块，读取后按照要求取对应位置指定长度的数据返回。 写文件：write(int index,int mem_area,int count,char content[])： 123456789101112131415void write(int index,int mem_area,int count,char content[])&#123; char temp[512]; char *s1=(char*)malloc(mem_area* sizeof(char)); char *s2=(char*)malloc(mem_area* sizeof(char)); char *s; int DiskNum = filedescriptor[index].DiskNum[0]; ReadBlock(DiskNum,temp); memcpy(s1,temp,mem_area); memcpy(s2,&amp;temp[mem_area],512-mem_area); s = strcat(s1,content); s = strcat(s,s2); filedescriptor[index].Length = strlen(s); WriteBlock(DiskNum,s);&#125; $\qquad$写文件的时候需要考虑可能是在原来文件的基础上，在某段插入一些内容，所以用s1字符指针保存mem_area之前的信息，s2保存mem_area之后的信息，加入要加入的内容后在连接成为一个完整的字符数组，最后调用IO系统提供的写入磁盘块接口写入 对应磁盘块。 3.4 搜索文件系统$\qquad$上面文件系统的用户接口中 很多地方用到了搜索文件描述符、搜索目录项等操作，所以需要单独写几个函数用于搜索文件描述符和目录项等结构。 搜索空闲文件描述符:SearchFileDescriptor(): 123456789int SearchFileDescriptor()&#123; for(int i=0;i&lt;256;i++) &#123; if(filedescriptor[i].IsFree == 'Y') return i; &#125; return -1;&#125; $\qquad$遍历文件描述符数组，找到空闲的文件描述符号返回 搜索空闲目录项：SearchMenuItem()： 123456789int SearchMenuItem()&#123; for(int i=0;i&lt;32;i++) &#123; if(strlen(menuitem[i].FileName)==0) return i; &#125; return -1;&#125; $\qquad$遍历所有的目录项数组，知道找到空闲的目录项返回目录项号 3.5 其它文件系统函数$\qquad$除了上面介绍的文件操作之外，还需一些函数，例如将文件描述符写入到磁盘中去，将目录项数组写入到第一个文件描述符对应的磁盘中；从磁盘中恢复文件描述符数组，恢复目录项数组。 将文件描述符数组写入磁盘：FileDescriptorToDisk(void)： 123456789101112131415161718192021222324252627282930//将文件描述符写入磁盘中void FileDescriptorToDisk(void)&#123; char temp_block[512]; int index = 0; int DiskNumIndex = 2; for(int i=0;i&lt;256;i++) &#123; char temp_descriptor[24]; memcpy(temp_descriptor,&amp;filedescriptor[i], sizeof(FileDescriptor)); memcpy(&amp;temp_block[index*24],temp_descriptor,24); index++; int t = index % 21; if(t == 0) &#123; index = 0; if(DiskNumIndex&lt;10) &#123; memcpy(ldisk[0][0][DiskNumIndex].Content,temp_block,512); ChangeBitMap(DiskNumIndex,'Y'); &#125; else &#123; memcpy(ldisk[0][1][DiskNumIndex-B].Content,temp_block,512); ChangeBitMap(DiskNumIndex,'Y');//修改位图 &#125; DiskNumIndex++; &#125; &#125;&#125; $\qquad$遍历整个文件描述符数组，每个文件描述符占据24字节信息，21个文件描述符一组，一共504字节，将每组504字节信息存入到一个磁盘块中，存入后修改磁盘的状态为占用。 从磁盘恢复文件描述符数组：DiskToFileDescriptor(void)： 12345678910111213141516171819202122232425262728//将磁盘读取的信息恢复void DiskToFileDescriptor(void)&#123; for(int i=2;i&lt;15;i++) &#123; char temp[512]; if (i&lt;B) memcpy(temp,ldisk[0][0][i].Content,512); else memcpy(temp,ldisk[0][1][i-B].Content,512); for (int j=0;j&lt;21;j++) &#123; if(((i-2)*21+j)&gt;256) break; char temp_FileDescriptor[24]; memcpy(temp_FileDescriptor,&amp;temp[j*24],24); FileDescriptor *f; f = (FileDescriptor*)temp_FileDescriptor; int num = (i-2)*21+j; filedescriptor[num].IsFree = f-&gt;IsFree; filedescriptor[num].DiskNum[0] = f-&gt;DiskNum[0]; filedescriptor[num].DiskNum[1] = f-&gt;DiskNum[1]; filedescriptor[num].DiskNum[2] = f-&gt;DiskNum[2]; filedescriptor[num].Length = f-&gt;Length; filedescriptor[num].Num = f-&gt;Num; &#125; &#125;&#125; $\qquad$由于每个磁盘块的空间只能存储21个文件描述符，所以每隔21就需要将index归零一次，用于从新读取一个新的磁盘的文件描述符信息，每次读取的是一整个磁盘的信息，长度是512字节，而每个文件描述符的大小为24，所以首先全部服务磁盘块信息到temp_block，然后每次读取24字节信息到temp_descriptor,之后通过强制类型转换，将字符换数组转化为文件描述符结构体指针，这样就将磁盘块中的信息读入。 将目录项数组写入文件描述符：MenuToFileDescriptor(void)： 123456789101112131415//将目录内容写入文件描述中void MenuToFileDescriptor(void)&#123; char temp_FileDescriptor[512]; for(int i=0;i&lt;32;i++) &#123; char temp_menuitem[16]; memcpy(temp_menuitem,&amp;menuitem[i],16); memcpy(&amp;temp_FileDescriptor[i*16],temp_menuitem,16); &#125; filedescriptor[0].IsFree = 'N'; filedescriptor[0].DiskNum[0] = SearchBitMap(); filedescriptor[0].Length = 512; WriteBlock(filedescriptor[0].DiskNum[0],temp_FileDescriptor);&#125; $\qquad$将所有的目录项合并为一个512字节的字符数组(注意使用的是memcpy而不是strcpy)然后将第一个文件描述符的状态修改位占用，并将字符数组写入第一个文件描述符对应的磁盘块。 从第一个文件描述符恢复目录项数组：FileDescriptorToMenu(void)： 1234567891011121314void FileDescriptorToMenu(void)&#123; char MenuContent[512]; ReadBlock(filedescriptor[0].DiskNum[0],MenuContent); for(int i=0;i&lt;32;i++) &#123; char temp_menuitem[16]; memcpy(temp_menuitem,&amp;MenuContent[i*16],16); MenuItem *t; t = (MenuItem *)temp_menuitem; strcpy(menuitem[i].FileName,t-&gt;FileName); menuitem[i].FileDescriptorNum = t-&gt;FileDescriptorNum; &#125;&#125; $\qquad$首先读取第一个文件描述符对应的磁盘块信息到MenuContent字符数中去，然后每次读取16字节信息，将读取的16字节信息强制转换为目录项指针。这样磁盘上存储的所欲目录项信息就会被全部读取。 四 菜单系统 菜单系统代码在main.cpp文件中 $\qquad$IO系统和文件系统准备好之后就可以更具需要的功能设计出具体的功能，并对应写出一个菜单系统。 对应的菜单系统有如下函数： 查看目录函数：ShowDir() 123456789101112131415161718void ShowDir()&#123; int index =1; int exist = 0; printf("****************目录***********************\n"); printf("当前目录下文件有:\n"); for(int i=0;i&lt;32;i++) &#123; if(strlen(menuitem[i].FileName)!=0) &#123; printf("%d %s %dB\n",index,menuitem[i].FileName,filedescriptor[menuitem[i].FileDescriptorNum].Length); exist++; &#125; index++; &#125; printf("一共存在%d个文件\n",exist); printf("****************************************\n");&#125; $\qquad$可以看到这个查看目录函数遍历目录项数组，打印所有非空目录项 内容，包括文件名和文件大小，最后统计出一共存在多少个文件。 打印位图：ShowBitMap() 1234567891011121314151617181920212223242526272829303132333435void ShowBitMap(void)&#123; printf("\n****************位图**********************\n"); int used = 0; printf("当前的磁盘使用情况如下(Y表示使用，N表示未使用)\n"); for(int i=0;i&lt;C;i++) &#123; printf("%d号柱面磁盘信息如下:\n",i); printf(" 区:0 1 2 3 4 5 6 7 8 9\n"); printf("头\n"); for(int j=0;j&lt;H;j++) &#123; printf("%d\t:",j); for(int k=0;k&lt;B;k++) &#123; int t=i*H*B+j*B+k; if(t&lt;512) &#123; printf("%c ",ldisk[0][0][0].Content[t]); if(ldisk[0][0][0].Content[t] == 'Y') used++; &#125; else &#123; printf("%c ",ldisk[0][0][1].Content[t-512]); if(ldisk[0][0][0].Content[t] == 'Y') used++; &#125; &#125; printf("\n"); &#125; &#125; printf("总共使用%d个磁盘块，剩余%d个磁盘块空闲\n",used,(C*B*H-used)); printf("****************************************\n");&#125; $\qquad$这个函数的大部分代码在进行位图打印信息的排版，每个柱面为一页，每一页中每一行表示一个磁头，每一列表示一个扇区。最后统计出所有磁盘的使用占比。 主菜单程序 由于整个函数代码太长，所以只展示核心代码，完整代码请查看github 123456789101112131415161718192021222324252627282930313233343536373839404142434445switch (choice2)&#123; case 1:ShowDir();break; case 2: printf("请输入要创建的文件名："); scanf("%s",filename); create(filename); break; case 3: printf("请输入要删除的文件名："); scanf("%s",filename); destroy(filename); break; case 4: printf("请输入要打开的文件名："); scanf("%s",filename); ReadFile(filename); break; case 5: int choice3; printf("1. 增加内容\t2. 删除内容"); printf("\n请选择："); scanf("%d",&amp;choice3); printf("请输入要修改的文件名:"); scanf("%s",filename); if(choice3==1) ChangeFileAdd(filename); else if(choice3==2) ChangeFileDel(filename); break; case 6: ShowBitMap(); break; case 7: printf("请输入要保存的文件名："); scanf("%s",filename); save(filename); break; case 8: flag=1; break; default: break;&#125; $\qquad$这个switch结构提供个8个选择，对应8个功能。 五 文件系统测试$\qquad$IO系统、文件系统和菜单系统完成之后需要对文件系统进行测试，下面是测试的详细过程。 5.1 测试概述$\qquad$测试部分分别测试IO系统、文件系统对应的功能，测试计划如下所示： 测试名称 测试描述 被测试模块 保存磁盘文件测试 将当前磁盘信息存入二进制文件 IO系统磁盘写入文件功能、菜单系统等 读取磁盘文件测试 从文件系统中读取磁盘文件，装载到磁盘系统中 IO系统磁盘写入文件功能、菜单系统等 目录查看测试 查看当前目录中存在的所有文件 文件系统目录模块、文件描述符模块；菜单系统 文件创建测试 创建新的文件 文件系统目录模块、文件系统用户接口 文件删除测试 删除已有(不存在)文件 文件系统目录模块、文件系统用户接口 打开文件测试 打开并查看文件内容 文件系统用户接口 修改文件测试 修改文件内容 文件系统目录模块、文件系统用户接口，IO系统 查看位图测试 查看当前磁盘位图信息 IO系统位图模块，菜单系统 5.2 系统测试 保存磁盘文件测试 &amp; 文件创建测试 保存磁盘系统之前首先需要创建一个新的磁盘系统 在新的文件系统中创建文件 可以看到查看文件目录的时候看到刚刚创建的目录 给刚刚创建的文件添加一点内容 可以看到添加了内容之后内容保存到文中去 再次查看目录 可以看到文件的长度确实发生了变化 保存磁盘文件 将磁盘系统保存到test.dat中去 为了验证刚刚的磁盘信息确实保存了下来，使用xxd工具查看test.dat文件的内容 可以看到test.dat中前面是位图信息，共占用15个磁盘块，标志位’Y’,其他所有磁盘块状态为空闲，标志位’N’ 再检索刚刚创建的文件是否存在 可以看到检索’Hello’和文件名’test’的时候都有对应内容，说明磁盘信息缺失保存了下来 读取磁盘文件测试 &amp; 目录查看测试 &amp; 打开文件测试 打开上面测试中保存的test.dat文件 可以看到磁盘信息全部恢复了 打开文件内容具体查看一下，内容是否存在变化 可以看到文件内容没有发生改变 文件删除测试 为了便于进行文件删除测试，首先先创建一个文件test2.txt 删除文件test2.txt 修改文件测试 $\qquad$修改文件测时候分为在原有文件的基础上增加内容和删除内容，我们这在test.txt的基础上进行增加和删除操作 在test.txt上增加内容 可以看到在指定位置增加了指定的内容 在test.txt删除内容 可以看到指定位置的指定内容被删除了 查看位图测试 文件系统在初始化之后应该有15个磁盘块被占用，其中2个用于存储位图，12个用于存储文件描述符，1个用于存储目录 可以看到0号柱面的磁盘位图信息如上所示,总共使用14个磁盘块，其他全部空闲 增加一个文件之后，查看磁盘位图 $\qquad$增加文件之后，当文件内容小于一个磁盘块大小时，暂时只分配一个磁盘块，所以应该只占用前个磁盘块 六 实验总结$\qquad$通过本次实验收获到了许多的东西，也许到了很多知识。实验之前，看完整个实验要求之后没有一个整体的思路就开始编写程序，导致后期的时候很多地方考虑不够全面，各个系统中函数组织混乱，整个构架不够完整，本次实验收获到的第一点就是在进行实验之前一定要提前设计好实验的思路，最好做好整个概要设计；第二点收获就是对文件系统有了更加深刻的认知，实验从最底层的磁盘块开始模拟，一点一点到IO系统，再到文件系、目录等等，通过自己的实践更加深刻的了解了文件系统；最后一点 收获就是在编程能力上的收获，这次通过编写这个文件系统，再次巩固了自己对于C语言的掌握能力，并且了解到了以前所用的处理字符串的一系列函数的缺点，例如strcpy只能复制\0之前的内容，strcat只能连接两个字符换的可见内容等等，学会了新的函数memcpy，通过这个函数实现将结构体以二进制的形式存储到字符串中和将字符串再恢复到结构体中。]]></content>
      <categories>
        <category>操作系统实验</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统调用实验]]></title>
    <url>%2Fsunpages%2F2019%2F03%2F01%2Flab1%2F</url>
    <content type="text"><![CDATA[实验一实验报告 孙汉武 16281047 安全1601 [TOC] Task 1 系统调用实验1.1 直接调用和汇编中断调用系统调用getpidC语言直接调用 实验步骤 源代码getpid_c.c： 123456789#include&lt;stdio.h&gt;#include&lt;unistd.h&gt;int main()&#123; pid_t pid; pid = getpid(); printf("%d\n",pid); return 0;&#125; 编译源代码，得到可执行文件getpid_c 执行可执行文件，得到程序的pid 查看getpid的系统调用号 64位Linux系统的系统调用列表保存在/usr/include/asm/unistd_64.h（32位在unistd_32.h）,查看该文件可得到getpid的系统调用号为39（32位系统的系统调用号为20） 通过上图可以看出，在64位系统中，有两套系统调用号的宏定义，除了64位正常的系统调用号表之外，还有一套用于向下兼容32位系统。 在Linux(debian)中，/usr/include/asm中有两个h文件，分别是unistd_32.h和unistd_64.这两个头文件中保存着系统调用号的宏定义， 当在程序代码中用到系统调用时，编译器会将上面提到的宏展开，展开后的代码实际上是将系统调用号放入ax后移用int 0x80使处理器转向系统调用入口，然后查找系统调用表，进而由内核调用真正的功能函数。 通过汇编代码可以看到中断向量号是0x80,而0x14是指系统调用号，在32位系统中，getpid系统调用号为20，所以是16进制的0x14，而64位系统的getpid的系统调用号为39. 系统调用号跟操作系统的位数(32或64)和不同的发行版本(debian和Ubuntu)有关，例如Ubuntu 64位机器上getpid的系统调用号是172，而网上查到Linux内核64位为39，32位为20。 出现不一致的原因是，在Linux64位系统中，对32位程序进行了兼容操作。之前的32位机中，系统通过开放0x80搭配系统调用号来实现用户程序使用系统调用功能。但在64位机中，已经不使用int 0x80作为触发系统调用的机制了，而使用syscall指令来触发。但为了保持兼容性，系统仍然支持int 0x80进行‘32位’风格的调用。自然我们的汇编代码使用20这个系统调用号，依然可以正确运行在64位机器上。 汇编中断调用 实验步骤 源代码getpid_asm.c： 1234567891011121314#include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main() &#123; pid_t pid; asm volatile ( "movl $0x14,%%eax\n\t" "int $0x80\n\t" "movl %%eax,%0\n\t" :"=m"(pid) ); printf(" current PID is : %u\n",pid); return 0;&#125; 编译源码，得到可执行文件getpid_asm 执行可执行文件，得到程序的pid getpid的中断向量号 在汇编代码int $0x80\n\t可以看到getpid的中断向量号为0x80 1.2 习题1.13使用C语言 实验步骤 源代码print_c.c: 123456#include&lt;stdio.h&gt;int main()&#123; printf("Hello World!\n"); return 0;&#125; 编译源码，得到可执行文件print_c 执行文件，屏幕打印Hello World 使用汇编 实验步骤 源代码print_asm.asm: 1234567891011121314section datamsg db &quot;Hello World&quot;,0xAlen equ $-msgsection .text global _start_start: mov eax,4 mov ebx,1 mov ecx,msg mov edx,len int 0x80 mov eax,1 xor ebx,ebx int 0x80 汇编源码，得到对象文件print_asm.o 链接得到可执行文件print_asm 执行可执行文件print_asm,屏幕打印Hello World 1.3 阅读pintos源码​ pintos中关于系统调用的源码以下部分。下面分别介绍他们各自的作用： /src/lib/user/syscall.c 这个文件中以宏定义的形式定义了四种系统调用的方式，分别是不传递参数、传递一个参数、传递两个参数、传递三个参数 1234#define syscall0(NUMBER) ...#define syscall1(NUMBER, ARG0) ...#define syscall2(NUMBER, ARG0, ARG1) ...#define syscall3(NUMBER, ARG0, ARG1, ARG2) ... 四个系统调用方式的中断向量号均为0x30. 定义了20种系统调用函数 1234567891011121314151617181920void halt (void);void exit (int status)pid_t exec (const char *file);int wait (pid_t pid);bool create (const char *file, unsigned initial_size);bool remove (const char *file);int open (const char *file);int filesize (int fd) ;int read (int fd, void *buffer, unsigned size);int write (int fd, const void *buffer, unsigned size);void seek (int fd, unsigned position) ;unsigned tell (int fd) ;void close (int fd);mapid_t mmap (int fd, void *addr);void munmap (mapid_t mapid);bool chdir (const char *dir);bool mkdir (const char *dir);bool readdir (int fd, char name[READDIR_MAX_LEN + 1]) ;bool isdir (int fd);int inumber (int fd); 上面的系统调用在下面的头文件中都有对应的系统调用号 /src/lib/syscallnr.h 这个文件中定义了系统调用列表，通过枚举类型定义了系统调用号 具体如下： src/userprog/syscall.c 这个文件中只有两个函数syscall_init和syscall_handler,其中syscall_init是负责系统调用初始化工作的，syscall_handler是负责处理系统调用的 syscall_init函数 这个函数内部调用了intr_register_int函数，用于注册软中断从而调用系统调用处理函数 下面是pintos系统调用的完整流程图 Task 2 并发实验2.1 实验步骤 编写cpu.c程序，代码如下： 1234567891011121314151617181920#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;sys/time.h&gt;#include&lt;assert.h&gt;#include&lt;unistd.h&gt;int main(int argc,char *argv[])&#123; if (argc!=2) &#123; fprintf(stderr,"usage:cpu&lt;string&gt;\n"); exit(1); &#125; char *str=argv[1]; while(1) &#123; sleep(1); printf("%s\n",str); &#125; return 0;&#125; 编译源码cpu.c，得到可执行文件cpu 1gcc cpu.c -o cpu 执行cpu程序 1./cpu A &amp; ; ./cpu B &amp; ; ./cpu C &amp; ; ./cpu D 程序功能解释： 该程序的接受且仅能接受一个参数，当正确接受到参数的时候打印该参数，没有正确接受参数的时候，通过打印标准错误输出提示用户正确输入参数。 2.2 实验结果通过上面的实验可以观察到四个进程的运行顺序并没有规律。对于这种现象的解释如下： 现代操作系统中进程的运行都是并发实现的，并不是像以前的单道批处理的操作系统那样，总是按照进程进入内存的先后顺序来执行，因此进程的运行的顺序并没有规律。 现代CPU一般都是多核CUP（我的电脑是四核），因此实验中的四个进程可能也不是简单的在一个CPU中并发，而有可能是在多个CPU核心中并行运行，也有可能某两个进程在一个CPU核心中并发运行，和其他的进程在不同的CPU核心中并行运行。所以进程的运行顺序并没有特别的规律。 Task 3 内存分配实验3.1 实验步骤 编写mem.c程序，代码如下： 123456789101112131415161718#include&lt;unistd.h&gt;#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;assert.h&gt;int main(int argc,char *argv[])&#123; int *p = malloc(sizeof(int)); assert(p!=NULL); printf("(%d) address pointed to by p: %p\n",getpid(),p); *p=0; while(1) &#123; sleep(1); *p=*p+1; printf("(%d) p: %d\n",getpid(),*p); &#125; return 0;&#125; 编译源码mem.c，得到可执行程序mem 1gcc mem.c -o mem 执行mem程序 测试一： 测试二： 测试三： 程序功能解释 mem程序的功能是首先申请一个int大小的内存地址，并打印进程号和内存地址。之后就是对该内存地址保存的值进行循环累加操作 3.2 实验结果与结论 实验现象 通过内存分配实验可以观察到如下现象： 两个进程申请分配的内存地址有时一样，有时不一样，但是大概率出现的是不一样的。 对于每个进程而言，每个进程一直在该分配的内存空间进行累加操作，并且两个进程之间没有相互影响。 关闭地址空间随机化之后会发现每次执行两个进程申请的地址是相同的。 原理解释 每个进程的4G内存空间只是虚拟内存空间，每次访问内存空间的某个地址，都需要把地址翻译为实际物理内存地址。 所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。进程需要用页表来记录哪些数据在物理地址，哪些不在，如果在的话在哪。 printf函数中%p打印的是虚拟地址 当关闭了地址空间随机化之后，在每个进程相当于有4G的独立虚拟内存，由于每个进程的程序是一模一样的，所以分配的地址肯定也一样。如果在申请的话应该就是顺序分配了。 现象解释 由于每个进程都会有独立的4G虚拟内存，所以每个进程的内存地址在分配的时候可能相同，也可能不同，因为两个虚拟的地址之间没有任何关联。由于每个进程的虚拟地址是独立于其他进程的，通过页表将虚拟地址转换为真实地址，不论两个进程申请的虚拟内存地址是否相同，真实的物理地址一定是不一样的，所以两个进程对地址上的数值操作都是独立的。 但是关闭地址空间随机化之后两个进程的操作是完全一样的，加上有没有地址空间随机化的干扰，所以地址就是相同的 Task 4 共享问题4.1 实验步骤 编写程序thread.c,源码如下： 12345678910111213141516171819202122232425262728293031#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;volatile int counter=0;int loops;void *worker(void *arg)&#123; int i; for(i=0;i&lt;loops;i++) &#123; counter++; &#125; return NULL;&#125;int main(int argc,char *argv[])&#123; if(argc!=2) &#123; fprintf(stderr,"usage: thread &lt;value&gt;\n"); exit(1); &#125; loops=atoi(argv[1]); pthread_t p1,p2; printf("Initial value: %d\n",counter); pthread_create(&amp;p1,NULL,worker,NULL); pthread_create(&amp;p2,NULL,worker,NULL); pthread_join(p1,NULL); pthread_join(p2,NULL); printf("Final value: %d\n",counter); return 0;&#125; 编译源码thread.c 1gcc -o thread -lpthread thread.c 执行thread程序 ./thread 1000 ./thread 10000 ./thread_1 1000 ./thread_1 10000 程序功能解释 程序一个main进程下创建了两个线程，两个线程执行相同的操作，都是对loops变量进行自增操作。 4.2 实验结果与结论 实验现象 可以看到当输入的参数比较小的时候，Final value等于Initial value的两倍，当输入的参数比较大的时候，Final value的值在Initial vlaue的一倍到两倍之间.并且在最后两个测试样例中可以看到两个线程操作的loops变量的内存地址是相同的。 原理解释 由于两个线程在同一个进程中，并且访问操作的是共享的变量。如果每个线程对内存都是可读可写的话，就会发生读取脏数据的问题，即是线程A读取内存x的之后，对它进行+1，在线程A操作完成的数据写入x之前，线程B也读取了原来的数据，导致最终线程B写入的数据和A写入的一样，相当于两个线程只进行了一次操作。 为了解决上面所说的脏数据的问题，现代CPU一般采用了加锁的解决办法，通过加锁使另一个线程不能读取。 现代计算机都是多核心的，对于每个独立的CPU核心来说，都不会发生问题，但是不同CPU核心之间却依然有问题。 现象解释 当输入的参数比较小的时候，一个CPU的核心足够处理，就是单核CPU运行多线程，由于每个核心都有内存锁机制，所以计算结果没有错误 当输入的参数比较大的时候，使用多个CPU核心进行运算，就会发生读取脏数据的问题。 5 实验疑问 在Task3中，关闭了地址空间随机化之后，按照理论上将申请两个int的地址应该是连续的，所以我我就验证了一下，在原本的代码中申请两个int类型的地址，然后打印这两个地址，看这两个地址连不连续。代码如下： 之后编译运行程序，结果如下： 发现地址并不是连续的，因此还有一下疑问： 0x1fd5260这个地址指的是啥，就是每个进程的虚拟内存的地址吗？ 我尝试过将int换成其他类型的，发现并没有发生变化，这是为啥呢？]]></content>
      <categories>
        <category>操作系统实验</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2Fsunpages%2F2018%2F09%2F11%2Fss_err%2F</url>
    <content type="text"><![CDATA[shadowsocks启动报错]]></content>
  </entry>
</search>
